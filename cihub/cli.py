from __future__ import annotations

import argparse
import base64
import json
import re
import subprocess
import sys
from pathlib import Path
from typing import Any

import yaml
from jsonschema import Draft7Validator

from cihub import __version__


GIT_REMOTE_RE = re.compile(
    r"(?:github\.com[:/])(?P<owner>[^/]+)/(?P<repo>[^/.]+)(?:\.git)?$"
)


def hub_root() -> Path:
    return Path(__file__).resolve().parents[1]


def read_yaml(path: Path) -> dict[str, Any]:
    if not path.exists():
        return {}
    data = yaml.safe_load(path.read_text(encoding="utf-8")) or {}
    if not isinstance(data, dict):
        raise ValueError(f"{path} must be a mapping at top level")
    return data


def write_yaml(path: Path, data: dict[str, Any], dry_run: bool) -> None:
    payload = yaml.safe_dump(
        data, sort_keys=False, default_flow_style=False, allow_unicode=True
    )
    if dry_run:
        print(f"# Would write: {path}")
        print(payload)
        return
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(payload, encoding="utf-8")


def write_text(path: Path, content: str, dry_run: bool) -> None:
    if dry_run:
        print(f"# Would write: {path}")
        print(content)
        return
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(content, encoding="utf-8")


def deep_merge(base: dict[str, Any], override: dict[str, Any]) -> dict[str, Any]:
    result: dict[str, Any] = {}
    for key in base:
        if key in override:
            b, o = base[key], override[key]
            if isinstance(b, dict) and isinstance(o, dict):
                result[key] = deep_merge(b, o)
            else:
                result[key] = o
        else:
            result[key] = base[key]
    for key in override:
        if key not in base:
            result[key] = override[key]
    return result


def detect_language(repo_path: Path) -> tuple[str | None, list[str]]:
    checks = {
        "java": ["pom.xml", "build.gradle", "build.gradle.kts"],
        "python": ["pyproject.toml", "requirements.txt", "setup.py"],
    }
    matches: dict[str, list[str]] = {"java": [], "python": []}
    for language, files in checks.items():
        for name in files:
            if (repo_path / name).exists():
                matches[language].append(name)

    java_found = bool(matches["java"])
    python_found = bool(matches["python"])

    if java_found and not python_found:
        return "java", matches["java"]
    if python_found and not java_found:
        return "python", matches["python"]
    if java_found and python_found:
        return None, matches["java"] + matches["python"]
    return None, []


def parse_repo_from_remote(url: str) -> tuple[str | None, str | None]:
    match = GIT_REMOTE_RE.search(url)
    if not match:
        return None, None
    return match.group("owner"), match.group("repo")


def get_git_remote(repo_path: Path) -> str | None:
    try:
        output = subprocess.check_output(
            ["git", "-C", str(repo_path), "config", "--get", "remote.origin.url"],
            stderr=subprocess.DEVNULL,
            text=True,
        )
        return output.strip() or None
    except (subprocess.CalledProcessError, FileNotFoundError):
        return None


def get_git_branch(repo_path: Path) -> str | None:
    try:
        output = subprocess.check_output(
            ["git", "-C", str(repo_path), "symbolic-ref", "--short", "HEAD"],
            stderr=subprocess.DEVNULL,
            text=True,
        )
        return output.strip() or None
    except (subprocess.CalledProcessError, FileNotFoundError):
        return None


def build_repo_config(
    language: str,
    owner: str,
    name: str,
    branch: str,
    subdir: str | None = None,
) -> dict[str, Any]:
    template_path = hub_root() / "templates" / "repo" / ".ci-hub.yml"
    base = read_yaml(template_path)

    repo_block = base.get("repo", {}) if isinstance(base.get("repo"), dict) else {}
    repo_block["owner"] = owner
    repo_block["name"] = name
    repo_block["language"] = language
    repo_block["default_branch"] = branch
    repo_block.setdefault("dispatch_workflow", "hub-ci.yml")
    if subdir:
        repo_block["subdir"] = subdir
    base["repo"] = repo_block

    base["language"] = language

    if language == "java":
        base.pop("python", None)
    elif language == "python":
        base.pop("java", None)

    base.setdefault("version", "1.0")
    return base


def render_caller_workflow(language: str) -> str:
    templates_dir = hub_root() / "templates" / "repo"
    if language == "java":
        template_path = templates_dir / "hub-java-ci.yml"
        replacement = "hub-java-ci.yml"
    else:
        template_path = templates_dir / "hub-python-ci.yml"
        replacement = "hub-python-ci.yml"

    content = template_path.read_text(encoding="utf-8")
    content = content.replace(replacement, "hub-ci.yml")
    header = "# Generated by cihub init - DO NOT EDIT\n"
    return header + content


def validate_config(config: dict[str, Any]) -> list[str]:
    schema_path = hub_root() / "schema" / "ci-hub-config.schema.json"
    schema = json.loads(schema_path.read_text(encoding="utf-8"))
    validator = Draft7Validator(schema)
    errors = []
    for err in validator.iter_errors(config):
        path = ".".join([str(p) for p in err.path]) or "<root>"
        errors.append(f"{path}: {err.message}")
    return sorted(errors)


def resolve_language(repo_path: Path, override: str | None) -> tuple[str, list[str]]:
    if override:
        return override, []
    detected, reasons = detect_language(repo_path)
    if not detected:
        reason_text = ", ".join(reasons) if reasons else "no language markers found"
        raise ValueError(f"Unable to detect language ({reason_text}); use --language.")
    return detected, reasons


def cmd_detect(args: argparse.Namespace) -> int:
    repo_path = Path(args.repo).resolve()
    language, reasons = resolve_language(repo_path, args.language)
    payload: dict[str, Any] = {"language": language}
    if args.explain:
        payload["reasons"] = reasons
    print(json.dumps(payload, indent=2))
    return 0


def cmd_init(args: argparse.Namespace) -> int:
    repo_path = Path(args.repo).resolve()
    language, _ = resolve_language(repo_path, args.language)

    owner = args.owner or ""
    name = args.name or ""
    if not owner or not name:
        remote = get_git_remote(repo_path)
        if remote:
            git_owner, git_name = parse_repo_from_remote(remote)
            owner = owner or (git_owner or "")
            name = name or (git_name or "")

    if not name:
        name = repo_path.name
    if not owner:
        owner = "unknown"
        print("Warning: could not detect repo owner; set repo.owner manually.", file=sys.stderr)

    branch = args.branch or get_git_branch(repo_path) or "main"

    subdir = args.subdir or ""
    config = build_repo_config(language, owner, name, branch, subdir=subdir)
    config_path = repo_path / ".ci-hub.yml"
    write_yaml(config_path, config, args.dry_run)

    workflow_path = repo_path / ".github" / "workflows" / "hub-ci.yml"
    workflow_content = render_caller_workflow(language)
    write_text(workflow_path, workflow_content, args.dry_run)

    return 0


def cmd_update(args: argparse.Namespace) -> int:
    repo_path = Path(args.repo).resolve()
    config_path = repo_path / ".ci-hub.yml"
    existing = read_yaml(config_path) if config_path.exists() else {}

    language = args.language or existing.get("language")
    if not language:
        language, _ = resolve_language(repo_path, None)

    owner = args.owner or existing.get("repo", {}).get("owner", "")
    name = args.name or existing.get("repo", {}).get("name", "")
    repo_existing = existing.get("repo", {}) if isinstance(existing.get("repo"), dict) else {}
    branch = args.branch or repo_existing.get("default_branch", "main")
    subdir = args.subdir or repo_existing.get("subdir")

    if not name:
        name = repo_path.name
    if not owner:
        owner = "unknown"
        print("Warning: could not detect repo owner; set repo.owner manually.", file=sys.stderr)

    base = build_repo_config(language, owner, name, branch, subdir=subdir)
    merged = deep_merge(base, existing)
    write_yaml(config_path, merged, args.dry_run)

    workflow_path = repo_path / ".github" / "workflows" / "hub-ci.yml"
    workflow_content = render_caller_workflow(language)
    write_text(workflow_path, workflow_content, args.dry_run)
    return 0


def cmd_validate(args: argparse.Namespace) -> int:
    repo_path = Path(args.repo).resolve()
    config_path = repo_path / ".ci-hub.yml"
    if not config_path.exists():
        print(f"Config not found: {config_path}", file=sys.stderr)
        return 2
    config = read_yaml(config_path)
    errors = validate_config(config)
    if errors:
        print("Validation failed:")
        for err in errors:
            print(f"  - {err}")
        return 1
    print("Config OK")
    return 0


def get_connected_repos(
    only_dispatch_enabled: bool = True,
    language_filter: str | None = None,
) -> list[str]:
    """Get unique repos from hub config/repos/*.yaml.

    Args:
        only_dispatch_enabled: If True, skip repos with dispatch_enabled=False
        language_filter: If set, only return repos with this language (java/python)
    """
    repos_dir = hub_root() / "config" / "repos"
    seen: set[str] = set()
    repos: list[str] = []
    for cfg_file in repos_dir.glob("*.yaml"):
        if cfg_file.name.endswith(".disabled"):
            continue
        try:
            data = read_yaml(cfg_file)
            repo = data.get("repo", {})
            if only_dispatch_enabled and repo.get("dispatch_enabled", True) is False:
                continue
            if language_filter:
                repo_lang = repo.get("language", "")
                if repo_lang != language_filter:
                    continue
            owner = repo.get("owner", "")
            name = repo.get("name", "")
            if owner and name:
                full = f"{owner}/{name}"
                if full not in seen:
                    seen.add(full)
                    repos.append(full)
        except Exception:
            pass
    return repos


def get_repo_entries(
    only_dispatch_enabled: bool = True,
) -> list[dict[str, str]]:
    """Return repo metadata from config/repos/*.yaml."""
    repos_dir = hub_root() / "config" / "repos"
    entries: list[dict[str, str]] = []
    seen: set[str] = set()
    for cfg_file in repos_dir.glob("*.yaml"):
        if cfg_file.name.endswith(".disabled"):
            continue
        try:
            data = read_yaml(cfg_file)
            repo = data.get("repo", {})
            if only_dispatch_enabled and repo.get("dispatch_enabled", True) is False:
                continue
            owner = repo.get("owner", "")
            name = repo.get("name", "")
            if not owner or not name:
                continue
            full = f"{owner}/{name}"
            if full in seen:
                continue
            seen.add(full)
            entries.append(
                {
                    "full": full,
                    "language": repo.get("language", ""),
                    "dispatch_workflow": repo.get("dispatch_workflow", "hub-ci.yml"),
                    "default_branch": repo.get("default_branch", "main"),
                }
            )
        except Exception:
            continue
    return entries


def render_dispatch_workflow(language: str, dispatch_workflow: str) -> str:
    templates_dir = hub_root() / "templates" / "repo"
    if dispatch_workflow == "hub-ci.yml":
        if not language:
            raise ValueError("language is required for hub-ci.yml rendering")
        return render_caller_workflow(language)
    if dispatch_workflow == "hub-java-ci.yml":
        return (templates_dir / "hub-java-ci.yml").read_text(encoding="utf-8")
    if dispatch_workflow == "hub-python-ci.yml":
        return (templates_dir / "hub-python-ci.yml").read_text(encoding="utf-8")
    raise ValueError(f"Unsupported dispatch_workflow: {dispatch_workflow}")


def gh_api_json(
    path: str, method: str = "GET", payload: dict[str, Any] | None = None
) -> dict[str, Any]:
    cmd = ["gh", "api"]
    if method != "GET":
        cmd += ["-X", method]
    cmd.append(path)
    input_data = None
    if payload is not None:
        cmd += ["--input", "-"]
        input_data = json.dumps(payload)
    result = subprocess.run(
        cmd,
        input=input_data,
        capture_output=True,
        text=True,
    )
    if result.returncode != 0:
        msg = result.stderr.strip() or result.stdout.strip()
        raise RuntimeError(msg or "gh api failed")
    if not result.stdout.strip():
        return {}
    return json.loads(result.stdout)


def fetch_remote_file(repo: str, path: str, branch: str) -> dict[str, str] | None:
    api_path = f"/repos/{repo}/contents/{path}?ref={branch}"
    try:
        data = gh_api_json(api_path)
    except RuntimeError as exc:
        msg = str(exc)
        if "Not Found" in msg or "404" in msg:
            return None
        raise
    if "content" not in data or "sha" not in data:
        return None
    content = base64.b64decode(data["content"]).decode("utf-8")
    return {"sha": data["sha"], "content": content}


def update_remote_file(
    repo: str,
    path: str,
    branch: str,
    content: str,
    message: str,
    sha: str | None = None,
) -> None:
    payload: dict[str, Any] = {
        "message": message,
        "content": base64.b64encode(content.encode("utf-8")).decode("utf-8"),
        "branch": branch,
    }
    if sha:
        payload["sha"] = sha
    gh_api_json(f"/repos/{repo}/contents/{path}", method="PUT", payload=payload)


def cmd_setup_secrets(args: argparse.Namespace) -> int:
    """Set HUB_DISPATCH_TOKEN on hub and optionally all connected repos."""
    import getpass
    import urllib.error
    import urllib.request

    hub_repo = args.hub_repo
    token = args.token

    if not token:
        token = getpass.getpass("Enter GitHub PAT: ")

    token = token.strip()

    if not token:
        print("Error: No token provided", file=sys.stderr)
        return 1

    if any(ch.isspace() for ch in token):
        print("Error: Token contains whitespace; paste the raw token value.", file=sys.stderr)
        return 1

    def verify_token(pat: str) -> tuple[bool, str]:
        req = urllib.request.Request(
            "https://api.github.com/user",
            headers={
                "Authorization": f"token {pat}",
                "Accept": "application/vnd.github+json",
                "User-Agent": "cihub",
            },
        )
        try:
            with urllib.request.urlopen(req, timeout=10) as resp:
                data = json.loads(resp.read().decode("utf-8"))
                scopes = resp.headers.get("X-OAuth-Scopes", "")
        except urllib.error.HTTPError as exc:
            if exc.code == 401:
                return False, "unauthorized (token invalid or expired)"
            return False, f"HTTP {exc.code} {exc.reason}"
        except Exception as exc:
            return False, str(exc)

        login = data.get("login", "unknown")
        scope_msg = f"scopes: {scopes}" if scopes else "scopes: (not reported)"
        return True, f"user {login} ({scope_msg})"

    def verify_cross_repo_access(pat: str, target_repo: str) -> tuple[bool, str]:
        """Verify token can access another repo's artifacts (required for orchestrator)."""
        req = urllib.request.Request(
            f"https://api.github.com/repos/{target_repo}/actions/artifacts",
            headers={
                "Authorization": f"token {pat}",
                "Accept": "application/vnd.github+json",
                "User-Agent": "cihub",
            },
        )
        try:
            with urllib.request.urlopen(req, timeout=10) as resp:
                data = json.loads(resp.read().decode("utf-8"))
                count = data.get("total_count", 0)
                return True, f"{count} artifacts accessible"
        except urllib.error.HTTPError as exc:
            if exc.code == 404:
                return False, f"repo not found or no access: {target_repo}"
            if exc.code == 401:
                return False, "token cannot access this repo (needs 'repo' scope)"
            return False, f"HTTP {exc.code} {exc.reason}"
        except Exception as exc:
            return False, str(exc)

    if args.verify:
        ok, message = verify_token(token)
        if not ok:
            print(f"Token verification failed: {message}", file=sys.stderr)
            return 1
        print(f"Token verified: {message}")

        # Also verify cross-repo access on connected repos
        connected = get_connected_repos()
        if connected:
            test_repo = connected[0]
            ok, message = verify_cross_repo_access(token, test_repo)
            if not ok:
                print(f"Cross-repo access failed for {test_repo}: {message}", file=sys.stderr)
                print("The token needs 'repo' scope to access other repos' artifacts.", file=sys.stderr)
                return 1
            print(f"Cross-repo access verified: {test_repo} ({message})")

    def set_secret(repo: str) -> tuple[bool, str]:
        result = subprocess.run(
            ["gh", "secret", "set", "HUB_DISPATCH_TOKEN", "-R", repo],
            input=token,
            capture_output=True,
            text=True,
        )
        if result.returncode != 0:
            return False, result.stderr.strip()
        return True, ""

    # Set on hub repo
    print(f"Setting HUB_DISPATCH_TOKEN on {hub_repo}...")
    ok, error = set_secret(hub_repo)
    if not ok:
        print(f"Failed: {error}", file=sys.stderr)
        return 1
    print(f"  ✅ {hub_repo}")

    if args.all:
        print("\nSetting on connected repos...")
        repos = get_connected_repos()
        for repo in repos:
            if repo == hub_repo:
                continue
            ok, error = set_secret(repo)
            if ok:
                print(f"  ✅ {repo}")
            else:
                suffix = " (no admin access)"
                if error:
                    suffix = f" ({error})"
                print(f"  ❌ {repo}{suffix}")

    print("\nConnected dispatch-enabled repos:")
    for repo in get_connected_repos():
        print(f"  - {repo}")
    print("\nEnsure PAT has 'repo' scope (classic) or Actions R/W (fine-grained) on all repos.")
    return 0


def cmd_setup_nvd(args: argparse.Namespace) -> int:
    """Set NVD_API_KEY on Java repos for OWASP Dependency Check."""
    import getpass
    import urllib.error
    import urllib.request

    nvd_key = args.nvd_key

    if not nvd_key:
        print("NVD API Key is required for fast OWASP Dependency Check scans.")
        print("Get a free key at: https://nvd.nist.gov/developers/request-an-api-key")
        print()
        nvd_key = getpass.getpass("Enter NVD API Key: ")

    nvd_key = nvd_key.strip()

    if not nvd_key:
        print("Error: No NVD API key provided", file=sys.stderr)
        return 1

    if any(ch.isspace() for ch in nvd_key):
        print("Error: Key contains whitespace; paste the raw key value.", file=sys.stderr)
        return 1

    def verify_nvd_key(key: str) -> tuple[bool, str]:
        """Verify NVD API key by making a test request."""
        # NVD API test - fetch a known CVE
        test_url = "https://services.nvd.nist.gov/rest/json/cves/2.0?cveId=CVE-2021-44228"
        req = urllib.request.Request(
            test_url,
            headers={
                "apiKey": key,
                "User-Agent": "cihub",
            },
        )
        try:
            with urllib.request.urlopen(req, timeout=15) as resp:
                if resp.status == 200:
                    return True, "NVD API key is valid"
        except urllib.error.HTTPError as exc:
            if exc.code == 403:
                return False, "invalid or expired API key"
            if exc.code == 404:
                return True, "API key accepted (test CVE not found)"
            return False, f"HTTP {exc.code} {exc.reason}"
        except Exception as exc:
            return False, str(exc)
        return True, "API key accepted"

    if args.verify:
        print("Verifying NVD API key...")
        ok, message = verify_nvd_key(nvd_key)
        if not ok:
            print(f"NVD API key verification failed: {message}", file=sys.stderr)
            return 1
        print(f"NVD API key verified: {message}")

    def set_secret(repo: str, secret_name: str, secret_value: str) -> tuple[bool, str]:
        result = subprocess.run(
            ["gh", "secret", "set", secret_name, "-R", repo],
            input=secret_value,
            capture_output=True,
            text=True,
        )
        if result.returncode != 0:
            return False, result.stderr.strip()
        return True, ""

    # Get Java repos
    java_repos = get_connected_repos(only_dispatch_enabled=False, language_filter="java")

    if not java_repos:
        print("No Java repos found in config/repos/*.yaml")
        print("NVD_API_KEY is only needed for Java repos (OWASP Dependency Check).")
        return 0

    print(f"\nSetting NVD_API_KEY on {len(java_repos)} Java repo(s)...")
    success_count = 0
    for repo in java_repos:
        ok, error = set_secret(repo, "NVD_API_KEY", nvd_key)
        if ok:
            print(f"  ✅ {repo}")
            success_count += 1
        else:
            suffix = " (no admin access)" if not error else f" ({error})"
            print(f"  ❌ {repo}{suffix}")

    print(f"\nSet NVD_API_KEY on {success_count}/{len(java_repos)} Java repos.")
    if success_count < len(java_repos):
        print("For repos you don't have admin access to, set the secret manually:")
        print("  gh secret set NVD_API_KEY -R owner/repo")
    return 0


def cmd_sync_templates(args: argparse.Namespace) -> int:
    """Sync caller workflow templates to target repos."""
    entries = get_repo_entries(only_dispatch_enabled=not args.include_disabled)
    if args.repo:
        repo_map = {entry["full"]: entry for entry in entries}
        missing = [repo for repo in args.repo if repo not in repo_map]
        if missing:
            print(
                "Error: repos not found in config/repos/*.yaml: "
                + ", ".join(missing),
                file=sys.stderr,
            )
            return 2
        entries = [repo_map[repo] for repo in args.repo]

    if not entries:
        print("No repos found to sync.")
        return 0

    failures = 0
    for entry in entries:
        repo = entry["full"]
        language = entry.get("language", "")
        dispatch_workflow = entry.get("dispatch_workflow", "hub-ci.yml")
        branch = entry.get("default_branch", "main") or "main"
        path = f".github/workflows/{dispatch_workflow}"

        try:
            desired = render_dispatch_workflow(language, dispatch_workflow)
        except ValueError as exc:
            print(f"Error: {repo} {path}: {exc}", file=sys.stderr)
            failures += 1
            continue

        remote = fetch_remote_file(repo, path, branch)
        if remote and remote.get("content") == desired:
            print(f"✅ {repo} {path} up to date")
            continue

        if args.check:
            print(f"❌ {repo} {path} out of date")
            failures += 1
            continue

        if args.dry_run:
            print(f"# Would update {repo} {path}")
            continue

        try:
            update_remote_file(
                repo,
                path,
                branch,
                desired,
                args.commit_message,
                remote.get("sha") if remote else None,
            )
            print(f"✅ {repo} {path} updated")
        except RuntimeError as exc:
            print(f"❌ {repo} {path} update failed: {exc}", file=sys.stderr)
            failures += 1

    if args.check and failures:
        print(f"Template drift detected in {failures} repo(s).", file=sys.stderr)
        return 1
    if failures:
        return 1
    return 0


def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(prog="cihub", description="CI/CD Hub CLI")
    parser.add_argument("--version", action="version", version=f"cihub {__version__}")
    subparsers = parser.add_subparsers(dest="command", required=True)

    detect = subparsers.add_parser("detect", help="Detect repo language and tools")
    detect.add_argument("--repo", required=True, help="Path to repo")
    detect.add_argument("--language", choices=["java", "python"], help="Override detection")
    detect.add_argument("--explain", action="store_true", help="Show detection reasons")
    detect.set_defaults(func=cmd_detect)

    init = subparsers.add_parser("init", help="Generate .ci-hub.yml and hub-ci.yml")
    init.add_argument("--repo", required=True, help="Path to repo")
    init.add_argument("--language", choices=["java", "python"], help="Override detection")
    init.add_argument("--owner", help="Repo owner (GitHub user/org)")
    init.add_argument("--name", help="Repo name")
    init.add_argument("--branch", help="Default branch (e.g., main)")
    init.add_argument("--subdir", help="Subdirectory for monorepos (repo.subdir)")
    init.add_argument("--workdir", dest="subdir", help="Alias for --subdir")
    init.add_argument("--dry-run", action="store_true", help="Print output instead of writing")
    init.set_defaults(func=cmd_init)

    update = subparsers.add_parser("update", help="Refresh hub-ci.yml and .ci-hub.yml")
    update.add_argument("--repo", required=True, help="Path to repo")
    update.add_argument("--language", choices=["java", "python"], help="Override detection")
    update.add_argument("--owner", help="Repo owner (GitHub user/org)")
    update.add_argument("--name", help="Repo name")
    update.add_argument("--branch", help="Default branch (e.g., main)")
    update.add_argument("--subdir", help="Subdirectory for monorepos (repo.subdir)")
    update.add_argument("--workdir", dest="subdir", help="Alias for --subdir")
    update.add_argument("--dry-run", action="store_true", help="Print output instead of writing")
    update.set_defaults(func=cmd_update)

    validate = subparsers.add_parser("validate", help="Validate .ci-hub.yml against schema")
    validate.add_argument("--repo", required=True, help="Path to repo")
    validate.set_defaults(func=cmd_validate)

    setup_secrets = subparsers.add_parser(
        "setup-secrets", help="Set HUB_DISPATCH_TOKEN on hub and connected repos"
    )
    setup_secrets.add_argument(
        "--hub-repo",
        default="jguida941/ci-cd-hub",
        help="Hub repository (default: jguida941/ci-cd-hub)",
    )
    setup_secrets.add_argument("--token", help="GitHub PAT (prompts if not provided)")
    setup_secrets.add_argument(
        "--all", action="store_true", help="Also set on all connected repos"
    )
    setup_secrets.add_argument(
        "--verify",
        action="store_true",
        help="Verify token with GitHub API before setting secrets",
    )
    setup_secrets.set_defaults(func=cmd_setup_secrets)

    setup_nvd = subparsers.add_parser(
        "setup-nvd", help="Set NVD_API_KEY on Java repos for OWASP Dependency Check"
    )
    setup_nvd.add_argument(
        "--nvd-key", help="NVD API key (prompts if not provided)"
    )
    setup_nvd.add_argument(
        "--verify",
        action="store_true",
        help="Verify NVD API key before setting secrets",
    )
    setup_nvd.set_defaults(func=cmd_setup_nvd)

    sync_templates = subparsers.add_parser(
        "sync-templates",
        help="Sync caller workflow templates to dispatch-enabled repos",
    )
    sync_templates.add_argument(
        "--repo",
        action="append",
        help="Target repo (owner/name). Repeatable.",
    )
    sync_templates.add_argument(
        "--include-disabled",
        action="store_true",
        help="Include repos with dispatch_enabled=false",
    )
    sync_templates.add_argument(
        "--check",
        action="store_true",
        help="Check for template drift without updating",
    )
    sync_templates.add_argument(
        "--dry-run",
        action="store_true",
        help="Show updates without writing",
    )
    sync_templates.add_argument(
        "--commit-message",
        default="chore: sync hub templates",
        help="Commit message for synced templates",
    )
    sync_templates.set_defaults(func=cmd_sync_templates)

    return parser


def main(argv: list[str] | None = None) -> int:
    parser = build_parser()
    args = parser.parse_args(argv)
    return args.func(args)


if __name__ == "__main__":
    raise SystemExit(main())
