# ============================================================================
# CI/CD Hub - Central Test Runner
# ============================================================================
# This is the TRUE hub workflow - it clones and tests ALL your repos directly.
# Target repos DO NOT need any workflow files - the hub does everything.
#
# How it works:
#   1. Reads config/repos/*.yaml to get repo list
#   2. Clones each repo
#   3. Detects language (Java/Python)
#   4. Runs ALL quality tools
#   5. Generates beautiful reports
#   6. Stores all artifacts centrally
# ============================================================================

name: "Hub: Run All Repos"

on:
  workflow_dispatch:
    inputs:
      repos:
        description: 'Specific repos (comma-separated, empty=all)'
        required: false
        type: string
      run_group:
        description: 'Run group filter (full, smoke, fixtures, or comma-separated)'
        required: false
        type: string
      skip_mutation:
        description: 'Skip mutation testing (faster)'
        required: false
        type: boolean
        default: false

  schedule:
    # Run nightly at 2 AM UTC
    - cron: '0 2 * * *'

  push:
    branches: [main, master]
    paths:
      - 'config/repos/*.yaml'

# Required permissions for all features
permissions:
  contents: read
  security-events: write  # For CodeQL
  actions: read

env:
  REPORTS_DIR: ${{ github.workspace }}/all-reports

jobs:
  # ============================================================================
  # Discover Repos
  # ============================================================================
  discover:
    name: Discover Repositories
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.repos.outputs.matrix }}
      count: ${{ steps.repos.outputs.count }}

    steps:
      - name: Checkout Hub
uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4
        with:
          persist-credentials: false

      - name: Set up Python
uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5
        with:
          python-version: '3.12'

      - name: Install Config Dependencies
        run: pip install pyyaml jsonschema

      - name: Build Repo Matrix
        id: repos
        run: |
          python <<'PY'
          import json
          import os
          from pathlib import Path

          from scripts.load_config import (
              ConfigValidationError,
              generate_workflow_inputs,
              load_config,
          )

          hub_root = Path(".")
          repos_dir = hub_root / "config" / "repos"

          run_group_filter = os.environ.get("INPUT_RUN_GROUP", "").strip()
          filter_groups = [g.strip() for g in run_group_filter.split(",") if g.strip()]

          repo_filter = os.environ.get("INPUT_REPOS", "").strip()
          filter_repos = [r.strip() for r in repo_filter.split(",") if r.strip()]

          entries: list[dict[str, object]] = []

          for config_file in sorted(repos_dir.glob("*.yaml")):
              repo_basename = config_file.stem
              try:
                  cfg = load_config(
                      repo_name=repo_basename,
                      hub_root=hub_root,
                      exit_on_validation_error=False,
                  )
              except ConfigValidationError as exc:
                  print(
                      f"::warning::Skipping {config_file}: validation failed ({exc})"
                  )
                  continue
              except SystemExit:
                  print(f"::warning::Skipping {config_file}: validation aborted")
                  continue
              except Exception as exc:
                  print(f"::warning::Skipping {config_file}: failed to load ({exc})")
                  continue

              repo_info = cfg.get("repo", {})
              owner = repo_info.get("owner")
              name = repo_info.get("name") or repo_basename
              language = repo_info.get("language") or cfg.get("language")

              if not (owner and name and language):
                  print(
                      f"::warning::Skipping {config_file}: missing repo.owner/name/language"
                  )
                  continue

              if filter_repos:
                  full_name = f"{owner}/{name}" if owner and name else name
                  if (
                      name not in filter_repos
                      and full_name not in filter_repos
                      and repo_basename not in filter_repos
                  ):
                      continue

              run_group = repo_info.get("run_group") or cfg.get("run_group") or "full"
              if filter_groups and run_group not in filter_groups:
                  continue

              inputs = generate_workflow_inputs(cfg)

              entry: dict[str, object] = {
                  "config_basename": repo_basename,
                  "name": name,
                  "owner": owner,
                  "language": language,
                  "branch": repo_info.get("default_branch", "main"),
                  "subdir": repo_info.get("subdir", ""),
                  "run_group": run_group,
              }

              # Java tool flags (including use_nvd_api_key for OWASP)
              for key in (
                  "run_jacoco",
                  "run_checkstyle",
                  "run_spotbugs",
                  "run_owasp",
                  "use_nvd_api_key",
                  "run_pitest",
                  "run_jqwik",
                  "run_pmd",
                  "run_semgrep",
                  "run_trivy",
                  "run_codeql",
                  "run_docker",
              ):
                  if key in inputs:
                      entry[key] = inputs[key]

              # Python tool flags
              for key in (
                  "run_pytest",
                  "run_ruff",
                  "run_bandit",
                  "run_pip_audit",
                  "run_mypy",
                  "run_black",
                  "run_isort",
                  "run_mutmut",
                  "run_hypothesis",
                  "run_semgrep",
                  "run_trivy",
                  "run_codeql",
                  "run_docker",
              ):
                  if key in inputs:
                      entry[key] = inputs[key]

              # Environment settings (version, retention, build tool)
              for key in (
                  "java_version",
                  "python_version",
                  "retention_days",
                  "build_tool",
              ):
                  if key in inputs:
                      entry[key] = inputs[key]

              entries.append(entry)

          matrix = {"include": entries}

          with open(os.environ["GITHUB_OUTPUT"], "a", encoding="utf-8") as handle:
              handle.write(f"matrix={json.dumps(matrix)}\n")
              handle.write(f"count={len(entries)}\n")

          print(f"Found {len(entries)} repositories")
          for entry in entries:
              print(
                  f"- {entry['owner']}/{entry['name']} ({entry['language']}) run_group={entry.get('run_group', 'full')}"
              )

          if not entries:
              raise SystemExit("No repositories found after filtering.")
          PY
        env:
          INPUT_REPOS: ${{ inputs.repos }}
          INPUT_RUN_GROUP: ${{ inputs.run_group }}

      - name: Verify matrix key coverage
        run: python scripts/verify_hub_matrix_keys.py

  # ============================================================================
  # Run CI for Each Repo
  # ============================================================================
  test-repo:
    name: "Test: ${{ matrix.config_basename }} (${{ matrix.owner }}/${{ matrix.name }}${{ matrix.subdir != '' && format(':{0}', matrix.subdir) || '' }})"
    runs-on: ubuntu-latest
    needs: discover
    if: needs.discover.outputs.count > 0
    strategy:
      fail-fast: false
      max-parallel: 3
      matrix: ${{ fromJson(needs.discover.outputs.matrix) }}
    env:
      # Always 'repo' - the subdirectory step moves subdir content to repo/
      WORKDIR: repo

    steps:
      - name: Checkout Hub (for scripts)
uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4
        with:
          path: hub
          persist-credentials: false

      - name: Checkout Target Repo
uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4
        with:
          repository: ${{ matrix.owner }}/${{ matrix.name }}
          ref: ${{ matrix.branch }}
          path: repo
          persist-credentials: false

      - name: Use subdirectory if provided
        if: matrix.subdir != ''
        env:
          # Pass subdir via env var to prevent shell injection
          SUBDIR: ${{ matrix.subdir }}
        run: |
          # Validate subdir to prevent path traversal attacks
          if [[ "$SUBDIR" == *".."* ]]; then
            echo "Error: subdir contains path traversal sequence '..'" >&2
            exit 1
          fi
          if [[ "$SUBDIR" == /* ]]; then
            echo "Error: subdir must be a relative path" >&2
            exit 1
          fi
          if [ ! -d "repo/$SUBDIR" ]; then
            echo "Subdir repo/$SUBDIR not found" >&2
            exit 1
          fi
          mv "repo/$SUBDIR" repo_subdir
          rm -rf repo
          mv repo_subdir repo

      - name: Create Reports Directory
        run: mkdir -p reports

      # ========================================
      # JAVA SETUP & TOOLS
      # ========================================
      - name: Set up JDK ${{ matrix.java_version }}
        if: matrix.language == 'java'
uses: actions/setup-java@c1e323688fd81a25caa38c78aa6df2d33d3e20d9 # v4
        with:
          java-version: '${{ matrix.java_version }}'
          distribution: 'temurin'
          cache: '${{ matrix.build_tool }}'

      - name: "[Java] Build & Test"
        if: matrix.language == 'java'
        id: java-build
        working-directory: ${{ env.WORKDIR }}
        run: |
          if [ -f "mvnw" ]; then
            chmod +x mvnw
            ./mvnw -B -ntp verify -Dmaven.test.failure.ignore=true
          elif [ -f "pom.xml" ]; then
            mvn -B -ntp verify -Dmaven.test.failure.ignore=true
          fi
        continue-on-error: true

      - name: "[Java] Extract Test Results"
        if: matrix.language == 'java'
        id: java-tests
        working-directory: ${{ env.WORKDIR }}
        run: |
          TOTAL=0; PASSED=0; FAILED=0; SKIPPED=0; RUNTIME=0

          while IFS= read -r -d '' report; do
            T=$(grep -oP 'tests="\K[0-9]+' "$report" 2>/dev/null | head -1 || echo 0)
            F=$(grep -oP 'failures="\K[0-9]+' "$report" 2>/dev/null | head -1 || echo 0)
            E=$(grep -oP 'errors="\K[0-9]+' "$report" 2>/dev/null | head -1 || echo 0)
            S=$(grep -oP 'skipped="\K[0-9]+' "$report" 2>/dev/null | head -1 || echo 0)
            TIME=$(grep -oP 'time="\K[0-9.]+' "$report" 2>/dev/null | head -1 || echo 0)
            TOTAL=$((TOTAL + T))
            FAILED=$((FAILED + F + E))
            SKIPPED=$((SKIPPED + S))
            RUNTIME=$(echo "$RUNTIME + $TIME" | bc 2>/dev/null || echo "$RUNTIME")
          done < <(find . -path "*/surefire-reports/*.xml" -o -path "*/failsafe-reports/*.xml" -print0 2>/dev/null)
          PASSED=$((TOTAL - FAILED - SKIPPED))

          {
            echo "total=$TOTAL"
            echo "passed=$PASSED"
            echo "failed=$FAILED"
            echo "skipped=$SKIPPED"
            echo "runtime=${RUNTIME}s"
          } >> "$GITHUB_OUTPUT"

      - name: "[Java] Extract Coverage"
        if: matrix.language == 'java' && matrix.run_jacoco == true
        id: java-coverage
        working-directory: ${{ env.WORKDIR }}
        run: |
          COVERED=0; MISSED=0; PERCENT=0

          JACOCO=$(find . -name "jacoco.xml" -path "*/site/*" 2>/dev/null | head -1)
          if [ -n "$JACOCO" ] && [ -f "$JACOCO" ]; then
            COVERED=$(grep -oP 'INSTRUCTION.*?covered="\K[0-9]+' "$JACOCO" 2>/dev/null | awk '{s+=$1} END {print s}' || echo 0)
            MISSED=$(grep -oP 'INSTRUCTION.*?missed="\K[0-9]+' "$JACOCO" 2>/dev/null | awk '{s+=$1} END {print s}' || echo 0)
            TOTAL=$((COVERED + MISSED))
            if [ "$TOTAL" -gt 0 ]; then
              PERCENT=$((COVERED * 100 / TOTAL))
            fi
          fi

          {
            echo "covered=$COVERED"
            echo "missed=$MISSED"
            echo "percent=$PERCENT"
            echo "lines=$COVERED / $((COVERED + MISSED))"
          } >> "$GITHUB_OUTPUT"

      - name: "[Java] Run PITest Mutation"
        if: matrix.language == 'java' && matrix.run_pitest == true && inputs.skip_mutation != true
        id: java-mutation
        working-directory: ${{ env.WORKDIR }}
        run: |
          KILLED=0; SURVIVED=0; SCORE=0

          # Identify ALL modules with PITest configured (search entire repo, not just modules/)
          MODULES=()

          # Search ALL pom.xml files in the repo for pitest-maven plugin
          while IFS= read -r pom_file; do
            if grep -q "pitest-maven" "$pom_file" 2>/dev/null; then
              MODULE_DIR=$(dirname "$pom_file")
              # Normalize path (remove leading ./)
              MODULE_DIR="${MODULE_DIR#./}"
              [ -z "$MODULE_DIR" ] && MODULE_DIR="."

              # Skip template directories (not real modules)
              if [[ "$MODULE_DIR" == *"template"* ]]; then
                echo "Skipping template directory: $MODULE_DIR"
                continue
              fi

              # Avoid duplicates
              found=false
              for existing in "${MODULES[@]}"; do
                if [ "$existing" = "$MODULE_DIR" ]; then
                  found=true
                  break
                fi
              done
              if [ "$found" = false ]; then
                MODULES+=("$MODULE_DIR")
              fi
            fi
          done < <(find . -name "pom.xml" -type f 2>/dev/null | grep -v target || true)

          echo "PITest modules detected: ${MODULES[*]:-none}"

          # Warn if no PITest modules found
          if [ ${#MODULES[@]} -eq 0 ]; then
            echo "::warning::No pom.xml files with pitest-maven plugin found. Ensure PITest is configured in your pom.xml."
          fi

          if [ ${#MODULES[@]} -eq 0 ]; then
            echo "No modules with PITest configuration found; skipping execution."
          else
            for mod in "${MODULES[@]}"; do
              if [ "$mod" = "." ]; then
                mvn -B -ntp org.pitest:pitest-maven:mutationCoverage || true
              else
                mvn -B -ntp -pl "$mod" -am org.pitest:pitest-maven:mutationCoverage || true
              fi
            done
          fi

          # Aggregate mutation results across all modules
          # Note: PITest uses single quotes in XML (status='KILLED'), so we match both quote styles
          # NO_COVERAGE mutations are code paths never executed during tests (count as not killed)
          echo "Searching for mutations.xml files..."
          MUTATION_FILES=$(find . -name "mutations.xml" 2>/dev/null | grep -v target/classes || true)
          echo "Found mutation files: $MUTATION_FILES"
          NO_COVERAGE=0

          for xml in $MUTATION_FILES; do
            K=$(grep -cE "status=['\"]KILLED['\"]" "$xml" 2>/dev/null || echo 0)
            S=$(grep -cE "status=['\"]SURVIVED['\"]" "$xml" 2>/dev/null || echo 0)
            N=$(grep -cE "status=['\"]NO_COVERAGE['\"]" "$xml" 2>/dev/null || echo 0)
            echo "  $xml: killed=$K, survived=$S, no_coverage=$N"
            KILLED=$((KILLED + K))
            SURVIVED=$((SURVIVED + S))
            NO_COVERAGE=$((NO_COVERAGE + N))
          done

          KILLED=${KILLED:-0}; SURVIVED=${SURVIVED:-0}; NO_COVERAGE=${NO_COVERAGE:-0}
          KNUM=$(printf '%s' "$KILLED" | tr -cd '0-9')
          SNUM=$(printf '%s' "$SURVIVED" | tr -cd '0-9')
          NNUM=$(printf '%s' "$NO_COVERAGE" | tr -cd '0-9')
          [ -z "$KNUM" ] && KNUM=0
          [ -z "$SNUM" ] && SNUM=0
          [ -z "$NNUM" ] && NNUM=0
          TOTAL=$((KNUM + SNUM + NNUM))
          if [ "$TOTAL" -gt 0 ]; then
            SCORE=$((KNUM * 100 / TOTAL))
          fi

          echo "Mutation Score: $SCORE% (Killed: $KNUM, Survived: $SNUM, No Coverage: $NNUM, Total: $TOTAL)"
          {
            echo "killed=$KNUM"
            echo "survived=$SNUM"
            echo "no_coverage=$NNUM"
            echo "score=${SCORE:-0}"
          } >> "$GITHUB_OUTPUT"
        continue-on-error: true

      - name: "[Java] OWASP Dependency Check"
        if: matrix.language == 'java' && matrix.run_owasp == true
        id: java-owasp
        working-directory: ${{ env.WORKDIR }}
        env:
          NVD_API_KEY: ${{ secrets.NVD_API_KEY }}
          USE_NVD_API_KEY: ${{ matrix.use_nvd_api_key }}
        run: |
          CRITICAL=0; HIGH=0; MEDIUM=0; LOW=0

          # Build NVD API key flag if enabled and secret is set
          if [ -z "$USE_NVD_API_KEY" ]; then
            USE_NVD_API_KEY="true"
          fi
          NVD_FLAGS=""
          if [ "$USE_NVD_API_KEY" = "true" ] && [ -n "$NVD_API_KEY" ]; then
            NVD_FLAGS="-DnvdApiKey=$NVD_API_KEY"
            echo "NVD API key configured - using accelerated vulnerability updates"
          elif [ "$USE_NVD_API_KEY" = "true" ]; then
            echo "Warning: NVD API key enabled but secret not set - vulnerability updates will be slow"
          else
            echo "NVD API key disabled via config"
          fi

          DC_FLAGS="-DnvdApiDelay=2500 -DnvdMaxRetryCount=10 -Ddependencycheck.failOnError=false"

          if [ -f "mvnw" ]; then
            # shellcheck disable=SC2086
            ./mvnw -B -ntp org.owasp:dependency-check-maven:check $NVD_FLAGS $DC_FLAGS -DfailBuildOnCVSS=11 2>/dev/null || true
          else
            # shellcheck disable=SC2086
            mvn -B -ntp org.owasp:dependency-check-maven:check $NVD_FLAGS $DC_FLAGS -DfailBuildOnCVSS=11 2>/dev/null || true
          fi

          REPORT=$(find . -name "dependency-check-report.json" 2>/dev/null | head -1)
          if [ -n "$REPORT" ] && [ -f "$REPORT" ]; then
            CRITICAL=$(jq '[.dependencies[]?.vulnerabilities[]? | select(.severity == "CRITICAL")] | length' "$REPORT" 2>/dev/null || echo 0)
            HIGH=$(jq '[.dependencies[]?.vulnerabilities[]? | select(.severity == "HIGH")] | length' "$REPORT" 2>/dev/null || echo 0)
            MEDIUM=$(jq '[.dependencies[]?.vulnerabilities[]? | select(.severity == "MEDIUM")] | length' "$REPORT" 2>/dev/null || echo 0)
            LOW=$(jq '[.dependencies[]?.vulnerabilities[]? | select(.severity == "LOW")] | length' "$REPORT" 2>/dev/null || echo 0)
          fi

          {
            echo "critical=$CRITICAL"
            echo "high=$HIGH"
            echo "medium=$MEDIUM"
            echo "low=$LOW"
          } >> "$GITHUB_OUTPUT"
        continue-on-error: true

      - name: "[Java] SpotBugs"
        if: matrix.language == 'java' && matrix.run_spotbugs == true
        id: java-spotbugs
        working-directory: ${{ env.WORKDIR }}
        run: |
          BUGS=0

          if [ -f "mvnw" ]; then
            ./mvnw -B -ntp spotbugs:spotbugs 2>&1 || true
          else
            mvn -B -ntp spotbugs:spotbugs 2>&1 || true
          fi

          while IFS= read -r -d '' xml; do
            COUNT=$(grep -c "<BugInstance" "$xml" 2>/dev/null || echo 0)
            BUGS=$((BUGS + COUNT))
          done < <(find . -name "spotbugsXml.xml" -print0 2>/dev/null)

          echo "count=$BUGS" >> "$GITHUB_OUTPUT"
        continue-on-error: true

      - name: "[Java] Checkstyle"
        if: matrix.language == 'java' && matrix.run_checkstyle == true
        id: java-checkstyle
        working-directory: ${{ env.WORKDIR }}
        run: |
          VIOLATIONS=0

          # Use checkstyle:checkstyle to generate full XML report (not :check which only counts errors)
          if [ -f "mvnw" ]; then
            ./mvnw -B -ntp -DskipTests checkstyle:checkstyle 2>&1 | tee checkstyle-output.txt || true
          else
            mvn -B -ntp -DskipTests checkstyle:checkstyle 2>&1 | tee checkstyle-output.txt || true
          fi

          # Count all issues from XML reports (includes both warnings and errors)
          while IFS= read -r -d '' xml; do
            COUNT=$(grep -c "<error" "$xml" 2>/dev/null || echo 0)
            VIOLATIONS=$((VIOLATIONS + COUNT))
          done < <(find . -name "checkstyle-result.xml" -print0 2>/dev/null)

          echo "violations=$VIOLATIONS" >> "$GITHUB_OUTPUT"
          echo "Checkstyle: $VIOLATIONS issues found"
        continue-on-error: true

      # ========================================
      # PYTHON SETUP & TOOLS
      # ========================================
      - name: Set up Python ${{ matrix.python_version }}
        if: matrix.language == 'python'
uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5
        with:
          python-version: '${{ matrix.python_version }}'

      - name: "[Python] Install Dependencies"
        if: matrix.language == 'python'
        working-directory: ${{ env.WORKDIR }}
        run: |
          pip install --upgrade pip
          # Core testing
          pip install pytest pytest-cov hypothesis
          # Linting & formatting
          pip install ruff black isort
          # Security
          pip install bandit pip-audit safety
          # Type checking
          pip install mypy
          # Mutation testing
          pip install mutmut
          # Install repo dependencies
          if [ -f "requirements.txt" ]; then pip install -r requirements.txt; fi
          if [ -f "requirements-dev.txt" ]; then pip install -r requirements-dev.txt; fi
          if [ -f "pyproject.toml" ]; then pip install -e ".[dev]" 2>/dev/null || pip install -e . 2>/dev/null || true; fi

      - name: "[Python] Run Tests with Coverage"
        if: matrix.language == 'python' && matrix.run_pytest == true
        id: python-tests
        working-directory: ${{ env.WORKDIR }}
        run: |
          pytest --cov=. --cov-report=xml --cov-report=term --junitxml=pytest-junit.xml -v 2>&1 | tee test-output.txt || true

          # Extract test counts from final summary line only
          TOTAL=$(grep -oP '\d+(?= passed)' test-output.txt | tail -1)
          TOTAL=${TOTAL:-0}
          FAILED=$(grep -oP '\d+(?= failed)' test-output.txt | tail -1)
          FAILED=${FAILED:-0}
          SKIPPED=$(grep -oP '\d+(?= skipped)' test-output.txt | tail -1)
          SKIPPED=${SKIPPED:-0}

          COVERAGE=0
          if [ -f "coverage.xml" ]; then
            COVERAGE=$(grep -oP 'line-rate="\K[0-9.]+' coverage.xml | head -1 | awk '{printf "%.0f", $1 * 100}')
            COVERAGE=${COVERAGE:-0}
          fi

          {
            echo "total=$TOTAL"
            echo "passed=$TOTAL"
            echo "failed=$FAILED"
            echo "skipped=$SKIPPED"
            echo "coverage=$COVERAGE"
          } >> "$GITHUB_OUTPUT"
        continue-on-error: true

      - name: "[Python] Ruff Lint + Security"
        if: matrix.language == 'python' && matrix.run_ruff == true
        id: python-ruff
        working-directory: ${{ env.WORKDIR }}
        run: |
          ruff check . --output-format=json > ruff-report.json 2>/dev/null || true
          ERRORS=$(jq 'length' ruff-report.json 2>/dev/null || echo 0)
          SECURITY=$(jq '[.[] | select(.code | startswith("S"))] | length' ruff-report.json 2>/dev/null || echo 0)

          {
            echo "errors=$ERRORS"
            echo "security=$SECURITY"
          } >> "$GITHUB_OUTPUT"
        continue-on-error: true

      - name: "[Python] Bandit Security Scan"
        if: matrix.language == 'python' && matrix.run_bandit == true
        id: python-bandit
        working-directory: ${{ env.WORKDIR }}
        run: |
          bandit -r . -f json -o bandit-report.json 2>/dev/null || true

          HIGH=0; MEDIUM=0; LOW=0
          if [ -f "bandit-report.json" ]; then
            HIGH=$(jq '[.results[] | select(.issue_severity == "HIGH")] | length' bandit-report.json 2>/dev/null || echo 0)
            MEDIUM=$(jq '[.results[] | select(.issue_severity == "MEDIUM")] | length' bandit-report.json 2>/dev/null || echo 0)
            LOW=$(jq '[.results[] | select(.issue_severity == "LOW")] | length' bandit-report.json 2>/dev/null || echo 0)
          fi

          {
            echo "high=$HIGH"
            echo "medium=$MEDIUM"
            echo "low=$LOW"
          } >> "$GITHUB_OUTPUT"
        continue-on-error: true

      - name: "[Python] pip-audit Dependency Check"
        if: matrix.language == 'python' && matrix.run_pip_audit == true
        id: python-pipaudit
        working-directory: ${{ env.WORKDIR }}
        run: |
          pip-audit --format=json --output=pip-audit-report.json 2>/dev/null || true

          VULNS=0
          if [ -f "pip-audit-report.json" ]; then
            VULNS=$(jq 'length' pip-audit-report.json 2>/dev/null || echo 0)
          fi

          echo "vulnerabilities=$VULNS" >> "$GITHUB_OUTPUT"
        continue-on-error: true

      - name: "[Python] Black Format Check"
        if: matrix.language == 'python' && matrix.run_black == true
        id: python-black
        working-directory: ${{ env.WORKDIR }}
        run: |
          black --check . 2>&1 | tee black-output.txt || true
          WOULD_REFORMAT=$(grep -c "would reformat" black-output.txt 2>/dev/null)
          WOULD_REFORMAT=${WOULD_REFORMAT:-0}
          echo "issues=$WOULD_REFORMAT" >> "$GITHUB_OUTPUT"
        continue-on-error: true

      - name: "[Python] mypy Type Check"
        if: matrix.language == 'python' && matrix.run_mypy == true
        id: python-mypy
        working-directory: ${{ env.WORKDIR }}
        run: |
          mypy . --ignore-missing-imports 2>&1 | tee mypy-output.txt || true
          ERRORS=$(grep -c "error:" mypy-output.txt 2>/dev/null)
          ERRORS=${ERRORS:-0}
          echo "errors=$ERRORS" >> "$GITHUB_OUTPUT"
        continue-on-error: true

      - name: "[Python] Hypothesis Property Tests"
        if: matrix.language == 'python' && matrix.run_hypothesis == true
        id: python-hypothesis
        working-directory: ${{ env.WORKDIR }}
        run: |
          # Run tests with hypothesis statistics
          pytest --hypothesis-show-statistics -v 2>&1 | tee hypothesis-output.txt || true
          EXAMPLES=$(grep -oP '\d+(?= passing examples)' hypothesis-output.txt | tail -1)
          EXAMPLES=${EXAMPLES:-0}
          echo "examples=$EXAMPLES" >> "$GITHUB_OUTPUT"
        continue-on-error: true

      - name: "[Python] mutmut Mutation Testing"
        if: matrix.language == 'python' && matrix.run_mutmut == true && inputs.skip_mutation != true
        id: python-mutmut
        working-directory: ${{ env.WORKDIR }}
        run: |
          KILLED=0; SURVIVED=0; SCORE=0; TOTAL=0

          # mutmut 3.x requires config in pyproject.toml or setup.cfg (no CLI options)
          HAS_MUTMUT_CONFIG=false
          if [ -f "pyproject.toml" ] && grep -q '\[tool\.mutmut\]' pyproject.toml; then
            HAS_MUTMUT_CONFIG=true
            echo "Found [tool.mutmut] in pyproject.toml - using project config"
          elif [ -f "setup.cfg" ] && grep -q '\[mutmut\]' setup.cfg; then
            HAS_MUTMUT_CONFIG=true
            echo "Found [mutmut] in setup.cfg - using project config"
          fi

          if [ "$HAS_MUTMUT_CONFIG" = "false" ]; then
            # No config - detect source dir and create temporary config
            SRC_DIR=""
            if [ -d "src" ]; then
              SRC_DIR="src/"
            else
              # Look for Python packages (dirs with __init__.py), excluding tests/venv
              for dir in */; do
                dir="${dir%/}"
                if [ -f "$dir/__init__.py" ] && [[ ! "$dir" =~ ^(tests?|venv|\.venv|build|dist)$ ]]; then
                  SRC_DIR="$dir/"
                  break
                fi
              done
            fi
            if [ -z "$SRC_DIR" ]; then
              SRC_DIR="./"
            fi
            echo "No mutmut config found - creating temporary config for: $SRC_DIR"
            ls -la "${SRC_DIR%/}" || echo "Cannot list $SRC_DIR"

            # Create setup.cfg with mutmut config (mutmut 3.x reads this)
            if [ -f "setup.cfg" ]; then
              echo -e "\n[mutmut]\npaths_to_mutate=$SRC_DIR" >> setup.cfg
            else
              echo -e "[mutmut]\npaths_to_mutate=$SRC_DIR" > setup.cfg
            fi
            echo "Created [mutmut] section in setup.cfg with paths_to_mutate=$SRC_DIR"
          fi

          echo "Running: mutmut run"
          timeout 600 mutmut run 2>&1 | tee mutmut-run.log || true

          # Parse results from mutmut 3.x run output
          # Final line format: "â ™ 73/73  ðŸŽ‰ 73 ðŸ«¥ 0  â° 0  ðŸ¤” 0  ðŸ™ 0  ðŸ”‡ 0"
          # Look for "mutations/second" line (appears at end) and get the line before it
          if grep -q "mutations/second" mutmut-run.log; then
            # Get the line with final counts (contains X/X pattern at start)
            FINAL=$(grep -E '[0-9]+/[0-9]+' mutmut-run.log | tail -1)
            # Extract numbers: killed is after party emoji, survived is after frown emoji
            # Use sed to extract - format is "ðŸŽ‰ NN" and "ðŸ™ NN"
            KILLED=$(echo "$FINAL" | sed -n 's/.*ðŸŽ‰[[:space:]]*\([0-9]*\).*/\1/p' | head -1)
            SURVIVED=$(echo "$FINAL" | sed -n 's/.*ðŸ™[[:space:]]*\([0-9]*\).*/\1/p' | head -1)
            KILLED=${KILLED:-0}
            SURVIVED=${SURVIVED:-0}
            TOTAL=$((KILLED + SURVIVED))
            if [ "$TOTAL" -gt 0 ]; then
              SCORE=$((KILLED * 100 / TOTAL))
            fi
          fi

          # Warn if no mutations found
          if [ "$TOTAL" -eq 0 ]; then
            echo "::warning::mutmut found 0 mutations. Ensure [tool.mutmut] is configured in pyproject.toml with paths_to_mutate."
          fi

          {
            echo "killed=$KILLED"
            echo "survived=$SURVIVED"
            echo "score=$SCORE"
          } >> "$GITHUB_OUTPUT"
        continue-on-error: true
        timeout-minutes: 15

      - name: "[Python] isort Import Check"
        if: matrix.language == 'python' && matrix.run_isort == true
        id: python-isort
        working-directory: ${{ env.WORKDIR }}
        run: |
          isort --check-only --diff . 2>&1 | tee isort-output.txt || true
          # Count ERROR lines (isort says "ERROR: <file> Imports are incorrectly sorted")
          ISSUES=$(grep -c "^ERROR:" isort-output.txt 2>/dev/null || echo 0)
          echo "issues=$ISSUES" >> "$GITHUB_OUTPUT"
        continue-on-error: true

      # ========================================
      # JAVA EXTRA TOOLS
      # ========================================
      - name: "[Java] PMD Static Analysis"
        if: matrix.language == 'java' && matrix.run_pmd == true
        id: java-pmd
        working-directory: ${{ env.WORKDIR }}
        run: |
          VIOLATIONS=0

          if [ -f "mvnw" ]; then
            ./mvnw -B -ntp pmd:check 2>/dev/null || true
          else
            mvn -B -ntp pmd:check 2>/dev/null || true
          fi

          while IFS= read -r -d '' xml; do
            COUNT=$(grep -c "<violation" "$xml" 2>/dev/null || echo 0)
            VIOLATIONS=$((VIOLATIONS + COUNT))
          done < <(find . -name "pmd.xml" -print0 2>/dev/null)

          echo "violations=$VIOLATIONS" >> "$GITHUB_OUTPUT"
        continue-on-error: true

      # ========================================
      # CONTAINER & UNIVERSAL TOOLS
      # ========================================
      - name: "[All] Trivy Container Scan"
        if: matrix.run_trivy == true
        id: trivy
        working-directory: ${{ env.WORKDIR }}
        run: |
          # Install Trivy
          curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin

          # Scan filesystem
          trivy fs --format json --output trivy-report.json . 2>/dev/null || true

          CRITICAL=0; HIGH=0
          if [ -f "trivy-report.json" ]; then
            CRITICAL=$(jq '[.Results[]?.Vulnerabilities[]? | select(.Severity == "CRITICAL")] | length' trivy-report.json 2>/dev/null || echo 0)
            HIGH=$(jq '[.Results[]?.Vulnerabilities[]? | select(.Severity == "HIGH")] | length' trivy-report.json 2>/dev/null || echo 0)
          fi

          {
            echo "critical=$CRITICAL"
            echo "high=$HIGH"
          } >> "$GITHUB_OUTPUT"
        continue-on-error: true

      - name: "[All] Semgrep SAST"
        if: matrix.run_semgrep == true
        id: semgrep
        working-directory: ${{ env.WORKDIR }}
        run: |
          pip install semgrep 2>/dev/null || true

          # Run semgrep with auto config
          semgrep --config=auto --json --output=semgrep-report.json . 2>/dev/null || true

          FINDINGS=0
          if [ -f "semgrep-report.json" ]; then
            FINDINGS=$(jq '.results | length' semgrep-report.json 2>/dev/null || echo 0)
          fi

          echo "findings=$FINDINGS" >> "$GITHUB_OUTPUT"
        continue-on-error: true

      # ========================================
      # DOCKER BUILD
      # ========================================
      - name: "[All] Docker Build"
        if: matrix.run_docker == true
        id: docker-build
        working-directory: ${{ env.WORKDIR }}
        env:
          DOCKER_IMAGE: ${{ matrix.owner }}/${{ matrix.name }}
        run: |
          if [ -f "Dockerfile" ]; then
            echo "Building Docker image..."
            docker build -t "${DOCKER_IMAGE}:ci-test" . 2>&1 | tee docker-build.log || true

            if docker images | grep -q "ci-test"; then
              echo "status=success" >> "$GITHUB_OUTPUT"
              echo "Docker image built successfully"
            else
              echo "status=failed" >> "$GITHUB_OUTPUT"
              echo "Docker build failed"
            fi
          else
            echo "No Dockerfile found, skipping"
            echo "status=skipped" >> "$GITHUB_OUTPUT"
          fi
        continue-on-error: true

      # ========================================
      # CODEQL ANALYSIS
      # ========================================
      - name: "[All] Initialize CodeQL"
        if: matrix.run_codeql == true
        uses: github/codeql-action/init@5d4e8d1aca955e8d8589aabd499c5cae939e33c7
        with:
          languages: ${{ matrix.language }}
          source-root: ${{ env.WORKDIR }}

      - name: "[All] Perform CodeQL Analysis"
        if: matrix.run_codeql == true
        id: codeql
        uses: github/codeql-action/analyze@5d4e8d1aca955e8d8589aabd499c5cae939e33c7
        continue-on-error: true

      # ========================================
      # EXTRA TESTS FROM CONFIG
      # ========================================
      - name: "[All] Run Extra Tests from Config"
        id: extra-tests
        working-directory: ${{ env.WORKDIR }}
        env:
          REPO_NAME: ${{ matrix.name }}
        run: |
          echo "Running extra tests for ${REPO_NAME}..."

          # Check if Makefile exists and run make targets
          if [ -f "Makefile" ]; then
            echo "Found Makefile, running available targets..."
            make lint 2>/dev/null || true
            make test 2>/dev/null || true
          fi

          echo "status=complete" >> "$GITHUB_OUTPUT"
        continue-on-error: true

      # ========================================
      # GENERATE BEAUTIFUL REPORT
      # ========================================
      - name: Generate QA Metrics Report
        id: report
        env:
          MATRIX_LANGUAGE: ${{ matrix.language }}
          MATRIX_CONFIG_BASENAME: ${{ matrix.config_basename }}
          MATRIX_SUBDIR: ${{ matrix.subdir }}
          MATRIX_OWNER: ${{ matrix.owner }}
          MATRIX_NAME: ${{ matrix.name }}
          MATRIX_BRANCH: ${{ matrix.branch }}
          MATRIX_RUN_GROUP: ${{ matrix.run_group }}
          MATRIX_JAVA_VERSION: ${{ matrix.java_version }}
          MATRIX_PYTHON_VERSION: ${{ matrix.python_version }}
          MATRIX_BUILD_TOOL: ${{ matrix.build_tool }}
          MATRIX_RETENTION_DAYS: ${{ matrix.retention_days }}
          # Java tool flags
          MATRIX_RUN_JACOCO: ${{ matrix.run_jacoco }}
          MATRIX_RUN_PITEST: ${{ matrix.run_pitest }}
          MATRIX_RUN_CHECKSTYLE: ${{ matrix.run_checkstyle }}
          MATRIX_RUN_PMD: ${{ matrix.run_pmd }}
          MATRIX_RUN_SPOTBUGS: ${{ matrix.run_spotbugs }}
          MATRIX_RUN_OWASP: ${{ matrix.run_owasp }}
          MATRIX_RUN_JQWIK: ${{ matrix.run_jqwik }}
          # Python tool flags
          MATRIX_RUN_PYTEST: ${{ matrix.run_pytest }}
          MATRIX_RUN_MUTMUT: ${{ matrix.run_mutmut }}
          MATRIX_RUN_RUFF: ${{ matrix.run_ruff }}
          MATRIX_RUN_BLACK: ${{ matrix.run_black }}
          MATRIX_RUN_ISORT: ${{ matrix.run_isort }}
          MATRIX_RUN_MYPY: ${{ matrix.run_mypy }}
          MATRIX_RUN_BANDIT: ${{ matrix.run_bandit }}
          MATRIX_RUN_PIP_AUDIT: ${{ matrix.run_pip_audit }}
          MATRIX_RUN_HYPOTHESIS: ${{ matrix.run_hypothesis }}
          # Common tool flags
          MATRIX_RUN_SEMGREP: ${{ matrix.run_semgrep }}
          MATRIX_RUN_TRIVY: ${{ matrix.run_trivy }}
          MATRIX_RUN_CODEQL: ${{ matrix.run_codeql }}
          MATRIX_RUN_DOCKER: ${{ matrix.run_docker }}
          # Step outcomes (safe but included for consistency)
          JAVA_BUILD_OUTCOME: ${{ steps.java-build.outcome }}
          JAVA_COVERAGE_OUTCOME: ${{ steps.java-coverage.outcome }}
          JAVA_MUTATION_OUTCOME: ${{ steps.java-mutation.outcome }}
          JAVA_CHECKSTYLE_OUTCOME: ${{ steps.java-checkstyle.outcome }}
          JAVA_PMD_OUTCOME: ${{ steps.java-pmd.outcome }}
          JAVA_SPOTBUGS_OUTCOME: ${{ steps.java-spotbugs.outcome }}
          JAVA_OWASP_OUTCOME: ${{ steps.java-owasp.outcome }}
          JAVA_TESTS_OUTCOME: ${{ steps.java-tests.outcome }}
          PYTHON_TESTS_OUTCOME: ${{ steps.python-tests.outcome }}
          PYTHON_MUTMUT_OUTCOME: ${{ steps.python-mutmut.outcome }}
          PYTHON_RUFF_OUTCOME: ${{ steps.python-ruff.outcome }}
          PYTHON_BLACK_OUTCOME: ${{ steps.python-black.outcome }}
          PYTHON_ISORT_OUTCOME: ${{ steps.python-isort.outcome }}
          PYTHON_MYPY_OUTCOME: ${{ steps.python-mypy.outcome }}
          PYTHON_BANDIT_OUTCOME: ${{ steps.python-bandit.outcome }}
          PYTHON_PIPAUDIT_OUTCOME: ${{ steps.python-pipaudit.outcome }}
          SEMGREP_OUTCOME: ${{ steps.semgrep.outcome }}
          TRIVY_OUTCOME: ${{ steps.trivy.outcome }}
          CODEQL_OUTCOME: ${{ steps.codeql.outcome }}
          DOCKER_BUILD_OUTCOME: ${{ steps.docker-build.outcome }}
          # Step outputs
          JAVA_COV_PERCENT: ${{ steps.java-coverage.outputs.percent }}
          JAVA_MUT_SCORE: ${{ steps.java-mutation.outputs.score }}
          JAVA_TESTS_TOTAL: ${{ steps.java-tests.outputs.total }}
          JAVA_TESTS_RUNTIME: ${{ steps.java-tests.outputs.runtime }}
          JAVA_TESTS_FAILED: ${{ steps.java-tests.outputs.failed }}
          JAVA_TESTS_SKIPPED: ${{ steps.java-tests.outputs.skipped }}
          JAVA_COV_LINES: ${{ steps.java-coverage.outputs.lines }}
          JAVA_MUT_KILLED: ${{ steps.java-mutation.outputs.killed }}
          JAVA_MUT_SURVIVED: ${{ steps.java-mutation.outputs.survived }}
          JAVA_OWASP_CRITICAL: ${{ steps.java-owasp.outputs.critical }}
          JAVA_OWASP_HIGH: ${{ steps.java-owasp.outputs.high }}
          JAVA_OWASP_MEDIUM: ${{ steps.java-owasp.outputs.medium }}
          JAVA_OWASP_LOW: ${{ steps.java-owasp.outputs.low }}
          JAVA_SPOTBUGS_COUNT: ${{ steps.java-spotbugs.outputs.count }}
          JAVA_PMD_VIOLATIONS: ${{ steps.java-pmd.outputs.violations }}
          JAVA_CHECKSTYLE_VIOLATIONS: ${{ steps.java-checkstyle.outputs.violations }}
          SEMGREP_FINDINGS: ${{ steps.semgrep.outputs.findings }}
          TRIVY_CRITICAL: ${{ steps.trivy.outputs.critical }}
          TRIVY_HIGH: ${{ steps.trivy.outputs.high }}
          PYTHON_COV_PERCENT: ${{ steps.python-tests.outputs.coverage_percent }}
          PYTHON_MUT_SCORE: ${{ steps.python-mutmut.outputs.score }}
          PYTHON_TESTS_TOTAL: ${{ steps.python-tests.outputs.total }}
          PYTHON_TESTS_RUNTIME: ${{ steps.python-tests.outputs.runtime }}
          PYTHON_TESTS_FAILED: ${{ steps.python-tests.outputs.failed }}
          PYTHON_TESTS_SKIPPED: ${{ steps.python-tests.outputs.skipped }}
          PYTHON_COV_LINES: ${{ steps.python-tests.outputs.coverage_lines }}
          PYTHON_MUT_KILLED: ${{ steps.python-mutmut.outputs.killed }}
          PYTHON_MUT_SURVIVED: ${{ steps.python-mutmut.outputs.survived }}
          PYTHON_BANDIT_HIGH: ${{ steps.python-bandit.outputs.high }}
          PYTHON_BANDIT_MEDIUM: ${{ steps.python-bandit.outputs.medium }}
          PYTHON_BANDIT_LOW: ${{ steps.python-bandit.outputs.low }}
          PYTHON_PIPAUDIT_VULNS: ${{ steps.python-pipaudit.outputs.vulnerabilities }}
          PYTHON_HYPOTHESIS_EXAMPLES: ${{ steps.python-hypothesis.outputs.examples }}
          PYTHON_RUFF_ERRORS: ${{ steps.python-ruff.outputs.errors }}
          PYTHON_RUFF_SECURITY: ${{ steps.python-ruff.outputs.security }}
          PYTHON_BLACK_ISSUES: ${{ steps.python-black.outputs.issues }}
          PYTHON_ISORT_ISSUES: ${{ steps.python-isort.outputs.issues }}
          PYTHON_MYPY_ERRORS: ${{ steps.python-mypy.outputs.errors }}
        run: |
          # Create reports directory for this config
          REPORT_SUFFIX="${MATRIX_CONFIG_BASENAME}${MATRIX_SUBDIR:+-${MATRIX_SUBDIR}}"
          REPORT_DIR="reports/${REPORT_SUFFIX}"
          mkdir -p "$REPORT_DIR"
          SUMMARY_FILE="$REPORT_DIR/summary.md"
          exec 3> "$SUMMARY_FILE"

          # Write to summary.md first, then copy to GITHUB_STEP_SUMMARY
          {
            echo "# Configuration Summary"
            echo ""
          } >&3

          if [ "$MATRIX_LANGUAGE" = "java" ]; then
            # Helper function to check if outcome is success
            is_success() { [ "$1" = "success" ] && echo "true" || echo "false"; }
            ran() { [ "$1" = "success" ] || [ "$1" = "failure" ] && echo "true" || echo "false"; }
            {
              echo "## Tools Enabled"
              echo "| Category | Tool | Configured | Ran | Success |"
              echo "|----------|------|------------|-----|---------|"
              echo "| Build | maven | true | true | $(is_success "$JAVA_BUILD_OUTCOME") |"
              echo "| Testing | JaCoCo Coverage | ${MATRIX_RUN_JACOCO} | $(ran "$JAVA_COVERAGE_OUTCOME") | $(is_success "$JAVA_COVERAGE_OUTCOME") |"
              echo "| Testing | PITest | ${MATRIX_RUN_PITEST} | $(ran "$JAVA_MUTATION_OUTCOME") | $(is_success "$JAVA_MUTATION_OUTCOME") |"
              echo "| Linting | Checkstyle | ${MATRIX_RUN_CHECKSTYLE} | $(ran "$JAVA_CHECKSTYLE_OUTCOME") | $(is_success "$JAVA_CHECKSTYLE_OUTCOME") |"
              echo "| Linting | PMD | ${MATRIX_RUN_PMD} | $(ran "$JAVA_PMD_OUTCOME") | $(is_success "$JAVA_PMD_OUTCOME") |"
              echo "| Linting | SpotBugs | ${MATRIX_RUN_SPOTBUGS} | $(ran "$JAVA_SPOTBUGS_OUTCOME") | $(is_success "$JAVA_SPOTBUGS_OUTCOME") |"
              echo "| Security | OWASP Dependency-Check | ${MATRIX_RUN_OWASP} | $(ran "$JAVA_OWASP_OUTCOME") | $(is_success "$JAVA_OWASP_OUTCOME") |"
              echo "| Security | Semgrep | ${MATRIX_RUN_SEMGREP} | $(ran "$SEMGREP_OUTCOME") | $(is_success "$SEMGREP_OUTCOME") |"
              echo "| Security | Trivy | ${MATRIX_RUN_TRIVY} | $(ran "$TRIVY_OUTCOME") | $(is_success "$TRIVY_OUTCOME") |"
              echo "| Security | CodeQL | ${MATRIX_RUN_CODEQL} | $(ran "$CODEQL_OUTCOME") | $(is_success "$CODEQL_OUTCOME") |"
              echo "| Testing | jqwik | ${MATRIX_RUN_JQWIK} | $(ran "$JAVA_TESTS_OUTCOME") | $(is_success "$JAVA_TESTS_OUTCOME") |"
              echo "| Container | Docker | ${MATRIX_RUN_DOCKER} | $(ran "$DOCKER_BUILD_OUTCOME") | $(is_success "$DOCKER_BUILD_OUTCOME") |"
              echo ""
              echo "## Environment"
              echo "| Setting | Value |"
              echo "|---------|-------|"
              echo "| Java Version | ${MATRIX_JAVA_VERSION:-NOT SET} |"
              echo "| Build Tool | ${MATRIX_BUILD_TOOL:-NOT SET} |"
              echo "| Working Directory | \`${MATRIX_SUBDIR:-.}\` |"
              echo "| Repository | ${MATRIX_OWNER}/${MATRIX_NAME} |"
              echo "| Branch | ${MATRIX_BRANCH} |"
              echo "| Language | Java |"
              echo "| Config | ${MATRIX_CONFIG_BASENAME} |"
              echo "| Run Group | ${MATRIX_RUN_GROUP} |"
              echo "| Run Number | #${GITHUB_RUN_NUMBER} |"
              echo "| Artifact Retention | ${MATRIX_RETENTION_DAYS:-NOT SET}${MATRIX_RETENTION_DAYS:+ days} |"
              echo ""
              echo "---"
              echo ""
            } >&3
          else
            {
              echo "## Tools Enabled"
              echo "| Category | Tool | Configured | Ran | Success |"
              echo "|----------|------|------------|-----|---------|"
              echo "| Testing | pytest | ${MATRIX_RUN_PYTEST} | $(ran "$PYTHON_TESTS_OUTCOME") | $(is_success "$PYTHON_TESTS_OUTCOME") |"
              echo "| Testing | mutmut | ${MATRIX_RUN_MUTMUT} | $(ran "$PYTHON_MUTMUT_OUTCOME") | $(is_success "$PYTHON_MUTMUT_OUTCOME") |"
              echo "| Linting | Ruff | ${MATRIX_RUN_RUFF} | $(ran "$PYTHON_RUFF_OUTCOME") | $(is_success "$PYTHON_RUFF_OUTCOME") |"
              echo "| Linting | Black | ${MATRIX_RUN_BLACK} | $(ran "$PYTHON_BLACK_OUTCOME") | $(is_success "$PYTHON_BLACK_OUTCOME") |"
              echo "| Linting | isort | ${MATRIX_RUN_ISORT} | $(ran "$PYTHON_ISORT_OUTCOME") | $(is_success "$PYTHON_ISORT_OUTCOME") |"
              echo "| Linting | mypy | ${MATRIX_RUN_MYPY} | $(ran "$PYTHON_MYPY_OUTCOME") | $(is_success "$PYTHON_MYPY_OUTCOME") |"
              echo "| Security | Bandit | ${MATRIX_RUN_BANDIT} | $(ran "$PYTHON_BANDIT_OUTCOME") | $(is_success "$PYTHON_BANDIT_OUTCOME") |"
              echo "| Security | pip-audit | ${MATRIX_RUN_PIP_AUDIT} | $(ran "$PYTHON_PIPAUDIT_OUTCOME") | $(is_success "$PYTHON_PIPAUDIT_OUTCOME") |"
              echo "| Security | Semgrep | ${MATRIX_RUN_SEMGREP} | $(ran "$SEMGREP_OUTCOME") | $(is_success "$SEMGREP_OUTCOME") |"
              echo "| Security | Trivy | ${MATRIX_RUN_TRIVY} | $(ran "$TRIVY_OUTCOME") | $(is_success "$TRIVY_OUTCOME") |"
              echo "| Security | CodeQL | ${MATRIX_RUN_CODEQL} | $(ran "$CODEQL_OUTCOME") | $(is_success "$CODEQL_OUTCOME") |"
              echo "| Testing | Hypothesis | ${MATRIX_RUN_HYPOTHESIS} | $(ran "$PYTHON_TESTS_OUTCOME") | $(is_success "$PYTHON_TESTS_OUTCOME") |"
              echo "| Container | Docker | ${MATRIX_RUN_DOCKER} | $(ran "$DOCKER_BUILD_OUTCOME") | $(is_success "$DOCKER_BUILD_OUTCOME") |"
              echo ""
              echo "## Environment"
              echo "| Setting | Value |"
              echo "|---------|-------|"
              echo "| Python Version | ${MATRIX_PYTHON_VERSION:-NOT SET} |"
              echo "| Working Directory | \`${MATRIX_SUBDIR:-.}\` |"
              echo "| Repository | ${MATRIX_OWNER}/${MATRIX_NAME} |"
              echo "| Branch | ${MATRIX_BRANCH} |"
              echo "| Language | Python |"
              echo "| Config | ${MATRIX_CONFIG_BASENAME} |"
              echo "| Run Group | ${MATRIX_RUN_GROUP} |"
              echo "| Run Number | #${GITHUB_RUN_NUMBER} |"
              echo "| Artifact Retention | ${MATRIX_RETENTION_DAYS:-NOT SET}${MATRIX_RETENTION_DAYS:+ days} |"
              echo ""
              echo "---"
              echo ""
            } >&3
          fi
          exec 3>&-

          if [ "$MATRIX_LANGUAGE" = "java" ]; then
            # Calculate progress bar
            COV=${JAVA_COV_PERCENT:-0}
            MUT=${JAVA_MUT_SCORE:-0}
            COV_BAR=$(printf 'â–ˆ%.0s' $(seq 1 $((COV / 5))) 2>/dev/null; printf 'â–‘%.0s' $(seq 1 $((20 - COV / 5))) 2>/dev/null)
            MUT_BAR=$(printf 'â–ˆ%.0s' $(seq 1 $((MUT / 5))) 2>/dev/null; printf 'â–‘%.0s' $(seq 1 $((20 - MUT / 5))) 2>/dev/null)

            {
              echo "## QA Metrics (Java)"
              echo ""
              echo "| Metric | Result | Details |"
              echo "|--------|--------|---------|"
              echo "| **Tests** | ${JAVA_TESTS_TOTAL:-0} executed | Runtime: ${JAVA_TESTS_RUNTIME:-0s}, Failures: ${JAVA_TESTS_FAILED:-0}, Skipped: ${JAVA_TESTS_SKIPPED:-0} |"
              echo "| **Line Coverage (JaCoCo)** | ${COV}% ${COV_BAR} | ${JAVA_COV_LINES:-0 / 0} lines covered |"
              echo "| **Mutation Score (PITest)** | ${MUT}% ${MUT_BAR} | ${JAVA_MUT_KILLED:-0} killed, ${JAVA_MUT_SURVIVED:-0} survived |"
              echo "| **Dependency-Check** | scan complete | ${JAVA_OWASP_CRITICAL:-0} crit, ${JAVA_OWASP_HIGH:-0} high, ${JAVA_OWASP_MEDIUM:-0} med |"
              echo "| **SpotBugs** | ${JAVA_SPOTBUGS_COUNT:-0} bugs | Static analysis |"
              echo "| **PMD** | ${JAVA_PMD_VIOLATIONS:-0} violations | Code analysis |"
              echo "| **Checkstyle** | ${JAVA_CHECKSTYLE_VIOLATIONS:-0} violations | Code style |"
              echo "| **Semgrep** | ${SEMGREP_FINDINGS:-0} findings | SAST analysis |"
              echo "| **Trivy** | ${TRIVY_CRITICAL:-0} crit, ${TRIVY_HIGH:-0} high | Container scan |"
              echo ""
              echo "### Dependency Severity"
              echo "| Severity | Count |"
              echo "|----------|-------|"
              echo "| Critical | ${JAVA_OWASP_CRITICAL:-0} |"
              echo "| High | ${JAVA_OWASP_HIGH:-0} |"
              echo "| Medium | ${JAVA_OWASP_MEDIUM:-0} |"
              echo "| Low | ${JAVA_OWASP_LOW:-0} |"
              echo ""
            } >&3

          else
            # Python report
            COV=${PYTHON_COV_PERCENT:-0}
            COV_BAR=$(printf 'â–ˆ%.0s' $(seq 1 $((COV / 5))) 2>/dev/null; printf 'â–‘%.0s' $(seq 1 $((20 - COV / 5))) 2>/dev/null)

            {
              echo "## QA Metrics (Python)"
              echo ""
              echo "| Metric | Result | Details |"
              echo "|--------|--------|---------|"
              echo "| **Tests (pytest)** | ${PYTHON_TESTS_TOTAL:-0} executed | Passed: ${PYTHON_TESTS_PASSED:-0}, Failed: ${PYTHON_TESTS_FAILED:-0}, Skipped: ${PYTHON_TESTS_SKIPPED:-0} |"
              echo "| **Line Coverage** | ${COV}% ${COV_BAR} | pytest-cov |"
              echo "| **Mutation (mutmut)** | ${PYTHON_MUT_SCORE:-0}% | ${PYTHON_MUT_KILLED:-0} killed, ${PYTHON_MUT_SURVIVED:-0} survived |"
              echo "| **Hypothesis** | ${PYTHON_HYPOTHESIS_EXAMPLES:-0} examples | Property-based testing |"
              echo "| **Ruff Lint** | ${PYTHON_RUFF_ERRORS:-0} issues | Security rules: ${PYTHON_RUFF_SECURITY:-0} |"
              echo "| **Bandit Security** | scan complete | High: ${PYTHON_BANDIT_HIGH:-0}, Med: ${PYTHON_BANDIT_MEDIUM:-0}, Low: ${PYTHON_BANDIT_LOW:-0} |"
              echo "| **pip-audit** | ${PYTHON_PIPAUDIT_VULNS:-0} vulns | Dependency check |"
              echo "| **Black** | ${PYTHON_BLACK_ISSUES:-0} files | Format check |"
              echo "| **isort** | ${PYTHON_ISORT_ISSUES:-0} files | Import ordering |"
              echo "| **mypy** | ${PYTHON_MYPY_ERRORS:-0} errors | Type check |"
              echo "| **Semgrep** | ${SEMGREP_FINDINGS:-0} findings | SAST analysis |"
              echo "| **Trivy** | ${TRIVY_CRITICAL:-0} crit, ${TRIVY_HIGH:-0} high | Container scan |"
              echo ""
              echo "### Security Summary"
              echo "| Severity | Count |"
              echo "|----------|-------|"
              echo "| High | ${PYTHON_BANDIT_HIGH:-0} |"
              echo "| Medium | ${PYTHON_BANDIT_MEDIUM:-0} |"
              echo "| Low | ${PYTHON_BANDIT_LOW:-0} |"
              echo ""
            } >&3
          fi

          # Quality Gates
          {
            echo ""
            echo "---"
            echo ""
            echo "### Quality Gates"
            echo ""
            echo "| Check | Status |"
            echo "|-------|--------|"
          } >&3

          # Helper for pass/fail status
          gate_status() { [ "${1:-0}" = "0" ] && echo "Passed" || echo "$2"; }

          if [ "$MATRIX_LANGUAGE" = "java" ]; then
            echo "| Unit Tests | $(gate_status "${JAVA_TESTS_FAILED}" "Failed") |" >&3
            echo "| JaCoCo Coverage | Generated |" >&3
            echo "| PITest Mutation | Generated |" >&3
            echo "| Checkstyle | $(gate_status "${JAVA_CHECKSTYLE_VIOLATIONS}" "Violations") |" >&3
            echo "| SpotBugs | $(gate_status "${JAVA_SPOTBUGS_COUNT}" "Bugs found") |" >&3
            echo "| PMD | $(gate_status "${JAVA_PMD_VIOLATIONS}" "Violations") |" >&3
            owasp_ok=$([[ "${JAVA_OWASP_CRITICAL:-0}" = "0" && "${JAVA_OWASP_HIGH:-0}" = "0" ]] && echo "Passed" || echo "Vulnerabilities")
            echo "| OWASP Check | $owasp_ok |" >&3
            echo "| Semgrep | $(gate_status "${SEMGREP_FINDINGS}" "Findings") |" >&3
          else
            echo "| pytest | $(gate_status "${PYTHON_TESTS_FAILED}" "Failed") |" >&3
            echo "| Coverage | Generated |" >&3
            echo "| mutmut Mutation | Generated |" >&3
            echo "| Hypothesis | Complete |" >&3
            echo "| Ruff | $(gate_status "${PYTHON_RUFF_ERRORS}" "Issues") |" >&3
            echo "| Bandit | $(gate_status "${PYTHON_BANDIT_HIGH}" "Security issues") |" >&3
            echo "| pip-audit | $(gate_status "${PYTHON_PIPAUDIT_VULNS}" "Vulnerabilities") |" >&3
            echo "| Black | $(gate_status "${PYTHON_BLACK_ISSUES}" "Format issues") |" >&3
            echo "| isort | $(gate_status "${PYTHON_ISORT_ISSUES}" "Import issues") |" >&3
            echo "| mypy | $(gate_status "${PYTHON_MYPY_ERRORS}" "Type errors") |" >&3
            echo "| Semgrep | $(gate_status "${SEMGREP_FINDINGS}" "Findings") |" >&3
          fi

          {
            echo ""
            echo "Job summary generated at run-time"
          } >&3

          exec 3>&-
          # Copy summary to GitHub Step Summary for display
          cat "$SUMMARY_FILE" >> "$GITHUB_STEP_SUMMARY"

      - name: Write Report JSON
        if: always()
        env:
          MATRIX_LANGUAGE: ${{ matrix.language }}
          MATRIX_CONFIG_BASENAME: ${{ matrix.config_basename }}
          MATRIX_SUBDIR: ${{ matrix.subdir }}
          MATRIX_OWNER: ${{ matrix.owner }}
          MATRIX_NAME: ${{ matrix.name }}
          MATRIX_BRANCH: ${{ matrix.branch }}
          MATRIX_JAVA_VERSION: ${{ matrix.java_version }}
          MATRIX_PYTHON_VERSION: ${{ matrix.python_version }}
          # Tool flags
          MATRIX_RUN_JACOCO: ${{ matrix.run_jacoco }}
          MATRIX_RUN_CHECKSTYLE: ${{ matrix.run_checkstyle }}
          MATRIX_RUN_SPOTBUGS: ${{ matrix.run_spotbugs }}
          MATRIX_RUN_PMD: ${{ matrix.run_pmd }}
          MATRIX_RUN_OWASP: ${{ matrix.run_owasp }}
          MATRIX_RUN_PITEST: ${{ matrix.run_pitest }}
          MATRIX_RUN_JQWIK: ${{ matrix.run_jqwik }}
          MATRIX_RUN_PYTEST: ${{ matrix.run_pytest }}
          MATRIX_RUN_MUTMUT: ${{ matrix.run_mutmut }}
          MATRIX_RUN_RUFF: ${{ matrix.run_ruff }}
          MATRIX_RUN_BANDIT: ${{ matrix.run_bandit }}
          MATRIX_RUN_PIP_AUDIT: ${{ matrix.run_pip_audit }}
          MATRIX_RUN_SEMGREP: ${{ matrix.run_semgrep }}
          MATRIX_RUN_TRIVY: ${{ matrix.run_trivy }}
          MATRIX_RUN_CODEQL: ${{ matrix.run_codeql }}
          MATRIX_RUN_DOCKER: ${{ matrix.run_docker }}
          # Step outcomes
          JAVA_COVERAGE_OUTCOME: ${{ steps.java-coverage.outcome }}
          JAVA_CHECKSTYLE_OUTCOME: ${{ steps.java-checkstyle.outcome }}
          JAVA_SPOTBUGS_OUTCOME: ${{ steps.java-spotbugs.outcome }}
          JAVA_PMD_OUTCOME: ${{ steps.java-pmd.outcome }}
          JAVA_OWASP_OUTCOME: ${{ steps.java-owasp.outcome }}
          JAVA_MUTATION_OUTCOME: ${{ steps.java-mutation.outcome }}
          JAVA_TESTS_OUTCOME: ${{ steps.java-tests.outcome }}
          PYTHON_TESTS_OUTCOME: ${{ steps.python-tests.outcome }}
          PYTHON_MUTMUT_OUTCOME: ${{ steps.python-mutmut.outcome }}
          PYTHON_RUFF_OUTCOME: ${{ steps.python-ruff.outcome }}
          PYTHON_BANDIT_OUTCOME: ${{ steps.python-bandit.outcome }}
          PYTHON_PIPAUDIT_OUTCOME: ${{ steps.python-pipaudit.outcome }}
          SEMGREP_OUTCOME: ${{ steps.semgrep.outcome }}
          TRIVY_OUTCOME: ${{ steps.trivy.outcome }}
          CODEQL_OUTCOME: ${{ steps.codeql.outcome }}
          DOCKER_BUILD_OUTCOME: ${{ steps.docker-build.outcome }}
          # Step outputs
          JAVA_COV_PERCENT: ${{ steps.java-coverage.outputs.percent }}
          JAVA_MUT_SCORE: ${{ steps.java-mutation.outputs.score }}
          JAVA_TESTS_PASSED: ${{ steps.java-tests.outputs.passed }}
          JAVA_TESTS_FAILED: ${{ steps.java-tests.outputs.failed }}
          JAVA_OWASP_CRITICAL: ${{ steps.java-owasp.outputs.critical }}
          JAVA_OWASP_HIGH: ${{ steps.java-owasp.outputs.high }}
          JAVA_OWASP_MEDIUM: ${{ steps.java-owasp.outputs.medium }}
          JAVA_SPOTBUGS_COUNT: ${{ steps.java-spotbugs.outputs.count }}
          JAVA_PMD_VIOLATIONS: ${{ steps.java-pmd.outputs.violations }}
          JAVA_CHECKSTYLE_VIOLATIONS: ${{ steps.java-checkstyle.outputs.violations }}
          SEMGREP_FINDINGS: ${{ steps.semgrep.outputs.findings }}
          TRIVY_CRITICAL: ${{ steps.trivy.outputs.critical }}
          TRIVY_HIGH: ${{ steps.trivy.outputs.high }}
          PYTHON_COV_PERCENT: ${{ steps.python-tests.outputs.coverage }}
          PYTHON_MUT_SCORE: ${{ steps.python-mutmut.outputs.score }}
          PYTHON_TESTS_PASSED: ${{ steps.python-tests.outputs.passed }}
          PYTHON_TESTS_FAILED: ${{ steps.python-tests.outputs.failed }}
          PYTHON_BANDIT_HIGH: ${{ steps.python-bandit.outputs.high }}
          PYTHON_BANDIT_MEDIUM: ${{ steps.python-bandit.outputs.medium }}
          PYTHON_PIPAUDIT_VULNS: ${{ steps.python-pipaudit.outputs.vulnerabilities }}
          PYTHON_RUFF_ERRORS: ${{ steps.python-ruff.outputs.errors }}
        run: |
          # Use same REPORT_DIR as Generate QA Metrics Report step
          REPORT_SUFFIX="${MATRIX_CONFIG_BASENAME}${MATRIX_SUBDIR:+-${MATRIX_SUBDIR}}"
          REPORT_DIR="reports/${REPORT_SUFFIX}"
          mkdir -p "$REPORT_DIR"

          # Summary was already written to $REPORT_DIR/summary.md in the previous step

          COMMIT_SHA=$(git -C repo rev-parse HEAD 2>/dev/null || echo "")
          TIMESTAMP=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          WORKFLOW_REF="${GITHUB_REPOSITORY}/.github/workflows/hub-run-all.yml@${GITHUB_REF_NAME}"

          # Helper for ran status
          ran() { [ "$1" = "success" ] || [ "$1" = "failure" ] && echo "true" || echo "false"; }

          if [ "$MATRIX_LANGUAGE" = "java" ]; then
            BUILD_STATUS="success"
            FAILED_TESTS="${JAVA_TESTS_FAILED:-0}"
            if [ "${FAILED_TESTS:-0}" -gt 0 ]; then
              BUILD_STATUS="failure"
            fi

            CRITICAL_VULNS=${{ steps.java-owasp.outputs.critical || 0 }}
            HIGH_VULNS=${{ steps.java-owasp.outputs.high || 0 }}
            MEDIUM_VULNS=${{ steps.java-owasp.outputs.medium || 0 }}

            TRIVY_CRITICAL=${{ steps.trivy.outputs.critical || 0 }}
            TRIVY_HIGH=${{ steps.trivy.outputs.high || 0 }}
            TRIVY_MEDIUM=0
            if [ -f "repo/trivy-report.json" ]; then
              TRIVY_MEDIUM=$(jq '[.Results[]?.Vulnerabilities[]? | select(.Severity == "MEDIUM")] | length' repo/trivy-report.json 2>/dev/null || echo 0)
            fi

            CRITICAL_VULNS=$((CRITICAL_VULNS + TRIVY_CRITICAL))
            HIGH_VULNS=$((HIGH_VULNS + TRIVY_HIGH))
            MEDIUM_VULNS=$((MEDIUM_VULNS + TRIVY_MEDIUM))

            cat > "$REPORT_DIR/report.json" << EOF
          {
            "schema_version": "2.0",
            "metadata": {
              "workflow_version": "v1.0.0",
              "workflow_ref": "${WORKFLOW_REF}",
              "generated_at": "${TIMESTAMP}"
            },
            "repository": "${{ matrix.owner }}/${{ matrix.name }}",
            "run_id": "${{ github.run_id }}",
            "run_number": "${{ github.run_number }}",
            "commit": "${COMMIT_SHA}",
            "branch": "${{ matrix.branch }}",
            "timestamp": "${TIMESTAMP}",
            "java_version": "${{ matrix.java_version }}",
            "results": {
              "build": "${BUILD_STATUS}",
              "coverage": ${{ steps.java-coverage.outputs.percent || 0 }},
              "mutation_score": ${{ steps.java-mutation.outputs.score || 0 }},
              "tests_passed": ${{ steps.java-tests.outputs.passed || 0 }},
              "tests_failed": ${{ steps.java-tests.outputs.failed || 0 }},
              "critical_vulns": ${CRITICAL_VULNS},
              "high_vulns": ${HIGH_VULNS},
              "medium_vulns": ${MEDIUM_VULNS}
            },
            "tool_metrics": {
              "checkstyle_issues": ${{ steps.java-checkstyle.outputs.violations || 0 }},
              "spotbugs_issues": ${{ steps.java-spotbugs.outputs.count || 0 }},
              "pmd_violations": ${{ steps.java-pmd.outputs.violations || 0 }},
              "owasp_critical": ${{ steps.java-owasp.outputs.critical || 0 }},
              "owasp_high": ${{ steps.java-owasp.outputs.high || 0 }},
              "semgrep_findings": ${{ steps.semgrep.outputs.findings || 0 }},
              "trivy_critical": ${{ steps.trivy.outputs.critical || 0 }},
              "trivy_high": ${{ steps.trivy.outputs.high || 0 }}
            },
            "tools_configured": {
              "jacoco": ${{ matrix.run_jacoco }},
              "checkstyle": ${{ matrix.run_checkstyle }},
              "spotbugs": ${{ matrix.run_spotbugs }},
              "pmd": ${{ matrix.run_pmd }},
              "owasp": ${{ matrix.run_owasp }},
              "pitest": ${{ matrix.run_pitest }},
              "jqwik": ${{ matrix.run_jqwik }},
              "semgrep": ${{ matrix.run_semgrep }},
              "trivy": ${{ matrix.run_trivy }},
              "codeql": ${{ matrix.run_codeql }},
              "docker": ${{ matrix.run_docker }}
            },
            "tools_ran": {
              "jacoco": ${{ steps.java-coverage.outcome == 'success' || steps.java-coverage.outcome == 'failure' }},
              "checkstyle": ${{ steps.java-checkstyle.outcome == 'success' || steps.java-checkstyle.outcome == 'failure' }},
              "spotbugs": ${{ steps.java-spotbugs.outcome == 'success' || steps.java-spotbugs.outcome == 'failure' }},
              "pmd": ${{ steps.java-pmd.outcome == 'success' || steps.java-pmd.outcome == 'failure' }},
              "owasp": ${{ steps.java-owasp.outcome == 'success' || steps.java-owasp.outcome == 'failure' }},
              "pitest": ${{ steps.java-mutation.outcome == 'success' || steps.java-mutation.outcome == 'failure' }},
              "jqwik": ${{ steps.java-tests.outcome == 'success' || steps.java-tests.outcome == 'failure' }},
              "semgrep": ${{ steps.semgrep.outcome == 'success' || steps.semgrep.outcome == 'failure' }},
              "trivy": ${{ steps.trivy.outcome == 'success' || steps.trivy.outcome == 'failure' }},
              "codeql": ${{ steps.codeql.outcome == 'success' || steps.codeql.outcome == 'failure' }},
              "docker": ${{ steps.docker-build.outcome == 'success' || steps.docker-build.outcome == 'failure' }}
            },
            "tools_success": {
              "jacoco": ${{ steps.java-coverage.outcome == 'success' }},
              "checkstyle": ${{ steps.java-checkstyle.outcome == 'success' }},
              "spotbugs": ${{ steps.java-spotbugs.outcome == 'success' }},
              "pmd": ${{ steps.java-pmd.outcome == 'success' }},
              "owasp": ${{ steps.java-owasp.outcome == 'success' }},
              "pitest": ${{ steps.java-mutation.outcome == 'success' }},
              "jqwik": ${{ steps.java-tests.outcome == 'success' }},
              "semgrep": ${{ steps.semgrep.outcome == 'success' }},
              "trivy": ${{ steps.trivy.outcome == 'success' }},
              "codeql": ${{ steps.codeql.outcome == 'success' }},
              "docker": ${{ steps.docker-build.outcome == 'success' }}
            }
          }
          EOF
          else
            TEST_STATUS="skipped"
            if [ "${{ matrix.run_pytest }}" = "true" ]; then
              FAILED_TESTS="${{ steps.python-tests.outputs.failed || 0 }}"
              if [ "${FAILED_TESTS:-0}" -gt 0 ]; then
                TEST_STATUS="failure"
              else
                TEST_STATUS="success"
              fi
            fi

            CRITICAL_VULNS=0
            HIGH_VULNS=${{ steps.python-pipaudit.outputs.vulnerabilities || 0 }}
            MEDIUM_VULNS=0

            TRIVY_CRITICAL=${{ steps.trivy.outputs.critical || 0 }}
            TRIVY_HIGH=${{ steps.trivy.outputs.high || 0 }}
            TRIVY_MEDIUM=0
            if [ -f "repo/trivy-report.json" ]; then
              TRIVY_MEDIUM=$(jq '[.Results[]?.Vulnerabilities[]? | select(.Severity == "MEDIUM")] | length' repo/trivy-report.json 2>/dev/null || echo 0)
            fi

            CRITICAL_VULNS=$((CRITICAL_VULNS + TRIVY_CRITICAL))
            HIGH_VULNS=$((HIGH_VULNS + TRIVY_HIGH))
            MEDIUM_VULNS=$((MEDIUM_VULNS + TRIVY_MEDIUM))

            cat > "$REPORT_DIR/report.json" << EOF
          {
            "schema_version": "2.0",
            "metadata": {
              "workflow_version": "v1.0.0",
              "workflow_ref": "${WORKFLOW_REF}",
              "generated_at": "${TIMESTAMP}"
            },
            "repository": "${{ matrix.owner }}/${{ matrix.name }}",
            "run_id": "${{ github.run_id }}",
            "run_number": "${{ github.run_number }}",
            "commit": "${COMMIT_SHA}",
            "branch": "${{ matrix.branch }}",
            "timestamp": "${TIMESTAMP}",
            "python_version": "${{ matrix.python_version }}",
            "results": {
              "test": "${TEST_STATUS}",
              "coverage": ${{ steps.python-tests.outputs.coverage || 0 }},
              "mutation_score": ${{ steps.python-mutmut.outputs.score || 0 }},
              "tests_passed": ${{ steps.python-tests.outputs.passed || 0 }},
              "tests_failed": ${{ steps.python-tests.outputs.failed || 0 }},
              "critical_vulns": ${CRITICAL_VULNS},
              "high_vulns": ${HIGH_VULNS},
              "medium_vulns": ${MEDIUM_VULNS}
            },
            "tool_metrics": {
              "ruff_errors": ${{ steps.python-ruff.outputs.errors || 0 }},
              "mypy_errors": ${{ steps.python-mypy.outputs.errors || 0 }},
              "bandit_high": ${{ steps.python-bandit.outputs.high || 0 }},
              "bandit_medium": ${{ steps.python-bandit.outputs.medium || 0 }},
              "black_issues": ${{ steps.python-black.outputs.issues || 0 }},
              "isort_issues": ${{ steps.python-isort.outputs.issues || 0 }},
              "pip_audit_vulns": ${{ steps.python-pipaudit.outputs.vulnerabilities || 0 }},
              "semgrep_findings": ${{ steps.semgrep.outputs.findings || 0 }},
              "trivy_critical": ${{ steps.trivy.outputs.critical || 0 }},
              "trivy_high": ${{ steps.trivy.outputs.high || 0 }}
            },
            "tools_configured": {
              "pytest": ${{ matrix.run_pytest }},
              "ruff": ${{ matrix.run_ruff }},
              "bandit": ${{ matrix.run_bandit }},
              "pip_audit": ${{ matrix.run_pip_audit }},
              "mypy": ${{ matrix.run_mypy }},
              "hypothesis": ${{ matrix.run_hypothesis }},
              "black": ${{ matrix.run_black }},
              "isort": ${{ matrix.run_isort }},
              "mutmut": ${{ matrix.run_mutmut }},
              "semgrep": ${{ matrix.run_semgrep }},
              "trivy": ${{ matrix.run_trivy }},
              "codeql": ${{ matrix.run_codeql }},
              "docker": ${{ matrix.run_docker }}
            },
            "tools_ran": {
              "pytest": ${{ steps.python-tests.outcome == 'success' || steps.python-tests.outcome == 'failure' }},
              "ruff": ${{ steps.python-ruff.outcome == 'success' || steps.python-ruff.outcome == 'failure' }},
              "bandit": ${{ steps.python-bandit.outcome == 'success' || steps.python-bandit.outcome == 'failure' }},
              "pip_audit": ${{ steps.python-pipaudit.outcome == 'success' || steps.python-pipaudit.outcome == 'failure' }},
              "mypy": ${{ steps.python-mypy.outcome == 'success' || steps.python-mypy.outcome == 'failure' }},
              "hypothesis": ${{ steps.python-hypothesis.outcome == 'success' || steps.python-hypothesis.outcome == 'failure' }},
              "black": ${{ steps.python-black.outcome == 'success' || steps.python-black.outcome == 'failure' }},
              "isort": ${{ steps.python-isort.outcome == 'success' || steps.python-isort.outcome == 'failure' }},
              "mutmut": ${{ steps.python-mutmut.outcome == 'success' || steps.python-mutmut.outcome == 'failure' }},
              "semgrep": ${{ steps.semgrep.outcome == 'success' || steps.semgrep.outcome == 'failure' }},
              "trivy": ${{ steps.trivy.outcome == 'success' || steps.trivy.outcome == 'failure' }},
              "codeql": ${{ steps.codeql.outcome == 'success' || steps.codeql.outcome == 'failure' }},
              "docker": ${{ steps.docker-build.outcome == 'success' || steps.docker-build.outcome == 'failure' }}
            },
            "tools_success": {
              "pytest": ${{ steps.python-tests.outcome == 'success' }},
              "ruff": ${{ steps.python-ruff.outcome == 'success' }},
              "bandit": ${{ steps.python-bandit.outcome == 'success' }},
              "pip_audit": ${{ steps.python-pipaudit.outcome == 'success' }},
              "mypy": ${{ steps.python-mypy.outcome == 'success' }},
              "hypothesis": ${{ steps.python-hypothesis.outcome == 'success' }},
              "black": ${{ steps.python-black.outcome == 'success' }},
              "isort": ${{ steps.python-isort.outcome == 'success' }},
              "mutmut": ${{ steps.python-mutmut.outcome == 'success' }},
              "semgrep": ${{ steps.semgrep.outcome == 'success' }},
              "trivy": ${{ steps.trivy.outcome == 'success' }},
              "codeql": ${{ steps.codeql.outcome == 'success' }},
              "docker": ${{ steps.docker-build.outcome == 'success' }}
            }
          }
          EOF
          fi

      - name: Validate Summary
        if: always()
        run: |
          REPORT_SUFFIX="${{ matrix.config_basename }}${{ matrix.subdir != '' && format('-{0}', matrix.subdir) || '' }}"
          REPORT_DIR="reports/${REPORT_SUFFIX}"
          python3 hub/scripts/validate_summary.py \
            --report "$REPORT_DIR/report.json" \
            --summary "$REPORT_DIR/summary.md" \
            --reports-dir repo \
            --strict

      # ========================================
      # UPLOAD ARTIFACTS
      # ========================================
      - name: Upload Test Reports
        if: always()
uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: reports-${{ matrix.config_basename }}${{ matrix.subdir != '' && format('-{0}', matrix.subdir) || '' }}
          path: |
            repo/**/target/surefire-reports/
            repo/**/target/site/jacoco/
            repo/**/target/pit-reports/
            repo/**/target/dependency-check-report.*
            repo/**/target/spotbugsXml.xml
            repo/**/target/checkstyle-result.xml
            repo/coverage.xml
            repo/htmlcov/
            repo/*-report.json
            repo/mutmut-*.log
            repo/mutmut-results.txt
            repo/mutmut-details.txt
            repo/mutmut-run.log
            repo/.mutmut-cache
            repo/pytest-junit.xml
            repo/test-output.txt
            repo/hypothesis-output.txt
            repo/black-output.txt
            repo/isort-output.txt
            repo/mypy-output.txt
            reports/**/report.json
            reports/**/summary.md
          retention-days: ${{ matrix.retention_days }}
          if-no-files-found: ignore

  # ============================================================================
  # Hub Summary
  # ============================================================================
  summary:
    name: Hub Summary
    runs-on: ubuntu-latest
    needs: [discover, test-repo]
    if: always()

    steps:
      - name: Generate Hub Summary
        run: |
          summary_file="$GITHUB_STEP_SUMMARY"
          exec 3> "$summary_file"
          cat >&3 << EOF
          # CI/CD Hub Summary

          **Total Repositories:** ${{ needs.discover.outputs.count }}
          **Run:** #${{ github.run_number }}
          **Triggered:** ${{ github.event_name }}

          ---

          See individual job summaries above for detailed QA metrics per repository.

          EOF
          exec 3>&-
