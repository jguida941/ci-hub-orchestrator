# ============================================================================
# CI/CD Hub - Main Orchestrator
# ============================================================================
# This workflow orchestrates CI/CD for all configured repositories.
# It reads config, triggers builds, and aggregates reports.
#
# Triggers:
#   - Manual dispatch (workflow_dispatch)
#   - Scheduled (e.g., nightly)
#   - When config changes
# ============================================================================

name: Hub Orchestrator

on:
  workflow_dispatch:
    inputs:
      repos:
        description: 'Comma-separated repo names (empty = all)'
        required: false
        type: string

  schedule:
    # Run nightly at 2 AM UTC
    - cron: '0 2 * * *'

  push:
    branches: [main, master]
    paths:
      - 'config/**'
      - '.github/workflows/hub-orchestrator.yml'

# Minimal default permissions - jobs override as needed
permissions:
  contents: read

# Prevent concurrent runs for the same ref
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # ============================================================================
  # Load Configuration
  # ============================================================================
  load-config:
    name: Load Repository Config
    runs-on: ubuntu-latest
    permissions:
      contents: read
    outputs:
      matrix: ${{ steps.config.outputs.matrix }}
      repo_count: ${{ steps.config.outputs.count }}

    steps:
      - name: Checkout Hub
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          fetch-depth: 1
          persist-credentials: false
          ref: ${{ github.sha }}

      - name: Set up Python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5
        with:
          python-version: '3.12'

      - name: Install Dependencies
        run: pip install pyyaml jsonschema

      - name: Generate Build Matrix
        id: config
        run: |
          python << 'EOF'
          import json
          import os
          import sys
          from pathlib import Path
          from scripts.load_config import load_config, generate_workflow_inputs

          hub_root = Path(".")
          repos_dir = hub_root / "config" / "repos"
          matrix_entries = []

          # Optional filter
          filter_repos = os.environ.get("INPUT_REPOS", "").strip()
          filter_list = [r.strip() for r in filter_repos.split(",")] if filter_repos else None

          for config_file in sorted(repos_dir.glob("*.yaml")):
              repo_name = config_file.stem
              try:
                  cfg = load_config(repo_name=repo_name, hub_root=hub_root)
              except SystemExit:
                  raise
              except Exception as exc:
                  print(f"Failed to load config {config_file}: {exc}", file=sys.stderr)
                  sys.exit(1)

              repo_info = cfg.get("repo", {})
              if not (repo_info.get("owner") and repo_info.get("name") and (repo_info.get("language") or cfg.get("language"))):
                  print(f"Skipping {config_file}: missing repo.owner/name/language")
                  continue
              if filter_list and repo_info.get("name", repo_name) not in filter_list:
                  continue

              inputs = generate_workflow_inputs(cfg)
              language = repo_info.get("language", cfg.get("language", "java"))
              # Default dispatch workflow: hub-ci.yml (generated by cihub init)
              default_workflow = "hub-ci.yml"
              entry = {
                  "config_file": str(config_file),
                  "config_basename": config_file.stem,  # Unique per config for artifact naming
                  "name": repo_info.get("name", repo_name),
                  "owner": repo_info.get("owner", "jguida941"),
                  "language": language,
                  "default_branch": repo_info.get("default_branch", "main"),
                  "subdir": repo_info.get("subdir", ""),
                  "dispatch_enabled": repo_info.get("dispatch_enabled", True),
                  "dispatch_workflow": repo_info.get("dispatch_workflow", default_workflow),
                  "run_group": repo_info.get("run_group", "full"),
              }
              entry.update(inputs)
              matrix_entries.append(entry)

          matrix = {"include": matrix_entries}

          with open(os.environ["GITHUB_OUTPUT"], "a") as f:
              f.write(f"matrix={json.dumps(matrix)}\n")
              f.write(f"count={len(matrix_entries)}\n")

          print(f"Found {len(matrix_entries)} repositories:")
          for r in matrix_entries:
              print(f"  - {r['owner']}/{r['name']} ({r['language']}) run_group={r.get('run_group','full')}")
          EOF
        env:
          INPUT_REPOS: ${{ inputs.repos || '' }}

      - name: Summary
        env:
          REPO_COUNT: ${{ steps.config.outputs.count }}
        run: |
          {
            echo "## Hub Orchestrator"
            echo ""
            echo "**Repositories to build:** $REPO_COUNT"
          } >> "$GITHUB_STEP_SUMMARY"

  # ============================================================================
  # Trigger Builds for Each Repo
  # ============================================================================
  trigger-builds:
    name: Build ${{ matrix.config_basename }}
    runs-on: ubuntu-latest
    needs: load-config
    if: needs.load-config.outputs.repo_count > 0
    permissions:
      contents: read
      actions: write  # For workflow dispatch
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.load-config.outputs.matrix) }}

    steps:
      - name: Checkout Hub
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          fetch-depth: 1
          persist-credentials: false
          ref: ${{ github.sha }}


      - name: Trigger Repository Workflow
        id: dispatch
        uses: actions/github-script@f28e40c7f34bde8b3046d885e986cb6290c5673b # v7
        env:
          # Pass matrix/step values via env vars to prevent expression injection
          MATRIX_OWNER: ${{ matrix.owner }}
          MATRIX_NAME: ${{ matrix.name }}
          MATRIX_LANGUAGE: ${{ matrix.language }}
          MATRIX_BRANCH: ${{ matrix.default_branch }}
          MATRIX_CONFIG_BASENAME: ${{ matrix.config_basename }}
          MATRIX_DISPATCH_ENABLED: ${{ matrix.dispatch_enabled }}
          MATRIX_DISPATCH_WORKFLOW: ${{ matrix.dispatch_workflow }}
          GH_RUN_ID: ${{ github.run_id }}
          GH_RUN_ATTEMPT: ${{ github.run_attempt }}
        with:
          github-token: ${{ secrets.HUB_DISPATCH_TOKEN || secrets.GITHUB_TOKEN }}
          script: |
            // Read values from environment variables (prevents expression injection)
            const owner = process.env.MATRIX_OWNER;
            const repo = process.env.MATRIX_NAME;
            const branch = process.env.MATRIX_BRANCH;
            const dispatchEnabled = (process.env.MATRIX_DISPATCH_ENABLED || '').toLowerCase() !== 'false';
            const correlationId = `${process.env.GH_RUN_ID}-${process.env.GH_RUN_ATTEMPT || '1'}-${process.env.MATRIX_CONFIG_BASENAME}`;

            if (!dispatchEnabled) {
              core.info(`Dispatch disabled for ${owner}/${repo}; skipping dispatch.`);
              return;
            }

            const inputs = { hub_correlation_id: correlationId };
            const MAX_POLL_MS = 30 * 60 * 1000; // 30 minutes

            // Use configurable workflow name from matrix, with fallback to hub-ci.yml
            const workflowId = process.env.MATRIX_DISPATCH_WORKFLOW || 'hub-ci.yml';
            const startedAt = Date.now();

            core.info(`Dispatching ${workflowId} on ${owner}/${repo}@${branch}`);
            try {
              await github.rest.actions.createWorkflowDispatch({
                owner,
                repo,
                workflow_id: workflowId,
                ref: branch,
                inputs,
              });
            } catch (err) {
              core.setFailed(`Dispatch failed for ${owner}/${repo}: ${err.message}`);
              throw err;
            }

            let runId = '';
            let pollDelay = 5000;
            const deadline = startedAt + MAX_POLL_MS;

            while (Date.now() < deadline) {
              await new Promise((resolve) => setTimeout(resolve, pollDelay));
              const runs = await github.rest.actions.listWorkflowRuns({
                owner,
                repo,
                workflow_id: workflowId,
                event: 'workflow_dispatch',
                branch,
                per_page: 5,
              });

            const recent = runs.data.workflow_runs.find((run) => {
                const created = new Date(run.created_at).getTime();
                return (
                  created >= startedAt - 2000 && // tighter window to reduce collisions
                  run.head_branch === branch &&
                  run.status !== 'completed'
                );
              });

              if (recent) {
                runId = String(recent.id);
                core.info(`Captured run id ${runId} for ${repo}`);
                break;
              }

              pollDelay = Math.min(pollDelay * 2, 30000); // backoff up to 30s
            }

            if (!runId) {
              core.setFailed(`Dispatched ${workflowId} for ${repo}, but could not determine run id.`);
              return;
            }

            core.setOutput('run_id', runId);
            core.setOutput('branch', branch);
            core.setOutput('workflow_id', workflowId);
            core.setOutput('correlation_id', correlationId);

      - name: Record Build Trigger
        env:
          MATRIX_NAME: ${{ matrix.name }}
          MATRIX_OWNER: ${{ matrix.owner }}
          MATRIX_LANGUAGE: ${{ matrix.language }}
          MATRIX_BRANCH: ${{ matrix.default_branch }}
          STEP_WORKFLOW_ID: ${{ steps.dispatch.outputs.workflow_id }}
          STEP_RUN_ID: ${{ steps.dispatch.outputs.run_id }}
        run: |
          {
            echo "## $MATRIX_NAME"
            echo ""
            echo "- **Owner:** $MATRIX_OWNER"
            echo "- **Language:** $MATRIX_LANGUAGE"
            echo "- **Branch:** $MATRIX_BRANCH"
            echo "- **Workflow:** $STEP_WORKFLOW_ID"
            echo "- **Run ID:** ${STEP_RUN_ID:-pending}"
            echo "- **Status:** Triggered"
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Save Dispatch Metadata
        if: always()
        env:
          MATRIX_CONFIG_BASENAME: ${{ matrix.config_basename }}
          MATRIX_OWNER: ${{ matrix.owner }}
          MATRIX_NAME: ${{ matrix.name }}
          MATRIX_SUBDIR: ${{ matrix.subdir }}
          MATRIX_LANGUAGE: ${{ matrix.language }}
          MATRIX_BRANCH: ${{ matrix.default_branch }}
          STEP_WORKFLOW_ID: ${{ steps.dispatch.outputs.workflow_id }}
          STEP_RUN_ID: ${{ steps.dispatch.outputs.run_id }}
          STEP_CORRELATION_ID: ${{ steps.dispatch.outputs.correlation_id }}
          JOB_STATUS: ${{ job.status }}
        run: |
          mkdir -p dispatch-results
          cat > "dispatch-results/${MATRIX_CONFIG_BASENAME}.json" << EOF
          {
            "config": "${MATRIX_CONFIG_BASENAME}",
            "repo": "${MATRIX_OWNER}/${MATRIX_NAME}",
            "subdir": "${MATRIX_SUBDIR}",
            "language": "${MATRIX_LANGUAGE}",
            "branch": "${MATRIX_BRANCH}",
            "workflow": "${STEP_WORKFLOW_ID}",
            "run_id": "${STEP_RUN_ID}",
            "correlation_id": "${STEP_CORRELATION_ID}",
            "dispatch_time": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
            "status": "${JOB_STATUS}"
          }
          EOF

      - name: Upload Dispatch Metadata
        if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: dispatch-${{ matrix.config_basename }}-${{ github.run_id }}
          path: dispatch-results/${{ matrix.config_basename }}.json
          retention-days: 7

  # ============================================================================
  # Aggregate Reports
  # ============================================================================
  aggregate-reports:
    name: Aggregate Reports
    runs-on: ubuntu-latest
    needs: [load-config, trigger-builds]
    if: always()
    permissions:
      contents: read
      actions: read  # For reading run artifacts

    steps:
      - name: Checkout Hub
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          fetch-depth: 1
          persist-credentials: false
          ref: ${{ github.sha }}

      - name: Set up Python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5
        with:
          python-version: '3.12'

      - name: Install Dependencies
        run: pip install pyyaml

      - name: Download Dispatch Metadata
        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093 # v4
        with:
          path: dispatch-artifacts
        continue-on-error: true

      - name: Generate Hub Summary and Report
        env:
          TOTAL_REPOS: ${{ needs.load-config.outputs.repo_count }}
          HUB_RUN_ID: ${{ github.run_id }}
          HUB_EVENT: ${{ github.event_name }}
          # Use HUB_DISPATCH_TOKEN for cross-repo artifact access
          HUB_DISPATCH_TOKEN: ${{ secrets.HUB_DISPATCH_TOKEN }}
        run: |
          if [ -z "${HUB_DISPATCH_TOKEN}" ]; then
            echo "::error::HUB_DISPATCH_TOKEN is required for cross-repo artifact access"
            exit 1
          fi
          python << 'EOF'
          import json
          import os
          from datetime import datetime, timezone
          from pathlib import Path
          from urllib import request
          import time
          import zipfile
          import tempfile

          token = os.environ.get("HUB_DISPATCH_TOKEN")
          if not token:
              print("Missing HUB_DISPATCH_TOKEN for aggregation", flush=True)
              exit(1)

          def gh_get(url: str, retries: int = 3, backoff: float = 2.0) -> dict:
              attempt = 0
              while True:
                  try:
                      req = request.Request(
                          url,
                          headers={
                              "Authorization": f"Bearer {token}",
                              "Accept": "application/vnd.github+json",
                              "X-GitHub-Api-Version": "2022-11-28",
                          },
                      )
                      with request.urlopen(req) as resp:
                          return json.loads(resp.read().decode())
                  except Exception as exc:  # noqa: PIE786
                      attempt += 1
                      if attempt > retries:
                          raise
                      sleep_for = backoff * attempt
                      print(f"Retry {attempt}/{retries} for {url} after error: {exc} (sleep {sleep_for}s)")
                      time.sleep(sleep_for)

          def download_artifact(archive_url: str, target_dir: Path) -> Path | None:
              req = request.Request(
                  archive_url,
                  headers={
                      "Authorization": f"Bearer {token}",
                      "Accept": "application/vnd.github+json",
                      "X-GitHub-Api-Version": "2022-11-28",
                  },
              )
              try:
                  with request.urlopen(req) as resp:
                      data = resp.read()
                  target_dir.mkdir(parents=True, exist_ok=True)
                  zip_path = target_dir / "artifact.zip"
                  zip_path.write_bytes(data)
                  with zipfile.ZipFile(zip_path, "r") as zf:
                      zf.extractall(target_dir)
                  return target_dir
              except Exception as exc:  # noqa: PIE786
                  print(f"Warning: failed to download artifact {archive_url}: {exc}")
                  return None

          meta_dir = Path("dispatch-artifacts")
          entries = []
          for path in meta_dir.rglob("*.json"):
              try:
                  data = json.loads(path.read_text())
                  data["_source"] = str(path)
                  entries.append(data)
              except Exception as exc:  # noqa: PIE786
                  print(f"Warning: could not read {path}: {exc}")

          def find_run_by_correlation_id(owner: str, repo: str, workflow_id: str, correlation_id: str) -> str | None:
              """
              Deterministic run matching: search recent runs and match by hub_correlation_id in artifact.
              Returns run_id if found, None otherwise.
              """
              if not correlation_id:
                  return None
              try:
                  # List recent workflow runs
                  runs_url = f"https://api.github.com/repos/{owner}/{repo}/actions/workflows/{workflow_id}/runs?per_page=20&event=workflow_dispatch"
                  runs_data = gh_get(runs_url)
                  for run in runs_data.get("workflow_runs", []):
                      run_id = run.get("id")
                      if not run_id:
                          continue
                      # Check artifacts for this run
                      try:
                          artifacts = gh_get(f"https://api.github.com/repos/{owner}/{repo}/actions/runs/{run_id}/artifacts")
                          ci_artifact = next((a for a in artifacts.get("artifacts", []) if a.get("name", "").endswith("ci-report")), None)
                          if ci_artifact:
                              with tempfile.TemporaryDirectory() as tmpdir:
                                  extracted = download_artifact(ci_artifact["archive_download_url"], Path(tmpdir))
                                  if extracted:
                                      report_file = next(iter(Path(extracted).rglob("report.json")), None)
                                      if report_file and report_file.exists():
                                          report_data = json.loads(report_file.read_text())
                                          if report_data.get("hub_correlation_id") == correlation_id:
                                              print(f"Found matching run {run_id} for correlation_id {correlation_id}")
                                              return str(run_id)
                      except Exception as e:
                          print(f"Warning: error checking run {run_id} artifacts: {e}")
                          continue
              except Exception as e:
                  print(f"Warning: error searching runs for correlation_id {correlation_id}: {e}")
              return None

          # Poll runs and collect artifacts/metrics
          results = []
          pending_statuses = {"queued", "in_progress", "waiting", "pending"}
          poll_timeout_sec = 30 * 60  # 30 minutes
          for entry in entries:
              repo_full = entry.get("repo", "unknown/unknown")
              owner_repo = repo_full.split("/")
              if len(owner_repo) != 2:
                  print(f"Invalid repo format in entry: {repo_full}")
                  continue
              owner, repo = owner_repo
              run_id = entry.get("run_id")
              language = entry.get("language")
              branch = entry.get("branch")
              workflow = entry.get("workflow")

              run_status = {
                  "config": entry.get("config", repo),
                  "repo": repo_full,
                  "subdir": entry.get("subdir", ""),
                  "language": language,
                  "branch": branch,
                  "workflow": workflow,
                  "run_id": run_id or "",
                  "correlation_id": entry.get("correlation_id", ""),
                  "status": "missing_run_id" if not run_id else "unknown",
                  "conclusion": "unknown",
                  # Common quality metrics
                  "coverage": None,
                  "mutation_score": None,
                  # Java-specific tools
                  "checkstyle_issues": None,
                  "spotbugs_issues": None,
                  "pmd_violations": None,
                  "owasp_critical": None,
                  "owasp_high": None,
                  "owasp_medium": None,
                  # Python-specific tools
                  "tests_passed": None,
                  "tests_failed": None,
                  "ruff_errors": None,
                  "black_issues": None,
                  "isort_issues": None,
                  "mypy_errors": None,
                  "bandit_high": None,
                  "bandit_medium": None,
                  "pip_audit_vulns": None,
                  # Cross-language security tools
                  "semgrep_findings": None,
                  "trivy_critical": None,
                  "trivy_high": None,
                  # Track which tools ran
                  "tools_ran": {},
              }

              # Deterministic correlation: if run_id is missing, search by correlation_id
              expected_corr = entry.get("correlation_id", "")
              if not run_id and expected_corr and workflow:
                  print(f"No run_id for {repo_full}, searching by correlation_id {expected_corr}...")
                  found_run_id = find_run_by_correlation_id(owner, repo, workflow, expected_corr)
                  if found_run_id:
                      run_id = found_run_id
                      run_status["run_id"] = run_id
                      run_status["status"] = "unknown"  # Reset status, will be updated by polling
                      print(f"Found run_id {run_id} for {repo_full} via correlation_id")
                  else:
                      print(f"Could not find run by correlation_id for {repo_full}")

              if not run_id:
                  results.append(run_status)
                  continue

              try:
                  url = f"https://api.github.com/repos/{owner}/{repo}/actions/runs/{run_id}"
                  start_poll = time.time()
                  delay = 10
                  while True:
                      run = gh_get(url)
                      status = run.get("status", "unknown")
                      conclusion = run.get("conclusion", "unknown")
                      run_status["status"] = status
                      run_status["conclusion"] = conclusion

                      if status not in pending_statuses:
                          break

                      if time.time() - start_poll > poll_timeout_sec:
                          run_status["status"] = "timed_out"
                          run_status["conclusion"] = "timed_out"
                          break

                      time.sleep(delay)
                      delay = min(delay * 1.5, 60)
              except Exception as exc:  # noqa: PIE786
                  print(f"Warning: could not fetch run {run_id} for {repo_full}: {exc}")
                  run_status["status"] = "fetch_failed"
                  results.append(run_status)
                  continue

              # If completed, try to download artifacts even on failure to capture report.json
              if run_status["status"] == "completed":
                  try:
                      artifacts = gh_get(f"https://api.github.com/repos/{owner}/{repo}/actions/runs/{run_id}/artifacts")
                      ci_artifacts = artifacts.get("artifacts", [])
                      # Prefer artifact ending with ci-report (handles prefix like 'python-passing-ci-report')
                      artifact = next((a for a in ci_artifacts if a.get("name", "").endswith("ci-report")), None)
                      if not artifact and ci_artifacts:
                          # Fallback to first artifact containing 'report'
                          artifact = next((a for a in ci_artifacts if "report" in a.get("name", "")), ci_artifacts[0])
                      if artifact:
                          with tempfile.TemporaryDirectory() as tmpdir:
                              extracted = download_artifact(artifact["archive_download_url"], Path(tmpdir))
                              if extracted:
                                  report_file = next(iter(Path(extracted).rglob("report.json")), None)
                                  if report_file and report_file.exists():
                                      try:
                                          report_data = json.loads(report_file.read_text())
                                          report_corr = report_data.get("hub_correlation_id", "")
                                          run_status["correlation_id"] = report_corr or expected_corr
                                          if expected_corr and report_corr and report_corr != expected_corr:
                                              print(
                                                  f"Correlation mismatch for {repo_full} run {run_id} "
                                                  f"(expected {expected_corr}, got {report_corr}); searching for correct run..."
                                              )
                                              # Try to find the correct run by correlation ID
                                              correct_run_id = find_run_by_correlation_id(owner, repo, workflow, expected_corr)
                                              if correct_run_id and correct_run_id != run_id:
                                                  print(f"Found correct run {correct_run_id}, re-fetching artifacts...")
                                                  # Re-fetch artifact from correct run
                                                  correct_artifacts = gh_get(f"https://api.github.com/repos/{owner}/{repo}/actions/runs/{correct_run_id}/artifacts")
                                                  correct_ci_artifact = next((a for a in correct_artifacts.get("artifacts", []) if a.get("name", "").endswith("ci-report")), None)
                                                  if correct_ci_artifact:
                                                      with tempfile.TemporaryDirectory() as tmpdir2:
                                                          extracted2 = download_artifact(correct_ci_artifact["archive_download_url"], Path(tmpdir2))
                                                          if extracted2:
                                                              report_file2 = next(iter(Path(extracted2).rglob("report.json")), None)
                                                              if report_file2 and report_file2.exists():
                                                                  report_data = json.loads(report_file2.read_text())
                                                                  run_status["run_id"] = correct_run_id
                                                                  run_status["correlation_id"] = expected_corr
                                                                  # Continue processing with correct report_data
                                              else:
                                                  print(f"Could not find correct run for {repo_full}, skipping artifact.")
                                                  continue
                                          results_data = report_data.get("results", {}) or {}
                                          tool_metrics = report_data.get("tool_metrics", {}) or {}
                                          # Common quality metrics
                                          run_status["coverage"] = results_data.get("coverage")
                                          run_status["mutation_score"] = results_data.get("mutation_score")
                                          # Java-specific tools
                                          run_status["checkstyle_issues"] = tool_metrics.get("checkstyle_issues")
                                          run_status["spotbugs_issues"] = tool_metrics.get("spotbugs_issues")
                                          run_status["pmd_violations"] = tool_metrics.get("pmd_violations")
                                          run_status["owasp_critical"] = tool_metrics.get("owasp_critical")
                                          run_status["owasp_high"] = tool_metrics.get("owasp_high")
                                          run_status["owasp_medium"] = tool_metrics.get("owasp_medium")
                                          # Python-specific tools
                                          run_status["tests_passed"] = results_data.get("tests_passed")
                                          run_status["tests_failed"] = results_data.get("tests_failed")
                                          run_status["ruff_errors"] = tool_metrics.get("ruff_errors")
                                          run_status["black_issues"] = tool_metrics.get("black_issues")
                                          run_status["isort_issues"] = tool_metrics.get("isort_issues")
                                          run_status["mypy_errors"] = tool_metrics.get("mypy_errors")
                                          run_status["bandit_high"] = tool_metrics.get("bandit_high")
                                          run_status["bandit_medium"] = tool_metrics.get("bandit_medium")
                                          run_status["pip_audit_vulns"] = tool_metrics.get("pip_audit_vulns")
                                          # Cross-language security tools
                                          run_status["semgrep_findings"] = tool_metrics.get("semgrep_findings")
                                          run_status["trivy_critical"] = tool_metrics.get("trivy_critical")
                                          run_status["trivy_high"] = tool_metrics.get("trivy_high")
                                          # Track tool execution status
                                          run_status["tools_ran"] = report_data.get("tools_ran", {})
                                          run_status["tools_configured"] = report_data.get("tools_configured", {})
                                          run_status["tools_success"] = report_data.get("tools_success", {})
                                      except Exception as exc:  # noqa: PIE786
                                          print(f"Warning: could not parse report.json from {artifact['name']}: {exc}")
                  except Exception as exc:  # noqa: PIE786
                      print(f"Warning: failed to fetch artifacts for run {run_id} in {repo_full}: {exc}")

              results.append(run_status)

          total_repos = int(os.environ.get("TOTAL_REPOS") or 0)
          dispatched = len(results)
          missing = max(total_repos - dispatched, 0)
          missing_run_id = len([e for e in results if not e.get("run_id")])

          failed_runs = [
              r for r in results
              if r.get("status") in ("missing_run_id", "fetch_failed")
              or (r.get("status") == "completed" and r.get("conclusion") != "success")
              or r.get("status") not in ("completed",)
          ]

          report = {
              "hub_run_id": os.environ.get("HUB_RUN_ID"),
              "timestamp": datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ"),
              "triggered_by": os.environ.get("HUB_EVENT"),
              "total_repos": total_repos,
              "dispatched_repos": dispatched,
              "missing_dispatch_metadata": missing,
              "runs": results,
          }

          # Helper to collect numeric values (ignores None)
          def collect_values(key):
              return [r[key] for r in results if isinstance(r.get(key), (int, float))]

          # Aggregated quality metrics
          coverages = collect_values("coverage")
          mutations = collect_values("mutation_score")

          if coverages:
              report["coverage_average"] = round(sum(coverages) / len(coverages), 1)
          if mutations:
              report["mutation_average"] = round(sum(mutations) / len(mutations), 1)

          # Aggregated vulnerability metrics (OWASP for Java, Bandit/pip-audit for Python, Trivy/Semgrep for both)
          owasp_critical = collect_values("owasp_critical")
          owasp_high = collect_values("owasp_high")
          owasp_medium = collect_values("owasp_medium")
          bandit_high = collect_values("bandit_high")
          bandit_medium = collect_values("bandit_medium")
          pip_audit_vulns = collect_values("pip_audit_vulns")
          trivy_critical = collect_values("trivy_critical")
          trivy_high = collect_values("trivy_high")
          semgrep_findings = collect_values("semgrep_findings")

          # Total critical/high across all security tools
          report["total_critical_vulns"] = sum(owasp_critical) + sum(trivy_critical)
          report["total_high_vulns"] = sum(owasp_high) + sum(bandit_high) + sum(trivy_high)
          report["total_medium_vulns"] = sum(owasp_medium) + sum(bandit_medium)
          report["total_pip_audit_vulns"] = sum(pip_audit_vulns)
          report["total_semgrep_findings"] = sum(semgrep_findings)

          # Aggregated code quality metrics
          checkstyle_issues = collect_values("checkstyle_issues")
          spotbugs_issues = collect_values("spotbugs_issues")
          pmd_violations = collect_values("pmd_violations")
          ruff_errors = collect_values("ruff_errors")
          black_issues = collect_values("black_issues")
          isort_issues = collect_values("isort_issues")
          mypy_errors = collect_values("mypy_errors")

          report["total_code_quality_issues"] = (
              sum(checkstyle_issues) + sum(spotbugs_issues) + sum(pmd_violations) +
              sum(ruff_errors) + sum(black_issues) + sum(isort_issues) + sum(mypy_errors)
          )

          # Aggregate tool stats across all repos
          tool_stats = {}
          for r in results:
              tools_configured = r.get("tools_configured", {})
              tools_ran = r.get("tools_ran", {})
              tools_success = r.get("tools_success", {})
              for tool, configured in tools_configured.items():
                  if tool not in tool_stats:
                      tool_stats[tool] = {"configured": 0, "ran": 0, "passed": 0, "failed": 0}
                  if configured:
                      tool_stats[tool]["configured"] += 1
                  if tools_ran.get(tool):
                      tool_stats[tool]["ran"] += 1
                  if tools_success.get(tool):
                      tool_stats[tool]["passed"] += 1
                  elif tools_ran.get(tool):
                      tool_stats[tool]["failed"] += 1
          report["tool_stats"] = tool_stats

          Path("hub-report.json").write_text(json.dumps(report, indent=2))

          # Helper to format metric (None -> "-", else value)
          def fmt(val, suffix=""):
              return f"{val}{suffix}" if val is not None else "-"

          summary_lines = [
              "# CI/CD Hub Report",
              "",
              f"**Run ID:** {report['hub_run_id']}",
              f"**Timestamp:** {report['timestamp']}",
              "",
              "## Dispatch Status",
              f"- Total configs: {total_repos}",
              f"- Successfully dispatched: {dispatched}",
              f"- Missing metadata: {missing}",
              f"- Missing run IDs: {missing_run_id}",
              "",
          ]

          # Separate Java and Python results
          java_results = [r for r in results if r.get("language") == "java"]
          python_results = [r for r in results if r.get("language") == "python"]

          # Java Results Table
          if java_results:
              summary_lines.extend([
                  "## Java Repos",
                  "",
                  "| Config | Status | Cov | Mut | CS | SB | PMD | OWASP | Semgrep | Trivy |",
                  "|--------|--------|-----|-----|----|----|-----|-------|---------|-------|",
              ])
              for entry in java_results:
                  config = entry.get('config', entry.get('repo', 'unknown').split('/')[-1])
                  status = entry.get('conclusion', entry.get('status', 'unknown'))
                  status_label = "PASS" if status == "success" else "FAIL" if status in ("failure", "failed") else "PENDING"

                  cov = fmt(entry.get('coverage'), '%')
                  mut = fmt(entry.get('mutation_score'), '%')
                  cs = fmt(entry.get('checkstyle_issues'))
                  sb = fmt(entry.get('spotbugs_issues'))
                  pmd = fmt(entry.get('pmd_violations'))

                  oc = entry.get('owasp_critical')
                  oh = entry.get('owasp_high')
                  om = entry.get('owasp_medium')
                  owasp = f"{oc or 0}/{oh or 0}/{om or 0}" if any(v is not None for v in [oc, oh, om]) else "-"

                  sem = fmt(entry.get('semgrep_findings'))

                  tc = entry.get('trivy_critical')
                  th = entry.get('trivy_high')
                  trivy = f"{tc or 0}/{th or 0}" if any(v is not None for v in [tc, th]) else "-"

                  summary_lines.append(f"| {config} | {status_label} | {cov} | {mut} | {cs} | {sb} | {pmd} | {owasp} | {sem} | {trivy} |")
              summary_lines.append("")

          # Python Results Table
          if python_results:
              summary_lines.extend([
                  "## Python Repos",
                  "",
                  "| Config | Status | Cov | Mut | Tests | Ruff | Black | isort | mypy | Bandit | pip-audit | Semgrep | Trivy |",
                  "|--------|--------|-----|-----|-------|------|-------|-------|------|--------|-----------|---------|-------|",
              ])
              for entry in python_results:
                  config = entry.get('config', entry.get('repo', 'unknown').split('/')[-1])
                  status = entry.get('conclusion', entry.get('status', 'unknown'))
                  status_label = "PASS" if status == "success" else "FAIL" if status in ("failure", "failed") else "PENDING"

                  cov = fmt(entry.get('coverage'), '%')
                  mut = fmt(entry.get('mutation_score'), '%')

                  tp = entry.get('tests_passed')
                  tf = entry.get('tests_failed')
                  tests = f"{tp or 0} pass/{tf or 0} fail" if any(v is not None for v in [tp, tf]) else "-"

                  ruff = fmt(entry.get('ruff_errors'))
                  black = fmt(entry.get('black_issues'))
                  isort = fmt(entry.get('isort_issues'))
                  mypy = fmt(entry.get('mypy_errors'))

                  bh = entry.get('bandit_high')
                  bm = entry.get('bandit_medium')
                  bandit = f"{bh or 0}/{bm or 0}" if any(v is not None for v in [bh, bm]) else "-"

                  pip = fmt(entry.get('pip_audit_vulns'))
                  sem = fmt(entry.get('semgrep_findings'))

                  tc = entry.get('trivy_critical')
                  th = entry.get('trivy_high')
                  trivy = f"{tc or 0}/{th or 0}" if any(v is not None for v in [tc, th]) else "-"

                  summary_lines.append(f"| {config} | {status_label} | {cov} | {mut} | {tests} | {ruff} | {black} | {isort} | {mypy} | {bandit} | {pip} | {sem} | {trivy} |")
              summary_lines.append("")

          # Aggregated Metrics
          summary_lines.extend([
              "## Aggregated Metrics",
              "",
              "### Quality",
          ])
          if "coverage_average" in report:
              summary_lines.append(f"- **Average Coverage:** {report['coverage_average']}%")
          if "mutation_average" in report:
              summary_lines.append(f"- **Average Mutation Score:** {report['mutation_average']}%")
          summary_lines.append(f"- **Total Code Quality Issues:** {report['total_code_quality_issues']}")

          summary_lines.extend([
              "",
              "### Security",
              f"- **Critical Vulnerabilities (OWASP+Trivy):** {report['total_critical_vulns']}",
              f"- **High Vulnerabilities (OWASP+Bandit+Trivy):** {report['total_high_vulns']}",
              f"- **Medium Vulnerabilities (OWASP+Bandit):** {report['total_medium_vulns']}",
              f"- **pip-audit Vulnerabilities:** {report['total_pip_audit_vulns']}",
              f"- **Semgrep Findings:** {report['total_semgrep_findings']}",
          ])

          # Tool Stats Aggregate Table
          if tool_stats:
              # Define tool categories for display
              tool_categories = {
                  # Java tools
                  "jacoco": ("Testing", "JaCoCo Coverage"),
                  "pitest": ("Testing", "PITest"),
                  "jqwik": ("Testing", "jqwik"),
                  "checkstyle": ("Linting", "Checkstyle"),
                  "spotbugs": ("Linting", "SpotBugs"),
                  "pmd": ("Linting", "PMD"),
                  "owasp": ("Security", "OWASP"),
                  # Python tools
                  "pytest": ("Testing", "pytest"),
                  "mutmut": ("Testing", "mutmut"),
                  "hypothesis": ("Testing", "Hypothesis"),
                  "ruff": ("Linting", "Ruff"),
                  "black": ("Linting", "Black"),
                  "isort": ("Linting", "isort"),
                  "mypy": ("Linting", "mypy"),
                  "bandit": ("Security", "Bandit"),
                  "pip_audit": ("Security", "pip-audit"),
                  # Cross-language
                  "semgrep": ("Security", "Semgrep"),
                  "trivy": ("Security", "Trivy"),
                  "codeql": ("Security", "CodeQL"),
                  "docker": ("Container", "Docker"),
              }

              summary_lines.extend([
                  "",
                  "## Tools Summary (Aggregate)",
                  "",
                  "| Category | Tool | Configured | Ran | Passed | Failed |",
                  "|----------|------|------------|-----|--------|--------|",
              ])

              for tool, stats in sorted(tool_stats.items()):
                  category, display_name = tool_categories.get(tool, ("Other", tool))
                  summary_lines.append(
                      f"| {category} | {display_name} | "
                      f"{stats['configured']}/{total_repos} | "
                      f"{stats['ran']}/{stats['configured']} | "
                      f"{stats['passed']} | {stats['failed']} |"
                  )
              summary_lines.append("")

          summary_path = Path(os.environ["GITHUB_STEP_SUMMARY"])
          summary_path.write_text("\n".join(summary_lines))

          # Load thresholds from defaults.yaml
          import yaml
          max_critical_vulns = 0
          max_high_vulns = 0
          defaults_path = Path("config/defaults.yaml")
          if defaults_path.exists():
              try:
                  defaults = yaml.safe_load(defaults_path.read_text())
                  thresholds = defaults.get("thresholds", {})
                  max_critical_vulns = thresholds.get("max_critical_vulns", 0)
                  max_high_vulns = thresholds.get("max_high_vulns", 0)
              except Exception as exc:  # noqa: PIE786
                  print(f"Warning: could not load thresholds from defaults.yaml: {exc}")

          # Check vulnerability thresholds
          threshold_exceeded = False
          if report["total_critical_vulns"] > max_critical_vulns:
              print(f"THRESHOLD EXCEEDED: Critical vulnerabilities {report['total_critical_vulns']} > {max_critical_vulns}", flush=True)
              threshold_exceeded = True
          if report["total_high_vulns"] > max_high_vulns:
              print(f"THRESHOLD EXCEEDED: High vulnerabilities {report['total_high_vulns']} > {max_high_vulns}", flush=True)
              threshold_exceeded = True

          # Fail the job if any run failed, metadata is missing, or thresholds exceeded
          if failed_runs or missing > 0 or threshold_exceeded:
              if failed_runs:
                  print("Aggregation detected failures.", flush=True)
              if missing > 0:
                  print("Aggregation detected missing data.", flush=True)
              if threshold_exceeded:
                  print("Vulnerability thresholds exceeded.", flush=True)
              print("Failing job.", flush=True)
              exit(1)
          EOF

      - name: Upload Hub Report
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: hub-report-${{ github.run_id }}
          path: hub-report.json
          retention-days: 30
