# ============================================================================
# CI/CD Hub - Reusable Java CI Workflow
# ============================================================================
# Call this workflow from any Java repository to run the full CI pipeline.
#
# Usage in your repo's workflow:
#   jobs:
#     ci:
#       uses: jguida941/ci-cd-hub/.github/workflows/java-ci.yml@main
#       with:
#         java_version: '21'
#         run_pitest: true
#         run_docker: false
#       secrets: inherit
# ============================================================================

name: Java CI Pipeline

on:
  workflow_call:
    inputs:
      # ---- Java Settings ----
      java_version:
        description: 'Java version'
        type: string
        default: '21'
      build_tool:
        description: 'Build tool (maven or gradle)'
        type: string
        default: 'maven'

      # ---- Tool Toggles ----
      run_jacoco:
        description: 'Run JaCoCo coverage'
        type: boolean
        default: true
      run_checkstyle:
        description: 'Run Checkstyle'
        type: boolean
        default: true
      run_spotbugs:
        description: 'Run SpotBugs'
        type: boolean
        default: true
      run_owasp:
        description: 'Run OWASP Dependency Check'
        type: boolean
        default: true
      run_pitest:
        description: 'Run PITest mutation testing'
        type: boolean
        default: true
      run_codeql:
        description: 'Run CodeQL analysis (expensive)'
        type: boolean
        default: false
      run_pmd:
        description: 'Run PMD static analysis'
        type: boolean
        default: true
      run_semgrep:
        description: 'Run Semgrep SAST (expensive)'
        type: boolean
        default: false
      run_trivy:
        description: 'Run Trivy container scan (expensive)'
        type: boolean
        default: false
      run_docker:
        description: 'Build and test Docker'
        type: boolean
        default: false

      # ---- Thresholds ----
      coverage_min:
        description: 'Minimum coverage percentage'
        type: number
        default: 70
      mutation_score_min:
        description: 'Minimum mutation score'
        type: number
        default: 70
      owasp_cvss_fail:
        description: 'CVSS score to fail on'
        type: number
        default: 7
      max_critical_vulns:
        description: 'Maximum allowed critical vulnerabilities across scanners'
        type: number
        default: 0
      max_high_vulns:
        description: 'Maximum allowed high vulnerabilities across scanners'
        type: number
        default: 0
      max_semgrep_findings:
        description: 'Maximum allowed Semgrep findings (default: 0 = fail on any)'
        type: number
        default: 0
      max_pmd_violations:
        description: 'Maximum allowed PMD violations (default: 0 = fail on any)'
        type: number
        default: 0
      max_checkstyle_errors:
        description: 'Maximum allowed Checkstyle errors (default: 0 = fail on any)'
        type: number
        default: 0
      max_spotbugs_bugs:
        description: 'Maximum allowed SpotBugs bugs (default: 0 = fail on any)'
        type: number
        default: 0

      # ---- Docker Settings ----
      docker_compose_file:
        description: 'Docker compose file path'
        type: string
        default: 'docker-compose.yml'
      docker_health_endpoint:
        description: 'Health check endpoint'
        type: string
        default: '/actuator/health'

      # ---- Reports ----
      retention_days:
        description: 'Artifact retention days'
        type: number
        default: 30
      workdir:
        description: 'Working directory (monorepo subfolder, default repo root)'
        type: string
        default: '.'
      artifact_prefix:
        description: 'Prefix for artifact names (use when calling multiple times in same workflow)'
        type: string
        default: ''

    secrets:
      NVD_API_KEY:
        required: false
      CODECOV_TOKEN:
        required: false

    outputs:
      build_status:
        description: 'Build result'
        value: ${{ jobs.build-test.outputs.status }}
      coverage:
        description: 'Coverage percentage'
        value: ${{ jobs.build-test.outputs.coverage }}
      mutation_score:
        description: 'Mutation score'
        value: ${{ jobs.mutation-test.outputs.score }}

jobs:
  # ============================================================================
  # Build & Test
  # ============================================================================
  build-test:
    name: Build & Test
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ${{ inputs.workdir }}
    outputs:
      status: ${{ steps.build.outcome }}
      coverage: ${{ steps.coverage.outputs.percentage }}
      tests_passed: ${{ steps.test-counts.outputs.passed }}
      tests_failed: ${{ steps.test-counts.outputs.failed }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install jq
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: Set up JDK ${{ inputs.java_version }}
        uses: actions/setup-java@v4
        with:
          java-version: ${{ inputs.java_version }}
          distribution: 'temurin'
          cache: ${{ inputs.build_tool }}

      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Configuration Summary
        run: |
          {
            echo "# Configuration Summary"
            echo ""
            echo "## Tools Enabled"
            echo "| Category | Tool | Enabled |"
            echo "|----------|------|---------|"
            echo "| Build | ${{ inputs.build_tool }} | true |"
            echo "| Testing | JaCoCo Coverage | ${{ inputs.run_jacoco }} |"
            echo "| Testing | PITest | ${{ inputs.run_pitest }} |"
            echo "| Linting | Checkstyle | ${{ inputs.run_checkstyle }} |"
            echo "| Linting | PMD | ${{ inputs.run_pmd }} |"
            echo "| Linting | SpotBugs | ${{ inputs.run_spotbugs }} |"
            echo "| Security | OWASP Dependency-Check | ${{ inputs.run_owasp }} |"
            echo "| Security | Semgrep | ${{ inputs.run_semgrep }} |"
            echo "| Security | Trivy | ${{ inputs.run_trivy }} |"
            echo "| Security | CodeQL | ${{ inputs.run_codeql }} |"
            echo "| Container | Docker | ${{ inputs.run_docker }} |"
            echo ""
            echo "## Thresholds"
            echo "| Setting | Value |"
            echo "|---------|-------|"
            echo "| Min Coverage | ${{ inputs.coverage_min }}% |"
            echo "| Min Mutation Score | ${{ inputs.mutation_score_min }}% |"
            echo "| OWASP CVSS Fail | ${{ inputs.owasp_cvss_fail }} |"
            echo "| Max Critical Vulns | ${{ inputs.max_critical_vulns }} |"
            echo "| Max High Vulns | ${{ inputs.max_high_vulns }} |"
            echo "| Max Semgrep Findings | ${{ inputs.max_semgrep_findings }} |"
            echo "| Max PMD Violations | ${{ inputs.max_pmd_violations }} |"
            echo "| Max Checkstyle Errors | ${{ inputs.max_checkstyle_errors }} |"
            echo "| Max SpotBugs Bugs | ${{ inputs.max_spotbugs_bugs }} |"
            echo ""
            echo "## Environment"
            echo "| Setting | Value |"
            echo "|---------|-------|"
            echo "| Java Version | ${{ inputs.java_version }} |"
            echo "| Build Tool | ${{ inputs.build_tool }} |"
            WORKDIR="${{ inputs.workdir }}"
            if [ "$WORKDIR" = "." ] || [ -z "$WORKDIR" ]; then
              echo "| Working Directory | \`.\` (repo root) |"
            else
              echo "| Working Directory | \`$WORKDIR\` |"
            fi
            # Detect multi-module project
            if [ -f "pom.xml" ] && grep -q "<modules>" pom.xml 2>/dev/null; then
              MODULE_COUNT=$(grep -c "<module>" pom.xml 2>/dev/null || echo "0")
              echo "| Project Type | Multi-module ($MODULE_COUNT modules) |"
            else
              echo "| Project Type | Single module |"
            fi
            echo "| Artifact Retention | ${{ inputs.retention_days }} days |"
            echo ""
            echo "---"
            echo ""
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Build and Test
        id: build
        # continue-on-error allows workflow to continue when tests fail,
        # enabling report generation and threshold enforcement
        continue-on-error: true
        run: |
          if [ "${{ inputs.build_tool }}" = "maven" ]; then
            MVN_CMD="mvn"
            if [ -f "mvnw" ]; then
              chmod +x mvnw
              MVN_CMD="./mvnw"
            fi

            # Step 1: Run the build lifecycle (may fail on tests)
            echo "Running: $MVN_CMD -B -ntp verify"
            $MVN_CMD -B -ntp verify || echo "Build/test phase completed with errors (expected for failing fixtures)"

            # Step 2: Run analysis tools separately with -DskipTests
            # This ensures they run even if tests failed above
            ANALYSIS_GOALS=""
            if [ "${{ inputs.run_checkstyle }}" = "true" ]; then
              ANALYSIS_GOALS="$ANALYSIS_GOALS checkstyle:checkstyle"
            fi
            if [ "${{ inputs.run_spotbugs }}" = "true" ]; then
              ANALYSIS_GOALS="$ANALYSIS_GOALS spotbugs:spotbugs"
            fi
            if [ "${{ inputs.run_owasp }}" = "true" ]; then
              ANALYSIS_GOALS="$ANALYSIS_GOALS dependency-check:check"
            fi

            if [ -n "$ANALYSIS_GOALS" ]; then
              # OWASP flags:
              #   -DnvdApiDelay=2500 - 2.5s delay between NVD API calls to avoid 403 rate limiting
              #   -DnvdMaxRetryCount=10 - retry failed API calls
              #   -Ddependencycheck.failOnError=false - don't fail build on vulnerabilities found
              # shellcheck disable=SC2086 # ANALYSIS_GOALS intentionally unquoted for word splitting
              echo "Running analysis tools: $MVN_CMD -B -ntp -DskipTests -DnvdApiDelay=2500 -DnvdMaxRetryCount=10 -Ddependencycheck.failOnError=false $ANALYSIS_GOALS"
              # shellcheck disable=SC2086 # ANALYSIS_GOALS intentionally unquoted for word splitting
              $MVN_CMD -B -ntp -DskipTests -DnvdApiDelay=2500 -DnvdMaxRetryCount=10 -Ddependencycheck.failOnError=false $ANALYSIS_GOALS || echo "Some analysis tools completed with errors"
            fi
          else
            if [ -f "gradlew" ]; then
              chmod +x gradlew
              ./gradlew build
            else
              gradle build
            fi
          fi
        env:
          NVD_API_KEY: ${{ secrets.NVD_API_KEY }}
          MAVEN_OPTS: -Xmx1024m

      - name: Extract Test Counts
        id: test-counts
        if: always()
        run: |
          PASSED=0
          FAILED=0
          # Parse surefire XML reports for test counts
          while IFS= read -r xml; do
            TESTS=$(grep -oP 'tests="\K[0-9]+' "$xml" | head -1 || echo 0)
            FAILURES=$(grep -oP 'failures="\K[0-9]+' "$xml" | head -1 || echo 0)
            ERRORS=$(grep -oP 'errors="\K[0-9]+' "$xml" | head -1 || echo 0)
            FAILED=$((FAILED + FAILURES + ERRORS))
            PASSED=$((PASSED + TESTS - FAILURES - ERRORS))
          done < <(find . -path "*/surefire-reports/*.xml" -name "TEST-*.xml" 2>/dev/null)
          echo "passed=$PASSED" >> "$GITHUB_OUTPUT"
          echo "failed=$FAILED" >> "$GITHUB_OUTPUT"
          echo "Tests: $PASSED passed, $FAILED failed"

      - name: Extract Coverage
        id: coverage
        if: inputs.run_jacoco
        run: |
          # Find ALL JaCoCo reports (supports single-module and multi-module projects)
          TOTAL_COVERED=0
          TOTAL_MISSED=0
          FOUND_REPORTS=0

          # Create temp file for per-module data
          echo "" > /tmp/module_coverage.txt

          # Search recursively for all jacoco.xml files
          while IFS= read -r REPORT; do
            if [ -f "$REPORT" ]; then
              FOUND_REPORTS=$((FOUND_REPORTS + 1))
              COVERED=$(grep -oP 'INSTRUCTION.*?counter.*?covered="\K[0-9]+' "$REPORT" | head -1 || echo "0")
              MISSED=$(grep -oP 'INSTRUCTION.*?counter.*?missed="\K[0-9]+' "$REPORT" | head -1 || echo "0")
              TOTAL_COVERED=$((TOTAL_COVERED + ${COVERED:-0}))
              TOTAL_MISSED=$((TOTAL_MISSED + ${MISSED:-0}))

              # Extract module name from path (e.g., modules/01-spring-hello-rest/target/... -> 01-spring-hello-rest)
              MODULE_NAME=$(echo "$REPORT" | sed -E 's|.*/([^/]+)/target/.*|\1|' | sed 's|^\./||')
              if [ "$MODULE_NAME" = "target" ]; then
                MODULE_NAME="(root)"
              fi

              # Calculate per-module coverage
              MODULE_COV=0
              if [ $((COVERED + MISSED)) -gt 0 ]; then
                MODULE_COV=$((COVERED * 100 / (COVERED + MISSED)))
              fi
              echo "$MODULE_NAME|$MODULE_COV" >> /tmp/module_coverage.txt
              echo "Found: $REPORT ($MODULE_NAME: $MODULE_COV%)"
            fi
          done < <(find . -path "*/target/site/jacoco/jacoco.xml" -type f 2>/dev/null)

          # Calculate overall coverage
          COVERAGE=0
          if [ $((TOTAL_COVERED + TOTAL_MISSED)) -gt 0 ]; then
            COVERAGE=$((TOTAL_COVERED * 100 / (TOTAL_COVERED + TOTAL_MISSED)))
          fi

          echo "Found $FOUND_REPORTS JaCoCo report(s)"
          echo "Total: covered=$TOTAL_COVERED, missed=$TOTAL_MISSED"
          echo "percentage=$COVERAGE" >> "$GITHUB_OUTPUT"
          echo "module_count=$FOUND_REPORTS" >> "$GITHUB_OUTPUT"
          echo "Coverage: $COVERAGE%"

      - name: Check Coverage Threshold
        if: inputs.run_jacoco
        run: |
          COVERAGE=${{ steps.coverage.outputs.percentage }}
          MIN=${{ inputs.coverage_min }}
          if [ "$COVERAGE" -lt "$MIN" ]; then
            echo "::error::Coverage $COVERAGE% is below minimum $MIN%"
            exit 1
          fi

      # ---- Generate Summary ----
      - name: Generate Build Summary
        if: always()
        run: |
          {
            echo "## Build Results"
            echo ""
            echo "| Metric | Value |"
            echo "|--------|-------|"
            echo "| Tests Passed | ${{ steps.test-counts.outputs.tests_passed }} |"
            echo "| Tests Failed | ${{ steps.test-counts.outputs.tests_failed }} |"
            echo "| Total Coverage | ${{ steps.coverage.outputs.percentage }}% |"

            # Show per-module breakdown for multi-module projects
            MODULE_COUNT="${{ steps.coverage.outputs.module_count }}"
            if [ "${MODULE_COUNT:-0}" -gt 1 ] && [ -f /tmp/module_coverage.txt ]; then
              echo ""
              echo "### Coverage by Module"
              echo ""
              echo "| Module | Coverage |"
              echo "|--------|----------|"
              while IFS='|' read -r MODULE COV; do
                if [ -n "$MODULE" ]; then
                  echo "| $MODULE | $COV% |"
                fi
              done < /tmp/module_coverage.txt
            fi
          } >> "$GITHUB_STEP_SUMMARY"

      # ---- Upload Artifacts ----
      - name: Upload Test Reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ${{ inputs.artifact_prefix }}test-reports
          path: |
            **/target/surefire-reports/
            **/target/failsafe-reports/
          retention-days: ${{ inputs.retention_days }}
          if-no-files-found: ignore

      - name: Upload JaCoCo Reports
        if: always() && inputs.run_jacoco
        uses: actions/upload-artifact@v4
        with:
          name: ${{ inputs.artifact_prefix }}jacoco-reports
          path: '**/target/site/jacoco/'
          retention-days: ${{ inputs.retention_days }}
          if-no-files-found: ignore

      - name: Upload Checkstyle Reports
        if: always() && inputs.run_checkstyle
        uses: actions/upload-artifact@v4
        with:
          name: ${{ inputs.artifact_prefix }}checkstyle-reports
          path: '**/target/checkstyle-result.xml'
          retention-days: ${{ inputs.retention_days }}
          if-no-files-found: ignore

      - name: Upload SpotBugs Reports
        if: always() && inputs.run_spotbugs
        uses: actions/upload-artifact@v4
        with:
          name: ${{ inputs.artifact_prefix }}spotbugs-reports
          path: |
            **/target/spotbugsXml.xml
            **/target/spotbugs.html
          retention-days: ${{ inputs.retention_days }}
          if-no-files-found: ignore

      - name: Upload OWASP Reports
        if: always() && inputs.run_owasp
        uses: actions/upload-artifact@v4
        with:
          name: ${{ inputs.artifact_prefix }}owasp-reports
          path: |
            **/target/dependency-check-report.html
            **/target/dependency-check-report.json
          retention-days: ${{ inputs.retention_days }}
          if-no-files-found: ignore

      - name: Enforce OWASP Thresholds
        if: inputs.run_owasp
        run: |
          REPORT=$(find . -name "dependency-check-report.json" -print -quit)
          CRITICAL=0
          HIGH=0
          MAX_CRITICAL="${{ inputs.max_critical_vulns || 0 }}"
          MAX_HIGH="${{ inputs.max_high_vulns || 0 }}"
          if [ -n "$REPORT" ] && [ -f "$REPORT" ]; then
            CRITICAL=$(jq '[.dependencies[]?.vulnerabilities[]? | select(.severity == "CRITICAL")] | length' "$REPORT" 2>/dev/null || echo 0)
            HIGH=$(jq '[.dependencies[]?.vulnerabilities[]? | select(.severity == "HIGH")] | length' "$REPORT" 2>/dev/null || echo 0)
          else
            echo "::warning::dependency-check-report.json not found; skipping vulnerability threshold enforcement"
          fi

          if [ "$CRITICAL" -gt "$MAX_CRITICAL" ]; then
            echo "::error::Critical vulnerabilities ($CRITICAL) exceed max_critical_vulns $MAX_CRITICAL"
            exit 1
          fi
          if [ "$HIGH" -gt "$MAX_HIGH" ]; then
            echo "::error::High vulnerabilities ($HIGH) exceed max_high_vulns $MAX_HIGH"
            exit 1
          fi

      - name: Upload to Codecov
        if: inputs.run_jacoco
        uses: codecov/codecov-action@v4
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: '**/target/site/jacoco/jacoco.xml'
          fail_ci_if_error: false
        continue-on-error: true

  # ============================================================================
  # PMD Static Analysis
  # ============================================================================
  pmd:
    name: PMD Analysis
    runs-on: ubuntu-latest
    needs: build-test
    if: always() && inputs.run_pmd
    outputs:
      violations: ${{ steps.pmd.outputs.violations }}
    defaults:
      run:
        working-directory: ${{ inputs.workdir }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up JDK ${{ inputs.java_version }}
        uses: actions/setup-java@v4
        with:
          java-version: ${{ inputs.java_version }}
          distribution: 'temurin'
          cache: ${{ inputs.build_tool }}

      - name: Run PMD
        id: pmd
        run: |
          if [ "${{ inputs.build_tool }}" = "maven" ]; then
            if [ -f "mvnw" ]; then
              chmod +x mvnw
              ./mvnw -B -ntp pmd:check || true
            else
              mvn -B -ntp pmd:check || true
            fi
          fi

          # Count violations
          VIOLATIONS=0
          while IFS= read -r xml; do
            COUNT=$(grep -c "<violation" "$xml" 2>/dev/null || echo 0)
            VIOLATIONS=$((VIOLATIONS + COUNT))
          done < <(find . -name "pmd.xml" 2>/dev/null)

          echo "violations=$VIOLATIONS" >> "$GITHUB_OUTPUT"
          echo "PMD Violations: $VIOLATIONS"
        continue-on-error: true

      - name: Generate PMD Summary
        if: always()
        run: |
          {
            echo "## PMD Static Analysis Results"
            echo ""
            echo "**Violations:** ${{ steps.pmd.outputs.violations }}"
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Upload PMD Reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ${{ inputs.artifact_prefix }}pmd-reports
          path: '**/target/pmd.xml'
          retention-days: ${{ inputs.retention_days }}
          if-no-files-found: ignore

      - name: Enforce PMD Violations
        run: |
          VIOLATIONS=${{ steps.pmd.outputs.violations || 0 }}
          MAX_VIOLATIONS=${{ inputs.max_pmd_violations || 0 }}
          if [ "$VIOLATIONS" -gt "$MAX_VIOLATIONS" ]; then
            echo "::error::PMD reported $VIOLATIONS violations (max: $MAX_VIOLATIONS)"
            exit 1
          fi

  # ============================================================================
  # Semgrep SAST
  # ============================================================================
  semgrep:
    name: Semgrep SAST
    runs-on: ubuntu-latest
    needs: build-test
    if: always() && inputs.run_semgrep
    outputs:
      findings: ${{ steps.semgrep.outputs.findings }}
    defaults:
      run:
        working-directory: ${{ inputs.workdir }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install jq
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install Semgrep
        run: pip install semgrep

      - name: Run Semgrep
        id: semgrep
        run: |
          semgrep --config=auto --json --output=semgrep-report.json . || true

          FINDINGS=0
          if [ -f "semgrep-report.json" ]; then
            FINDINGS=$(jq '.results | length' semgrep-report.json 2>/dev/null || echo 0)
          fi

          echo "findings=$FINDINGS" >> "$GITHUB_OUTPUT"
          echo "Semgrep Findings: $FINDINGS"
        continue-on-error: true

      - name: Generate Semgrep Summary
        if: always()
        run: |
          {
            echo "## Semgrep SAST Results"
            echo ""
            echo "**Findings:** ${{ steps.semgrep.outputs.findings }}"
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Upload Semgrep Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ${{ inputs.artifact_prefix }}semgrep-report
          path: semgrep-report.json
          retention-days: ${{ inputs.retention_days }}
          if-no-files-found: ignore

      - name: Enforce Semgrep Threshold
        run: |
          FINDINGS=${{ steps.semgrep.outputs.findings || 0 }}
          MAX_FINDINGS=${{ inputs.max_semgrep_findings || 0 }}
          if [ "$FINDINGS" -gt "$MAX_FINDINGS" ]; then
            echo "::error::Semgrep reported $FINDINGS findings (max: $MAX_FINDINGS)"
            exit 1
          fi

  # ============================================================================
  # Trivy Container Scan
  # ============================================================================
  trivy:
    name: Trivy Container Scan
    runs-on: ubuntu-latest
    needs: build-test
    if: always() && inputs.run_trivy
    outputs:
      critical: ${{ steps.trivy-parse.outputs.critical }}
      high: ${{ steps.trivy-parse.outputs.high }}
    defaults:
      run:
        working-directory: ${{ inputs.workdir }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install jq
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: Check for Dockerfile
        id: check-dockerfile
        run: |
          if [ -f "Dockerfile" ]; then
            echo "exists=true" >> "$GITHUB_OUTPUT"
          else
            echo "exists=false" >> "$GITHUB_OUTPUT"
            echo "No Dockerfile found - skipping Trivy container scan"
          fi

      - name: Run Trivy Scan
        if: steps.check-dockerfile.outputs.exists == 'true'
        id: trivy
        uses: aquasecurity/trivy-action@0.28.0
        with:
          scan-type: 'fs'
          scan-ref: ${{ inputs.workdir }}
          format: 'json'
          output: 'trivy-report.json'
        continue-on-error: true

      - name: Parse Trivy Results
        if: steps.check-dockerfile.outputs.exists == 'true'
        id: trivy-parse
        run: |
          CRITICAL=0
          HIGH=0
          # trivy-action outputs to workspace root, not working-directory
          REPORT="${{ github.workspace }}/trivy-report.json"
          if [ -f "$REPORT" ]; then
            CRITICAL=$(jq '[.Results[]?.Vulnerabilities[]? | select(.Severity == "CRITICAL")] | length' "$REPORT" 2>/dev/null || echo 0)
            HIGH=$(jq '[.Results[]?.Vulnerabilities[]? | select(.Severity == "HIGH")] | length' "$REPORT" 2>/dev/null || echo 0)
          fi
          echo "critical=$CRITICAL" >> "$GITHUB_OUTPUT"
          echo "high=$HIGH" >> "$GITHUB_OUTPUT"
          echo "Trivy: $CRITICAL critical, $HIGH high"

      - name: Generate Trivy Summary
        if: always() && steps.check-dockerfile.outputs.exists == 'true'
        run: |
          {
            echo "## Trivy Container Scan Results"
            echo ""
            echo "**Critical:** ${{ steps.trivy-parse.outputs.critical }}"
            echo "**High:** ${{ steps.trivy-parse.outputs.high }}"
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Upload Trivy Report
        if: always() && steps.check-dockerfile.outputs.exists == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: ${{ inputs.artifact_prefix }}trivy-report
          path: ${{ github.workspace }}/trivy-report.json
          retention-days: ${{ inputs.retention_days }}
          if-no-files-found: ignore

      - name: Enforce Trivy Thresholds
        if: steps.check-dockerfile.outputs.exists == 'true'
        run: |
          CRIT="${{ steps.trivy-parse.outputs.critical || 0 }}"
          HIGH="${{ steps.trivy-parse.outputs.high || 0 }}"
          MAX_CRITICAL="${{ inputs.max_critical_vulns || 0 }}"
          MAX_HIGH="${{ inputs.max_high_vulns || 0 }}"
          if [ "$CRIT" -gt "$MAX_CRITICAL" ]; then
            echo "::error::Trivy critical findings ($CRIT) exceed max_critical_vulns $MAX_CRITICAL"
            exit 1
          fi
          if [ "$HIGH" -gt "$MAX_HIGH" ]; then
            echo "::error::Trivy high findings ($HIGH) exceed max_high_vulns $MAX_HIGH"
            exit 1
          fi

  # ============================================================================
  # Mutation Testing
  # ============================================================================
  mutation-test:
    name: Mutation Testing
    runs-on: ubuntu-latest
    needs: build-test
    if: always() && inputs.run_pitest
    defaults:
      run:
        working-directory: ${{ inputs.workdir }}
    outputs:
      score: ${{ steps.pitest.outputs.score }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up JDK ${{ inputs.java_version }}
        uses: actions/setup-java@v4
        with:
          java-version: ${{ inputs.java_version }}
          distribution: 'temurin'
          cache: ${{ inputs.build_tool }}

      - name: Run PITest
        id: pitest
        run: |
          PITEST_EXIT=0
          if [ "${{ inputs.build_tool }}" = "maven" ]; then
            if [ -f "mvnw" ]; then
              chmod +x mvnw
              # Note: Do NOT use -DskipTests with PITest - it needs to run tests to detect killed mutations
              ./mvnw -B -ntp test-compile org.pitest:pitest-maven:mutationCoverage || PITEST_EXIT=$?
            else
              mvn -B -ntp test-compile org.pitest:pitest-maven:mutationCoverage || PITEST_EXIT=$?
            fi
          fi

          if [ "$PITEST_EXIT" -ne 0 ]; then
            echo "::warning::PITest exited with code $PITEST_EXIT"
          fi

          # Extract mutation score from ALL modules (supports multi-module projects)
          # Note: PITest uses single quotes in XML (status='KILLED'), so we match both quote styles
          TOTAL_KILLED=0
          TOTAL_SURVIVED=0
          FOUND_REPORTS=0

          # Create temp file for per-module data
          echo "" > /tmp/module_mutations.txt

          echo "Looking for pit-reports/mutations.xml..."
          while IFS= read -r REPORT; do
            if [ -f "$REPORT" ]; then
              FOUND_REPORTS=$((FOUND_REPORTS + 1))
              KILLED=$(grep -cE "status=['\"]KILLED['\"]" "$REPORT" || echo "0")
              SURVIVED=$(grep -cE "status=['\"]SURVIVED['\"]" "$REPORT" || echo "0")
              TOTAL_KILLED=$((TOTAL_KILLED + ${KILLED:-0}))
              TOTAL_SURVIVED=$((TOTAL_SURVIVED + ${SURVIVED:-0}))

              # Extract module name from path
              MODULE_NAME=$(echo "$REPORT" | sed -E 's|.*/([^/]+)/target/.*|\1|' | sed 's|^\./||')
              if [ "$MODULE_NAME" = "target" ]; then
                MODULE_NAME="(root)"
              fi

              # Calculate per-module score
              MODULE_SCORE=0
              MODULE_TOTAL=$((KILLED + SURVIVED))
              if [ "$MODULE_TOTAL" -gt 0 ]; then
                MODULE_SCORE=$((KILLED * 100 / MODULE_TOTAL))
              fi
              echo "$MODULE_NAME|$MODULE_SCORE|$KILLED|$SURVIVED" >> /tmp/module_mutations.txt
              echo "Found: $REPORT ($MODULE_NAME: $MODULE_SCORE%)"
            fi
          done < <(find . -path "*/target/pit-reports/mutations.xml" -type f 2>/dev/null)

          # Calculate overall mutation score
          SCORE=0
          TOTAL=$((TOTAL_KILLED + TOTAL_SURVIVED))
          if [ "$TOTAL" -gt 0 ]; then
            SCORE=$((TOTAL_KILLED * 100 / TOTAL))
          fi

          if [ "$FOUND_REPORTS" -eq 0 ]; then
            echo "::warning::No mutations.xml found - PITest may not have run"
          else
            echo "Found $FOUND_REPORTS PITest report(s)"
          fi
          echo "Total: killed=$TOTAL_KILLED, survived=$TOTAL_SURVIVED"
          echo "score=$SCORE" >> "$GITHUB_OUTPUT"
          echo "module_count=$FOUND_REPORTS" >> "$GITHUB_OUTPUT"
          echo "Mutation Score: $SCORE%"

      - name: Check Mutation Threshold
        run: |
          SCORE=${{ steps.pitest.outputs.score }}
          MIN=${{ inputs.mutation_score_min }}
          if [ "$SCORE" -lt "$MIN" ]; then
            echo "::error::Mutation score $SCORE% is below minimum $MIN%"
            exit 1
          fi

      - name: Generate Mutation Summary
        if: always()
        run: |
          {
            echo "## Mutation Testing Results"
            echo ""
            echo "| Metric | Value |"
            echo "|--------|-------|"
            echo "| Total Mutation Score | ${{ steps.pitest.outputs.score }}% |"
            echo "| Threshold | ${{ inputs.mutation_score_min }}% |"

            # Show per-module breakdown for multi-module projects
            MODULE_COUNT="${{ steps.pitest.outputs.module_count }}"
            if [ "${MODULE_COUNT:-0}" -gt 1 ] && [ -f /tmp/module_mutations.txt ]; then
              echo ""
              echo "### Mutations by Module"
              echo ""
              echo "| Module | Score | Killed | Survived |"
              echo "|--------|-------|--------|----------|"
              while IFS='|' read -r MODULE SCORE KILLED SURVIVED; do
                if [ -n "$MODULE" ]; then
                  echo "| $MODULE | $SCORE% | $KILLED | $SURVIVED |"
                fi
              done < /tmp/module_mutations.txt
            fi
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Upload PITest Reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ${{ inputs.artifact_prefix }}pitest-reports
          path: '**/target/pit-reports/'
          retention-days: ${{ inputs.retention_days }}
          if-no-files-found: ignore

  # ============================================================================
  # Docker Build & Test
  # ============================================================================
  docker-build:
    name: Docker Build
    runs-on: ubuntu-latest
    needs: build-test
    if: always() && inputs.run_docker
    defaults:
      run:
        working-directory: ${{ inputs.workdir }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build Docker Image
        run: |
          if [ -f "Dockerfile" ]; then
            docker build -t ${{ github.repository }}:ci-test .
          fi

      - name: Test with Docker Compose
        if: hashFiles(inputs.docker_compose_file) != ''
        run: |
          docker compose -f ${{ inputs.docker_compose_file }} up -d

          # Wait for health check
          echo "Waiting for services to be healthy..."
          for i in $(seq 1 30); do
            if curl -sf http://localhost:8080${{ inputs.docker_health_endpoint }} > /dev/null 2>&1; then
              echo "Service is healthy!"
              break
            fi
            echo "Attempt $i/30..."
            sleep 10
          done

          # Show logs
          docker compose logs

          # Cleanup
          docker compose down

  # ============================================================================
  # CodeQL Security Analysis
  # ============================================================================
  codeql:
    name: CodeQL Analysis
    runs-on: ubuntu-latest
    if: inputs.run_codeql
    permissions:
      security-events: write
    defaults:
      run:
        working-directory: ${{ inputs.workdir }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Initialize CodeQL
        uses: github/codeql-action/init@v3
        with:
          languages: java
          # Scope analysis to workdir only
          source-root: ${{ inputs.workdir }}

      - name: Set up JDK ${{ inputs.java_version }}
        uses: actions/setup-java@v4
        with:
          java-version: ${{ inputs.java_version }}
          distribution: 'temurin'
          cache: ${{ inputs.build_tool }}

      - name: Build for CodeQL
        run: |
          if [ "${{ inputs.build_tool }}" = "maven" ]; then
            if [ -f "mvnw" ]; then
              chmod +x mvnw
              ./mvnw -B -ntp compile -DskipTests
            else
              mvn -B -ntp compile -DskipTests
            fi
          else
            if [ -f "gradlew" ]; then
              chmod +x gradlew
              ./gradlew compileJava
            else
              gradle compileJava
            fi
          fi

      - name: Perform CodeQL Analysis
        uses: github/codeql-action/analyze@v3

  # ============================================================================
  # Generate Final Report
  # ============================================================================
  report:
    name: Generate Report
    runs-on: ubuntu-latest
    needs: [build-test, pmd, mutation-test, semgrep, trivy]
    if: always()

    steps:
      - name: Download All Artifacts
        uses: actions/download-artifact@v4
        with:
          path: all-reports/

      - name: Generate Combined Report
        run: |
          # Extract vulnerability counts from OWASP report
          CRITICAL_VULNS=0
          HIGH_VULNS=0
          MEDIUM_VULNS=0
          OWASP_CRITICAL=0
          OWASP_HIGH=0

          OWASP_REPORT=$(find all-reports -name "dependency-check-report.json" 2>/dev/null | head -1)
          if [ -n "$OWASP_REPORT" ] && [ -f "$OWASP_REPORT" ]; then
            OWASP_CRITICAL=$(jq '[.dependencies[]?.vulnerabilities[]? | select(.severity == "CRITICAL")] | length' "$OWASP_REPORT" 2>/dev/null || echo 0)
            OWASP_HIGH=$(jq '[.dependencies[]?.vulnerabilities[]? | select(.severity == "HIGH")] | length' "$OWASP_REPORT" 2>/dev/null || echo 0)
            MEDIUM_VULNS=$(jq '[.dependencies[]?.vulnerabilities[]? | select(.severity == "MEDIUM")] | length' "$OWASP_REPORT" 2>/dev/null || echo 0)
            CRITICAL_VULNS=$OWASP_CRITICAL
            HIGH_VULNS=$OWASP_HIGH
          fi

          # Extract Trivy vulnerability counts if available
          TRIVY_CRITICAL=0
          TRIVY_HIGH=0
          TRIVY_REPORT=$(find all-reports -name "trivy-report.json" 2>/dev/null | head -1)
          if [ -n "$TRIVY_REPORT" ] && [ -f "$TRIVY_REPORT" ]; then
            TRIVY_CRITICAL=$(jq '[.Results[]?.Vulnerabilities[]? | select(.Severity == "CRITICAL")] | length' "$TRIVY_REPORT" 2>/dev/null || echo 0)
            TRIVY_HIGH=$(jq '[.Results[]?.Vulnerabilities[]? | select(.Severity == "HIGH")] | length' "$TRIVY_REPORT" 2>/dev/null || echo 0)
            TRIVY_MEDIUM=$(jq '[.Results[]?.Vulnerabilities[]? | select(.Severity == "MEDIUM")] | length' "$TRIVY_REPORT" 2>/dev/null || echo 0)
            CRITICAL_VULNS=$((CRITICAL_VULNS + TRIVY_CRITICAL))
            HIGH_VULNS=$((HIGH_VULNS + TRIVY_HIGH))
            MEDIUM_VULNS=$((MEDIUM_VULNS + TRIVY_MEDIUM))
          fi

          # Extract checkstyle issues from artifact
          CHECKSTYLE_ISSUES=0
          CHECKSTYLE_REPORT=$(find all-reports -name "checkstyle-result.xml" 2>/dev/null | head -1)
          if [ -n "$CHECKSTYLE_REPORT" ] && [ -f "$CHECKSTYLE_REPORT" ]; then
            CHECKSTYLE_ISSUES=$(grep -c "<error" "$CHECKSTYLE_REPORT" 2>/dev/null || echo 0)
          fi

          # Extract spotbugs issues from artifact
          SPOTBUGS_ISSUES=0
          SPOTBUGS_REPORT=$(find all-reports -name "spotbugsXml.xml" 2>/dev/null | head -1)
          if [ -n "$SPOTBUGS_REPORT" ] && [ -f "$SPOTBUGS_REPORT" ]; then
            SPOTBUGS_ISSUES=$(grep -c "<BugInstance" "$SPOTBUGS_REPORT" 2>/dev/null || echo 0)
          fi

          cat > report.json << EOF
          {
            "schema_version": "2.0",
            "metadata": {
              "workflow_version": "v1.0.0",
              "workflow_ref": "${{ github.repository }}/.github/workflows/java-ci.yml@${{ github.ref_name }}",
              "generated_at": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")"
            },
            "repository": "${{ github.repository }}",
            "run_id": "${{ github.run_id }}",
            "run_number": "${{ github.run_number }}",
            "commit": "${{ github.sha }}",
            "branch": "${{ github.ref_name }}",
            "timestamp": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
            "java_version": "${{ inputs.java_version }}",
            "results": {
              "build": "${{ needs.build-test.outputs.status }}",
              "coverage": ${{ needs.build-test.outputs.coverage || 0 }},
              "mutation_score": ${{ needs.mutation-test.outputs.score || 0 }},
              "tests_passed": ${{ needs.build-test.outputs.tests_passed || 0 }},
              "tests_failed": ${{ needs.build-test.outputs.tests_failed || 0 }},
              "critical_vulns": ${CRITICAL_VULNS},
              "high_vulns": ${HIGH_VULNS},
              "medium_vulns": ${MEDIUM_VULNS}
            },
            "tool_metrics": {
              "checkstyle_issues": ${CHECKSTYLE_ISSUES},
              "spotbugs_issues": ${SPOTBUGS_ISSUES},
              "pmd_violations": ${{ needs.pmd.outputs.violations || 0 }},
              "owasp_critical": ${OWASP_CRITICAL},
              "owasp_high": ${OWASP_HIGH},
              "semgrep_findings": ${{ needs.semgrep.outputs.findings || 0 }},
              "trivy_critical": ${{ needs.trivy.outputs.critical || 0 }},
              "trivy_high": ${{ needs.trivy.outputs.high || 0 }}
            },
            "tools_ran": {
              "jacoco": ${{ inputs.run_jacoco }},
              "checkstyle": ${{ inputs.run_checkstyle }},
              "spotbugs": ${{ inputs.run_spotbugs }},
              "pmd": ${{ inputs.run_pmd }},
              "owasp": ${{ inputs.run_owasp }},
              "pitest": ${{ inputs.run_pitest }},
              "semgrep": ${{ inputs.run_semgrep }},
              "trivy": ${{ inputs.run_trivy }},
              "codeql": ${{ inputs.run_codeql }},
              "docker": ${{ inputs.run_docker }}
            },
            "thresholds": {
              "coverage_min": ${{ inputs.coverage_min }},
              "mutation_score_min": ${{ inputs.mutation_score_min }},
              "owasp_cvss_fail": ${{ inputs.owasp_cvss_fail }},
              "max_pmd_violations": ${{ inputs.max_pmd_violations }}
            }
          }
          EOF

          cat report.json

      - name: Upload Combined Report
        uses: actions/upload-artifact@v4
        with:
          name: ${{ inputs.artifact_prefix }}ci-report
          path: report.json
          retention-days: ${{ inputs.retention_days }}
