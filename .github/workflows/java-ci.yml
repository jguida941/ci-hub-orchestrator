# ============================================================================
# CI/CD Hub - Reusable Java CI Workflow
# ============================================================================
# Call this workflow from any Java repository to run the full CI pipeline.
#
# Usage in your repo's workflow:
#   jobs:
#     ci:
#       uses: jguida941/ci-cd-hub/.github/workflows/java-ci.yml@main
#       with:
#         java_version: '21'
#         run_pitest: true
#         run_docker: false
#       secrets: inherit
# ============================================================================

name: Java CI Pipeline

permissions:
  contents: read

on:
  workflow_call:
    inputs:
      # ---- Java Settings ----
      java_version:
        description: 'Java version'
        type: string
        default: '21'
      build_tool:
        description: 'Build tool (maven or gradle)'
        type: string
        default: 'maven'

      # ---- Tool Toggles ----
      run_jacoco:
        description: 'Run JaCoCo coverage'
        type: boolean
        default: true
      run_checkstyle:
        description: 'Run Checkstyle'
        type: boolean
        default: true
      run_spotbugs:
        description: 'Run SpotBugs'
        type: boolean
        default: true
      run_owasp:
        description: 'Run OWASP Dependency Check'
        type: boolean
        default: true
      use_nvd_api_key:
        description: 'Use NVD API key for faster OWASP scans (requires NVD_API_KEY secret)'
        type: boolean
        default: true
      run_pitest:
        description: 'Run PITest mutation testing'
        type: boolean
        default: true
      run_jqwik:
        description: 'Run jqwik property-based testing'
        type: boolean
        default: false
      run_codeql:
        description: 'Run CodeQL analysis (expensive)'
        type: boolean
        default: false
      run_pmd:
        description: 'Run PMD static analysis'
        type: boolean
        default: true
      run_semgrep:
        description: 'Run Semgrep SAST (expensive)'
        type: boolean
        default: false
      run_trivy:
        description: 'Run Trivy container scan (expensive)'
        type: boolean
        default: false
      run_docker:
        description: 'Build and test Docker'
        type: boolean
        default: false

      # ---- Thresholds ----
      coverage_min:
        description: 'Minimum coverage percentage'
        type: number
        default: 70
      mutation_score_min:
        description: 'Minimum mutation score'
        type: number
        default: 70
      owasp_cvss_fail:
        description: 'CVSS score to fail on'
        type: number
        default: 7
      max_critical_vulns:
        description: 'Maximum allowed critical vulnerabilities across scanners'
        type: number
        default: 0
      max_high_vulns:
        description: 'Maximum allowed high vulnerabilities across scanners'
        type: number
        default: 0
      max_semgrep_findings:
        description: 'Maximum allowed Semgrep findings (default: 0 = fail on any)'
        type: number
        default: 0
      max_pmd_violations:
        description: 'Maximum allowed PMD violations (default: 0 = fail on any)'
        type: number
        default: 0
      max_checkstyle_errors:
        description: 'Maximum allowed Checkstyle errors (default: 0 = fail on any)'
        type: number
        default: 0
      max_spotbugs_bugs:
        description: 'Maximum allowed SpotBugs bugs (default: 0 = fail on any)'
        type: number
        default: 0

      # ---- Docker Settings ----
      docker_compose_file:
        description: 'Docker compose file path'
        type: string
        default: 'docker-compose.yml'
      docker_health_endpoint:
        description: 'Health check endpoint'
        type: string
        default: '/actuator/health'

      # ---- Reports ----
      retention_days:
        description: 'Artifact retention days'
        type: number
        default: 30
      workdir:
        description: 'Working directory (monorepo subfolder, default repo root)'
        type: string
        default: '.'
      artifact_prefix:
        description: 'Prefix for artifact names (use when calling multiple times in same workflow)'
        type: string
        default: ''
      hub_correlation_id:
        description: 'Correlation ID from hub orchestrator for run matching'
        type: string
        default: ''

    secrets:
      NVD_API_KEY:
        required: false
      CODECOV_TOKEN:
        required: false

    outputs:
      build_status:
        description: 'Build result'
        value: ${{ jobs.build-test.outputs.status }}
      coverage:
        description: 'Coverage percentage'
        value: ${{ jobs.build-test.outputs.coverage }}
      mutation_score:
        description: 'Mutation score'
        value: ${{ jobs.mutation-test.outputs.score }}

jobs:
  # ============================================================================
  # Build & Test
  # ============================================================================
  build-test:
    name: Build & Test
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ${{ inputs.workdir }}
    outputs:
      status: ${{ steps.build.outcome }}
      coverage: ${{ steps.coverage.outputs.percentage }}
      coverage_lines_covered: ${{ steps.coverage.outputs.lines_covered }}
      coverage_lines_total: ${{ steps.coverage.outputs.lines_total }}
      tests_passed: ${{ steps.test-counts.outputs.passed }}
      tests_failed: ${{ steps.test-counts.outputs.failed }}
      tests_skipped: ${{ steps.test-counts.outputs.skipped }}
      tests_runtime_seconds: ${{ steps.test-counts.outputs.runtime_seconds }}
      project_type: ${{ steps.project-type.outputs.project_type }}

    steps:
      - name: Checkout
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          fetch-depth: 0
          persist-credentials: false

      - name: Detect Project Type
        id: project-type
        run: |
          if [ -f "pom.xml" ] && grep -q "<modules>" pom.xml 2>/dev/null; then
            MODULE_COUNT=$(grep -c "<module>" pom.xml 2>/dev/null || echo "0")
            echo "project_type=Multi-module (${MODULE_COUNT} modules)" >> "$GITHUB_OUTPUT"
          else
            echo "project_type=Single module" >> "$GITHUB_OUTPUT"
          fi

      - name: Install jq
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: Set up JDK ${{ inputs.java_version }}
        uses: actions/setup-java@c1e323688fd81a25caa38c78aa6df2d33d3e20d9 # v4
        with:
          java-version: ${{ inputs.java_version }}
          distribution: 'temurin'
          cache: ${{ inputs.build_tool }}

      - name: Set up Python 3.12
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5
        with:
          python-version: '3.12'

      - name: Build and Test
        id: build
        # continue-on-error allows workflow to continue when tests fail,
        # enabling report generation and threshold enforcement
        continue-on-error: true
        run: |
          if [ "${{ inputs.build_tool }}" = "maven" ]; then
            MVN_CMD="mvn"
            if [ -f "mvnw" ]; then
              chmod +x mvnw
              MVN_CMD="./mvnw"
            fi

            # Step 1: Run the build lifecycle (may fail on tests)
            echo "Running: $MVN_CMD -B -ntp verify"
            $MVN_CMD -B -ntp verify || echo "Build/test phase completed with errors (expected for failing fixtures)"

            # Step 2: Run analysis tools separately with -DskipTests
            # This ensures they run even if tests failed above
            ANALYSIS_GOALS=""
            if [ "${{ inputs.run_checkstyle }}" = "true" ]; then
              ANALYSIS_GOALS="$ANALYSIS_GOALS checkstyle:checkstyle"
            fi
            if [ "${{ inputs.run_spotbugs }}" = "true" ]; then
              ANALYSIS_GOALS="$ANALYSIS_GOALS spotbugs:spotbugs"
            fi
            if [ "${{ inputs.run_owasp }}" = "true" ]; then
              ANALYSIS_GOALS="$ANALYSIS_GOALS dependency-check:check"
            fi

            if [ -n "$ANALYSIS_GOALS" ]; then
              # OWASP flags:
              #   -DnvdApiKey - NVD API key for faster vulnerability database updates
              #   -DnvdApiDelay=2500 - 2.5s delay between NVD API calls to avoid 403 rate limiting
              #   -DnvdMaxRetryCount=10 - retry failed API calls
              #   -Ddependencycheck.failOnError=false - don't fail build on vulnerabilities found
              USE_NVD_API_KEY="${{ inputs.use_nvd_api_key }}"
              if [ -z "$USE_NVD_API_KEY" ]; then
                USE_NVD_API_KEY="true"
              fi
              NVD_FLAGS=""
              if [ "$USE_NVD_API_KEY" = "true" ] && [ -n "$NVD_API_KEY" ]; then
                NVD_FLAGS="-DnvdApiKey=$NVD_API_KEY"
                echo "NVD API key configured - using accelerated vulnerability updates"
              elif [ "$USE_NVD_API_KEY" = "true" ]; then
                echo "Warning: use_nvd_api_key=true but NVD_API_KEY secret not set - vulnerability updates will be slow"
              else
                echo "NVD API key disabled via config"
              fi
              # shellcheck disable=SC2086 # ANALYSIS_GOALS and NVD_FLAGS intentionally unquoted for word splitting
              echo "Running analysis tools: $MVN_CMD -B -ntp -DskipTests $NVD_FLAGS -DnvdApiDelay=2500 -DnvdMaxRetryCount=10 -Ddependencycheck.failOnError=false $ANALYSIS_GOALS"
              # shellcheck disable=SC2086 # ANALYSIS_GOALS and NVD_FLAGS intentionally unquoted for word splitting
              $MVN_CMD -B -ntp -DskipTests $NVD_FLAGS -DnvdApiDelay=2500 -DnvdMaxRetryCount=10 -Ddependencycheck.failOnError=false $ANALYSIS_GOALS || echo "Some analysis tools completed with errors"
            fi
          else
            if [ -f "gradlew" ]; then
              chmod +x gradlew
              ./gradlew build
            else
              gradle build
            fi
          fi
        env:
          NVD_API_KEY: ${{ secrets.NVD_API_KEY }}
          MAVEN_OPTS: -Xmx1024m

      - name: Extract Test Counts
        id: test-counts
        if: always()
        run: |
          PASSED=0
          FAILED=0
          SKIPPED=0
          RUNTIME=0
          # Parse surefire XML reports for test counts
          while IFS= read -r xml; do
            TESTS=$(grep -oP 'tests="\K[0-9]+' "$xml" | head -1 || echo 0)
            FAILURES=$(grep -oP 'failures="\K[0-9]+' "$xml" | head -1 || echo 0)
            ERRORS=$(grep -oP 'errors="\K[0-9]+' "$xml" | head -1 || echo 0)
            SKIP=$(grep -oP 'skipped="\K[0-9]+' "$xml" | head -1 || echo 0)
            TIME=$(grep -oP 'time="\K[0-9.]+' "$xml" | head -1 || echo 0)
            FAILED=$((FAILED + FAILURES + ERRORS))
            PASSED=$((PASSED + TESTS - FAILURES - ERRORS))
            SKIPPED=$((SKIPPED + SKIP))
            RUNTIME=$(awk -v r="$RUNTIME" -v t="$TIME" 'BEGIN {printf "%.3f", r + t}')
          done < <(find . -path "*/surefire-reports/*.xml" -name "TEST-*.xml" 2>/dev/null)
          {
            echo "passed=$PASSED"
            echo "failed=$FAILED"
            echo "skipped=$SKIPPED"
            echo "runtime_seconds=$RUNTIME"
          } >> "$GITHUB_OUTPUT"
          echo "Tests: $PASSED passed, $FAILED failed, $SKIPPED skipped"

      - name: Extract jqwik Property Test Results
        id: jqwik-results
        if: always() && inputs.run_jqwik
        run: |
          # jqwik runs with JUnit 5, extract property test stats from surefire output
          # Look for jqwik test output patterns
          JQWIK_TESTS=0
          while IFS= read -r report; do
            if [ -f "$report" ]; then
              # Count jqwik property tests (they show in test reports)
              COUNT=$(grep -c "net.jqwik" "$report" 2>/dev/null || echo 0)
              JQWIK_TESTS=$((JQWIK_TESTS + COUNT))
            fi
          done < <(find . -path "*/surefire-reports/*.xml" -name "TEST-*.xml" 2>/dev/null)
          echo "tests=${JQWIK_TESTS:-0}" >> "$GITHUB_OUTPUT"
          echo "jqwik: ${JQWIK_TESTS:-0} property tests"

      - name: Extract Lint Results
        id: lint-results
        if: always()
        run: |
          # Checkstyle
          CHECKSTYLE_ISSUES=0
          if [ "${{ inputs.run_checkstyle }}" = "true" ]; then
            while IFS= read -r report; do
              if [ -f "$report" ]; then
                COUNT=$(grep -c "<error" "$report" 2>/dev/null || echo 0)
                CHECKSTYLE_ISSUES=$((CHECKSTYLE_ISSUES + COUNT))
              fi
            done < <(find . -name "checkstyle-result.xml" -type f 2>/dev/null)
          fi
          echo "checkstyle=$CHECKSTYLE_ISSUES" >> "$GITHUB_OUTPUT"

          # SpotBugs
          SPOTBUGS_ISSUES=0
          if [ "${{ inputs.run_spotbugs }}" = "true" ]; then
            while IFS= read -r report; do
              if [ -f "$report" ]; then
                COUNT=$(grep -c "<BugInstance" "$report" 2>/dev/null || echo 0)
                SPOTBUGS_ISSUES=$((SPOTBUGS_ISSUES + COUNT))
              fi
            done < <(find . -name "spotbugsXml.xml" -type f 2>/dev/null)
          fi
          echo "spotbugs=$SPOTBUGS_ISSUES" >> "$GITHUB_OUTPUT"

          # PMD - count from PMD report if it exists
          PMD_ISSUES=0
          if [ "${{ inputs.run_pmd }}" = "true" ]; then
            while IFS= read -r report; do
              if [ -f "$report" ]; then
                COUNT=$(grep -c "<violation" "$report" 2>/dev/null || echo 0)
                PMD_ISSUES=$((PMD_ISSUES + COUNT))
              fi
            done < <(find . -name "pmd.xml" -type f 2>/dev/null)
          fi
          echo "pmd=$PMD_ISSUES" >> "$GITHUB_OUTPUT"

          echo "Lint: Checkstyle=$CHECKSTYLE_ISSUES, SpotBugs=$SPOTBUGS_ISSUES, PMD=$PMD_ISSUES"

      - name: Extract Security Results
        id: security-results
        if: always()
        run: |
          # OWASP Dependency Check
          OWASP_CRITICAL=0
          OWASP_HIGH=0
          OWASP_MEDIUM=0
          if [ "${{ inputs.run_owasp }}" = "true" ]; then
            OWASP_REPORT=$(find . -name "dependency-check-report.json" -type f 2>/dev/null | head -1)
            if [ -n "$OWASP_REPORT" ] && [ -f "$OWASP_REPORT" ]; then
              OWASP_CRITICAL=$(jq '[.dependencies[]?.vulnerabilities[]? | select(.severity == "CRITICAL")] | length' "$OWASP_REPORT" 2>/dev/null || echo 0)
              OWASP_HIGH=$(jq '[.dependencies[]?.vulnerabilities[]? | select(.severity == "HIGH")] | length' "$OWASP_REPORT" 2>/dev/null || echo 0)
              OWASP_MEDIUM=$(jq '[.dependencies[]?.vulnerabilities[]? | select(.severity == "MEDIUM")] | length' "$OWASP_REPORT" 2>/dev/null || echo 0)
            fi
          fi
          {
            echo "owasp_critical=${OWASP_CRITICAL:-0}"
            echo "owasp_high=${OWASP_HIGH:-0}"
            echo "owasp_medium=${OWASP_MEDIUM:-0}"
          } >> "$GITHUB_OUTPUT"

          echo "Security: OWASP critical=$OWASP_CRITICAL, high=$OWASP_HIGH, medium=$OWASP_MEDIUM"

      - name: Extract Coverage
        id: coverage
        if: inputs.run_jacoco
        run: |
          # Find ALL JaCoCo reports (supports single-module and multi-module projects)
          TOTAL_COVERED=0
          TOTAL_MISSED=0
          FOUND_REPORTS=0
          LINE_COVERED=0
          LINE_MISSED=0

          # Create temp file for per-module data
          echo "" > /tmp/module_coverage.txt

          # Search recursively for all jacoco.xml files
          while IFS= read -r REPORT; do
            if [ -f "$REPORT" ]; then
              FOUND_REPORTS=$((FOUND_REPORTS + 1))
              COVERED=$(grep -oP 'type="LINE".*?covered="\K[0-9]+' "$REPORT" | head -1 || echo "0")
              MISSED=$(grep -oP 'type="LINE".*?missed="\K[0-9]+' "$REPORT" | head -1 || echo "0")
              TOTAL_COVERED=$((TOTAL_COVERED + ${COVERED:-0}))
              TOTAL_MISSED=$((TOTAL_MISSED + ${MISSED:-0}))
              LINE_COVERED=$((LINE_COVERED + ${COVERED:-0}))
              LINE_MISSED=$((LINE_MISSED + ${MISSED:-0}))

              # Extract module name from path (e.g., modules/01-spring-hello-rest/target/... -> 01-spring-hello-rest)
              MODULE_NAME=$(echo "$REPORT" | sed -E 's|.*/([^/]+)/target/.*|\1|' | sed 's|^\./||')
              if [ "$MODULE_NAME" = "target" ]; then
                MODULE_NAME="(root)"
              fi

              # Calculate per-module coverage
              MODULE_COV=0
              if [ $((COVERED + MISSED)) -gt 0 ]; then
                MODULE_COV=$((COVERED * 100 / (COVERED + MISSED)))
              fi
              echo "$MODULE_NAME|$MODULE_COV" >> /tmp/module_coverage.txt
              echo "Found: $REPORT ($MODULE_NAME: $MODULE_COV%)"
            fi
          done < <(find . -path "*/target/site/jacoco/jacoco.xml" -type f 2>/dev/null)

          # Calculate overall coverage
          COVERAGE=0
          if [ $((TOTAL_COVERED + TOTAL_MISSED)) -gt 0 ]; then
            COVERAGE=$((TOTAL_COVERED * 100 / (TOTAL_COVERED + TOTAL_MISSED)))
          fi
          LINE_TOTAL=$((LINE_COVERED + LINE_MISSED))

          echo "Found $FOUND_REPORTS JaCoCo report(s)"
          echo "Total: covered=$TOTAL_COVERED, missed=$TOTAL_MISSED"
          echo "percentage=$COVERAGE" >> "$GITHUB_OUTPUT"
          echo "module_count=$FOUND_REPORTS" >> "$GITHUB_OUTPUT"
          echo "lines_covered=$LINE_COVERED" >> "$GITHUB_OUTPUT"
          echo "lines_total=$LINE_TOTAL" >> "$GITHUB_OUTPUT"
          echo "Coverage: $COVERAGE%"

      - name: Check Coverage Threshold
        if: inputs.run_jacoco
        run: |
          COVERAGE=${{ steps.coverage.outputs.percentage }}
          MIN=${{ inputs.coverage_min }}
          if [ "$COVERAGE" -lt "$MIN" ]; then
            echo "::error::Coverage $COVERAGE% is below minimum $MIN%"
            exit 1
          fi

      - name: Enforce Checkstyle Threshold
        if: always() && inputs.run_checkstyle
        run: |
          ISSUES="${{ steps.lint-results.outputs.checkstyle }}"
          MAX="${{ inputs.max_checkstyle_errors }}"
          if [ "${ISSUES:-0}" -gt "${MAX:-0}" ]; then
            echo "::error::Checkstyle errors ($ISSUES) exceed max_checkstyle_errors ($MAX)"
            exit 1
          fi

      - name: Enforce SpotBugs Threshold
        if: always() && inputs.run_spotbugs
        run: |
          ISSUES="${{ steps.lint-results.outputs.spotbugs }}"
          MAX="${{ inputs.max_spotbugs_bugs }}"
          if [ "${ISSUES:-0}" -gt "${MAX:-0}" ]; then
            echo "::error::SpotBugs bugs ($ISSUES) exceed max_spotbugs_bugs ($MAX)"
            exit 1
          fi

      - name: Upload Test Reports
        if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: ${{ inputs.artifact_prefix }}test-reports
          path: |
            **/target/surefire-reports/
            **/target/failsafe-reports/
          retention-days: ${{ inputs.retention_days }}
          if-no-files-found: ignore

      - name: Upload JaCoCo Reports
        if: always() && inputs.run_jacoco
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: ${{ inputs.artifact_prefix }}jacoco-reports
          path: '**/target/site/jacoco/'
          retention-days: ${{ inputs.retention_days }}
          if-no-files-found: ignore

      - name: Upload Checkstyle Reports
        if: always() && inputs.run_checkstyle
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: ${{ inputs.artifact_prefix }}checkstyle-reports
          path: '**/target/checkstyle-result.xml'
          retention-days: ${{ inputs.retention_days }}
          if-no-files-found: ignore

      - name: Upload SpotBugs Reports
        if: always() && inputs.run_spotbugs
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: ${{ inputs.artifact_prefix }}spotbugs-reports
          path: |
            **/target/spotbugsXml.xml
            **/target/spotbugs.html
          retention-days: ${{ inputs.retention_days }}
          if-no-files-found: ignore

      - name: Upload OWASP Reports
        if: always() && inputs.run_owasp
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: ${{ inputs.artifact_prefix }}owasp-reports
          path: |
            **/target/dependency-check-report.html
            **/target/dependency-check-report.json
          retention-days: ${{ inputs.retention_days }}
          if-no-files-found: ignore

      - name: Enforce OWASP Thresholds
        if: always() && inputs.run_owasp
        run: |
          REPORT=$(find . -name "dependency-check-report.json" -print -quit)
          CRITICAL=0
          HIGH=0
          MAX_CRITICAL="${{ inputs.max_critical_vulns || 0 }}"
          MAX_HIGH="${{ inputs.max_high_vulns || 0 }}"
          if [ -n "$REPORT" ] && [ -f "$REPORT" ]; then
            CRITICAL=$(jq '[.dependencies[]?.vulnerabilities[]? | select(.severity == "CRITICAL")] | length' "$REPORT" 2>/dev/null || echo 0)
            HIGH=$(jq '[.dependencies[]?.vulnerabilities[]? | select(.severity == "HIGH")] | length' "$REPORT" 2>/dev/null || echo 0)
          else
            echo "::warning::dependency-check-report.json not found; skipping vulnerability threshold enforcement"
          fi

          if [ "$CRITICAL" -gt "$MAX_CRITICAL" ]; then
            echo "::error::Critical vulnerabilities ($CRITICAL) exceed max_critical_vulns $MAX_CRITICAL"
            exit 1
          fi
          if [ "$HIGH" -gt "$MAX_HIGH" ]; then
            echo "::error::High vulnerabilities ($HIGH) exceed max_high_vulns $MAX_HIGH"
            exit 1
          fi

          # CVSS-based enforcement
          CVSS_THRESHOLD="${{ inputs.owasp_cvss_fail }}"
          if [ -n "$REPORT" ] && [ -f "$REPORT" ]; then
            MAX_CVSS=$(jq '
              [.dependencies[]?.vulnerabilities[]? |
               (.cvssv3?.baseScore // .cvssv2?.score // .cvssData?.baseScore // 0)] | max // 0
            ' "$REPORT" 2>/dev/null || echo 0)

            # Default to 0 if empty to avoid awk errors
            MAX_CVSS="${MAX_CVSS:-0}"

            if awk "BEGIN {exit !($MAX_CVSS >= $CVSS_THRESHOLD)}"; then
              echo "::error::OWASP found vulnerability with CVSS $MAX_CVSS >= threshold $CVSS_THRESHOLD"
              exit 1
            fi
          fi

      - name: Upload to Codecov
        if: inputs.run_jacoco
        uses: codecov/codecov-action@b9fd7d16f6d7d1b5d2bec1a2887e65ceed900238 # v4
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: '**/target/site/jacoco/jacoco.xml'
          fail_ci_if_error: false
        continue-on-error: true

  # ============================================================================
  # PMD Static Analysis
  # ============================================================================
  pmd:
    name: PMD Analysis
    runs-on: ubuntu-latest
    needs: build-test
    if: always() && inputs.run_pmd
    outputs:
      violations: ${{ steps.pmd.outputs.violations }}
    defaults:
      run:
        working-directory: ${{ inputs.workdir }}

    steps:
      - name: Checkout
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          persist-credentials: false

      - name: Set up JDK ${{ inputs.java_version }}
        uses: actions/setup-java@c1e323688fd81a25caa38c78aa6df2d33d3e20d9 # v4
        with:
          java-version: ${{ inputs.java_version }}
          distribution: 'temurin'
          cache: ${{ inputs.build_tool }}

      - name: Run PMD
        id: pmd
        run: |
          if [ "${{ inputs.build_tool }}" = "maven" ]; then
            if [ -f "mvnw" ]; then
              chmod +x mvnw
              ./mvnw -B -ntp pmd:check || true
            else
              mvn -B -ntp pmd:check || true
            fi
          fi

          # Count violations
          VIOLATIONS=0
          while IFS= read -r xml; do
            COUNT=$(grep -c "<violation" "$xml" 2>/dev/null || echo 0)
            VIOLATIONS=$((VIOLATIONS + COUNT))
          done < <(find . -name "pmd.xml" 2>/dev/null)

          echo "violations=$VIOLATIONS" >> "$GITHUB_OUTPUT"
          echo "PMD Violations: $VIOLATIONS"
        continue-on-error: true

      - name: Upload PMD Reports
        if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: ${{ inputs.artifact_prefix }}pmd-reports
          path: '**/target/pmd.xml'
          retention-days: ${{ inputs.retention_days }}
          if-no-files-found: ignore

      - name: Enforce PMD Violations
        run: |
          VIOLATIONS=${{ steps.pmd.outputs.violations || 0 }}
          MAX_VIOLATIONS=${{ inputs.max_pmd_violations || 0 }}
          if [ "$VIOLATIONS" -gt "$MAX_VIOLATIONS" ]; then
            echo "::error::PMD reported $VIOLATIONS violations (max: $MAX_VIOLATIONS)"
            exit 1
          fi

  # ============================================================================
  # Semgrep SAST
  # ============================================================================
  semgrep:
    name: Semgrep SAST
    runs-on: ubuntu-latest
    needs: build-test
    if: always() && inputs.run_semgrep
    outputs:
      findings: ${{ steps.semgrep.outputs.findings }}
    defaults:
      run:
        working-directory: ${{ inputs.workdir }}

    steps:
      - name: Checkout
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          persist-credentials: false

      - name: Install jq
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: Set up Python 3.12
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5
        with:
          python-version: '3.12'

      - name: Install Semgrep
        run: pip install semgrep

      - name: Run Semgrep
        id: semgrep
        run: |
          semgrep --config=auto --json --output=semgrep-report.json . || true

          FINDINGS=0
          if [ -f "semgrep-report.json" ]; then
            FINDINGS=$(jq '.results | length' semgrep-report.json 2>/dev/null || echo 0)
          fi

          echo "findings=$FINDINGS" >> "$GITHUB_OUTPUT"
          echo "Semgrep Findings: $FINDINGS"
        continue-on-error: true

      - name: Upload Semgrep Report
        if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: ${{ inputs.artifact_prefix }}semgrep-report
          path: semgrep-report.json
          retention-days: ${{ inputs.retention_days }}
          if-no-files-found: ignore

      - name: Enforce Semgrep Threshold
        run: |
          FINDINGS=${{ steps.semgrep.outputs.findings || 0 }}
          MAX_FINDINGS=${{ inputs.max_semgrep_findings || 0 }}
          if [ "$FINDINGS" -gt "$MAX_FINDINGS" ]; then
            echo "::error::Semgrep reported $FINDINGS findings (max: $MAX_FINDINGS)"
            exit 1
          fi

  # ============================================================================
  # Trivy Container Scan
  # ============================================================================
  trivy:
    name: Trivy Container Scan
    runs-on: ubuntu-latest
    needs: build-test
    if: always() && inputs.run_trivy
    outputs:
      critical: ${{ steps.trivy-parse.outputs.critical }}
      high: ${{ steps.trivy-parse.outputs.high }}
    defaults:
      run:
        working-directory: ${{ inputs.workdir }}

    steps:
      - name: Checkout
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          persist-credentials: false

      - name: Install jq
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: Check for Dockerfile
        id: check-dockerfile
        run: |
          if [ -f "Dockerfile" ]; then
            echo "exists=true" >> "$GITHUB_OUTPUT"
          else
            echo "exists=false" >> "$GITHUB_OUTPUT"
            echo "No Dockerfile found - skipping Trivy container scan"
          fi

      - name: Run Trivy Scan
        if: steps.check-dockerfile.outputs.exists == 'true'
        id: trivy
        uses: aquasecurity/trivy-action@915b19bbe73b92a6cf82a1bc12b087c9a19a5fe2 # 0.28.0
        with:
          scan-type: 'fs'
          scan-ref: ${{ inputs.workdir }}
          format: 'json'
          output: 'trivy-report.json'
        continue-on-error: true

      - name: Parse Trivy Results
        if: steps.check-dockerfile.outputs.exists == 'true'
        id: trivy-parse
        run: |
          CRITICAL=0
          HIGH=0
          # trivy-action outputs to workspace root, not working-directory
          REPORT="${{ github.workspace }}/trivy-report.json"
          if [ -f "$REPORT" ]; then
            CRITICAL=$(jq '[.Results[]?.Vulnerabilities[]? | select(.Severity == "CRITICAL")] | length' "$REPORT" 2>/dev/null || echo 0)
            HIGH=$(jq '[.Results[]?.Vulnerabilities[]? | select(.Severity == "HIGH")] | length' "$REPORT" 2>/dev/null || echo 0)
          fi
          echo "critical=$CRITICAL" >> "$GITHUB_OUTPUT"
          echo "high=$HIGH" >> "$GITHUB_OUTPUT"
          echo "Trivy: $CRITICAL critical, $HIGH high"

      - name: Upload Trivy Report
        if: always() && steps.check-dockerfile.outputs.exists == 'true'
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: ${{ inputs.artifact_prefix }}trivy-report
          path: ${{ github.workspace }}/trivy-report.json
          retention-days: ${{ inputs.retention_days }}
          if-no-files-found: ignore

      - name: Enforce Trivy Thresholds
        if: steps.check-dockerfile.outputs.exists == 'true'
        run: |
          CRIT="${{ steps.trivy-parse.outputs.critical || 0 }}"
          HIGH="${{ steps.trivy-parse.outputs.high || 0 }}"
          MAX_CRITICAL="${{ inputs.max_critical_vulns || 0 }}"
          MAX_HIGH="${{ inputs.max_high_vulns || 0 }}"
          if [ "$CRIT" -gt "$MAX_CRITICAL" ]; then
            echo "::error::Trivy critical findings ($CRIT) exceed max_critical_vulns $MAX_CRITICAL"
            exit 1
          fi
          if [ "$HIGH" -gt "$MAX_HIGH" ]; then
            echo "::error::Trivy high findings ($HIGH) exceed max_high_vulns $MAX_HIGH"
            exit 1
          fi

          # CVSS-based enforcement
          CVSS_THRESHOLD="${{ inputs.owasp_cvss_fail }}"
          REPORT="${{ github.workspace }}/trivy-report.json"
          if [ -f "$REPORT" ]; then
            MAX_CVSS=$(jq '
              [.Results[]?.Vulnerabilities[]?.CVSS | to_entries[]?.value |
               (.V3Score // .V2Score // 0)] | max // 0
            ' "$REPORT" 2>/dev/null || echo 0)

            # Default to 0 if empty to avoid awk errors
            MAX_CVSS="${MAX_CVSS:-0}"

            if awk "BEGIN {exit !($MAX_CVSS >= $CVSS_THRESHOLD)}"; then
              echo "::error::Trivy found vulnerability with CVSS $MAX_CVSS >= threshold $CVSS_THRESHOLD"
              exit 1
            fi
          fi

  # ============================================================================
  # Mutation Testing
  # ============================================================================
  mutation-test:
    name: Mutation Testing
    runs-on: ubuntu-latest
    needs: build-test
    if: always() && inputs.run_pitest
    defaults:
      run:
        working-directory: ${{ inputs.workdir }}
    outputs:
      score: ${{ steps.pitest.outputs.score }}
      killed: ${{ steps.pitest.outputs.killed }}
      survived: ${{ steps.pitest.outputs.survived }}

    steps:
      - name: Checkout
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          persist-credentials: false

      - name: Set up JDK ${{ inputs.java_version }}
        uses: actions/setup-java@c1e323688fd81a25caa38c78aa6df2d33d3e20d9 # v4
        with:
          java-version: ${{ inputs.java_version }}
          distribution: 'temurin'
          cache: ${{ inputs.build_tool }}

      - name: Run PITest
        id: pitest
        run: |
          PITEST_EXIT=0
          if [ "${{ inputs.build_tool }}" = "maven" ]; then
            if [ -f "mvnw" ]; then
              chmod +x mvnw
              # Note: Do NOT use -DskipTests with PITest - it needs to run tests to detect killed mutations
              ./mvnw -B -ntp test-compile org.pitest:pitest-maven:mutationCoverage || PITEST_EXIT=$?
            else
              mvn -B -ntp test-compile org.pitest:pitest-maven:mutationCoverage || PITEST_EXIT=$?
            fi
          fi

          if [ "$PITEST_EXIT" -ne 0 ]; then
            echo "::warning::PITest exited with code $PITEST_EXIT"
          fi

          # Extract mutation score from ALL modules (supports multi-module projects)
          # Note: PITest uses single quotes in XML (status='KILLED'), so we match both quote styles
          TOTAL_KILLED=0
          TOTAL_SURVIVED=0
          FOUND_REPORTS=0

          # Create temp file for per-module data
          echo "" > /tmp/module_mutations.txt

          echo "Looking for pit-reports/mutations.xml..."
          while IFS= read -r REPORT; do
            if [ -f "$REPORT" ]; then
              FOUND_REPORTS=$((FOUND_REPORTS + 1))
              KILLED=$(grep -cE "status=['\"]KILLED['\"]" "$REPORT" || echo "0")
              SURVIVED=$(grep -cE "status=['\"]SURVIVED['\"]" "$REPORT" || echo "0")
              TOTAL_KILLED=$((TOTAL_KILLED + ${KILLED:-0}))
              TOTAL_SURVIVED=$((TOTAL_SURVIVED + ${SURVIVED:-0}))

              # Extract module name from path
              MODULE_NAME=$(echo "$REPORT" | sed -E 's|.*/([^/]+)/target/.*|\1|' | sed 's|^\./||')
              if [ "$MODULE_NAME" = "target" ]; then
                MODULE_NAME="(root)"
              fi

              # Calculate per-module score
              MODULE_SCORE=0
              MODULE_TOTAL=$((KILLED + SURVIVED))
              if [ "$MODULE_TOTAL" -gt 0 ]; then
                MODULE_SCORE=$((KILLED * 100 / MODULE_TOTAL))
              fi
              echo "$MODULE_NAME|$MODULE_SCORE|$KILLED|$SURVIVED" >> /tmp/module_mutations.txt
              echo "Found: $REPORT ($MODULE_NAME: $MODULE_SCORE%)"
            fi
          done < <(find . -path "*/target/pit-reports/mutations.xml" -type f 2>/dev/null)

          # Calculate overall mutation score
          SCORE=0
          TOTAL=$((TOTAL_KILLED + TOTAL_SURVIVED))
          if [ "$TOTAL" -gt 0 ]; then
            SCORE=$((TOTAL_KILLED * 100 / TOTAL))
          fi

          if [ "$FOUND_REPORTS" -eq 0 ]; then
            echo "::warning::No mutations.xml found - PITest may not have run"
          else
            echo "Found $FOUND_REPORTS PITest report(s)"
          fi
          echo "Total: killed=$TOTAL_KILLED, survived=$TOTAL_SURVIVED"
          echo "score=$SCORE" >> "$GITHUB_OUTPUT"
          echo "killed=$TOTAL_KILLED" >> "$GITHUB_OUTPUT"
          echo "survived=$TOTAL_SURVIVED" >> "$GITHUB_OUTPUT"
          echo "module_count=$FOUND_REPORTS" >> "$GITHUB_OUTPUT"
          echo "Mutation Score: $SCORE%"

      - name: Check Mutation Threshold
        run: |
          SCORE=${{ steps.pitest.outputs.score }}
          MIN=${{ inputs.mutation_score_min }}
          if [ "$SCORE" -lt "$MIN" ]; then
            echo "::error::Mutation score $SCORE% is below minimum $MIN%"
            exit 1
          fi

      - name: Upload PITest Reports
        if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: ${{ inputs.artifact_prefix }}pitest-reports
          path: '**/target/pit-reports/'
          retention-days: ${{ inputs.retention_days }}
          if-no-files-found: ignore

  # ============================================================================
  # Docker Build & Test
  # ============================================================================
  docker-build:
    name: Docker Build
    runs-on: ubuntu-latest
    needs: build-test
    if: always() && inputs.run_docker
    defaults:
      run:
        working-directory: ${{ inputs.workdir }}

    steps:
      - name: Checkout
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          persist-credentials: false

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@8d2750c68a42422c14e847fe6c8ac0403b4cbd6f # v3

      - name: Build Docker Image
        id: docker-build
        run: |
          if [ -f "Dockerfile" ]; then
            docker build -t ${{ github.repository }}:ci-test .
          fi

      - name: Test with Docker Compose
        id: docker-compose-test
        if: hashFiles(inputs.docker_compose_file) != ''
        run: |
          docker compose -f ${{ inputs.docker_compose_file }} up -d

          # Wait for health check
          echo "Waiting for services to be healthy..."
          for i in $(seq 1 30); do
            if curl -sf http://localhost:8080${{ inputs.docker_health_endpoint }} > /dev/null 2>&1; then
              echo "Service is healthy!"
              break
            fi
            echo "Attempt $i/30..."
            sleep 10
          done

          # Show logs
          docker compose logs

          # Cleanup
          docker compose down

  # ============================================================================
  # CodeQL
  # ============================================================================
  codeql:
    name: CodeQL Analysis
    runs-on: ubuntu-latest
    if: inputs.run_codeql
    permissions:
      security-events: write
    defaults:
      run:
        working-directory: ${{ inputs.workdir }}

    steps:
      - name: Checkout
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          persist-credentials: false

      - name: Initialize CodeQL
        uses: github/codeql-action/init@5d4e8d1aca955e8d8589aabd499c5cae939e33c7
        with:
          languages: java
          # Scope analysis to workdir only
          source-root: ${{ inputs.workdir }}

      - name: Set up JDK ${{ inputs.java_version }}
        uses: actions/setup-java@c1e323688fd81a25caa38c78aa6df2d33d3e20d9 # v4
        with:
          java-version: ${{ inputs.java_version }}
          distribution: 'temurin'
          cache: ${{ inputs.build_tool }}

      - name: Build for CodeQL
        run: |
          if [ "${{ inputs.build_tool }}" = "maven" ]; then
            if [ -f "mvnw" ]; then
              chmod +x mvnw
              ./mvnw -B -ntp compile -DskipTests
            else
              mvn -B -ntp compile -DskipTests
            fi
          else
            if [ -f "gradlew" ]; then
              chmod +x gradlew
              ./gradlew compileJava
            else
              gradle compileJava
            fi
          fi

      - name: Perform CodeQL Analysis
        id: codeql-analyze
        uses: github/codeql-action/analyze@5d4e8d1aca955e8d8589aabd499c5cae939e33c7

  # ============================================================================
  # Generate Report
  # ============================================================================
  report:
    name: Generate Report
    runs-on: ubuntu-latest
    needs: [build-test, pmd, semgrep, trivy, mutation-test, docker-build, codeql]
    if: always()

    steps:
      - name: Download All Artifacts
        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093 # v4
        if: always()
        continue-on-error: true
        with:
          path: all-reports/

      - name: Generate Combined Report
        env:
          GITHUB_REPO: ${{ github.repository }}
          GITHUB_RUN_ID: ${{ github.run_id }}
          GITHUB_RUN_NUMBER: ${{ github.run_number }}
          GITHUB_SHA_VAL: ${{ github.sha }}
          GITHUB_REF_NAME_VAL: ${{ github.ref_name }}
          GITHUB_WORKFLOW_REF_VAL: ${{ github.workflow_ref }}
          HUB_CORRELATION_ID: ${{ inputs.hub_correlation_id }}
          INPUT_JAVA_VERSION: ${{ inputs.java_version }}
          INPUT_BUILD_TOOL: ${{ inputs.build_tool }}
          INPUT_WORKDIR: ${{ inputs.workdir }}
          INPUT_RETENTION_DAYS: ${{ inputs.retention_days }}
          INPUT_DOCKER_COMPOSE_FILE: ${{ inputs.docker_compose_file }}
          INPUT_DOCKER_HEALTH_ENDPOINT: ${{ inputs.docker_health_endpoint }}
          INPUT_RUN_JACOCO: ${{ inputs.run_jacoco }}
          INPUT_RUN_CHECKSTYLE: ${{ inputs.run_checkstyle }}
          INPUT_RUN_SPOTBUGS: ${{ inputs.run_spotbugs }}
          INPUT_RUN_OWASP: ${{ inputs.run_owasp }}
          INPUT_RUN_PITEST: ${{ inputs.run_pitest }}
          INPUT_RUN_JQWIK: ${{ inputs.run_jqwik }}
          INPUT_RUN_PMD: ${{ inputs.run_pmd }}
          INPUT_RUN_SEMGREP: ${{ inputs.run_semgrep }}
          INPUT_RUN_TRIVY: ${{ inputs.run_trivy }}
          INPUT_RUN_CODEQL: ${{ inputs.run_codeql }}
          INPUT_RUN_DOCKER: ${{ inputs.run_docker }}
          INPUT_COVERAGE_MIN: ${{ inputs.coverage_min }}
          INPUT_MUTATION_SCORE_MIN: ${{ inputs.mutation_score_min }}
          INPUT_OWASP_CVSS_FAIL: ${{ inputs.owasp_cvss_fail }}
          INPUT_MAX_CRITICAL_VULNS: ${{ inputs.max_critical_vulns }}
          INPUT_MAX_HIGH_VULNS: ${{ inputs.max_high_vulns }}
          INPUT_MAX_SEMGREP_FINDINGS: ${{ inputs.max_semgrep_findings }}
          INPUT_MAX_PMD_VIOLATIONS: ${{ inputs.max_pmd_violations }}
          INPUT_MAX_CHECKSTYLE_ERRORS: ${{ inputs.max_checkstyle_errors }}
          INPUT_MAX_SPOTBUGS_BUGS: ${{ inputs.max_spotbugs_bugs }}
          BUILD_STATUS: ${{ needs.build-test.outputs.status }}
          BUILD_COVERAGE: ${{ needs.build-test.outputs.coverage || 0 }}
          BUILD_COVERAGE_LINES_COVERED: ${{ needs.build-test.outputs.coverage_lines_covered || 0 }}
          BUILD_COVERAGE_LINES_TOTAL: ${{ needs.build-test.outputs.coverage_lines_total || 0 }}
          BUILD_TESTS_PASSED: ${{ needs.build-test.outputs.tests_passed || 0 }}
          BUILD_TESTS_FAILED: ${{ needs.build-test.outputs.tests_failed || 0 }}
          BUILD_TESTS_SKIPPED: ${{ needs.build-test.outputs.tests_skipped || 0 }}
          BUILD_TESTS_RUNTIME: ${{ needs.build-test.outputs.tests_runtime_seconds || 0 }}
          BUILD_PROJECT_TYPE: ${{ needs.build-test.outputs.project_type }}
          MUTATION_SCORE: ${{ needs.mutation-test.outputs.score || 0 }}
          MUTATION_KILLED: ${{ needs.mutation-test.outputs.killed || 0 }}
          MUTATION_SURVIVED: ${{ needs.mutation-test.outputs.survived || 0 }}
          PMD_VIOLATIONS: ${{ needs.pmd.outputs.violations || 0 }}
          SEMGREP_FINDINGS: ${{ needs.semgrep.outputs.findings || 0 }}
          TRIVY_CRITICAL_OUT: ${{ needs.trivy.outputs.critical || 0 }}
          TRIVY_HIGH_OUT: ${{ needs.trivy.outputs.high || 0 }}
          NEEDS_PMD_RESULT: ${{ needs.pmd.result }}
          NEEDS_SEMGREP_RESULT: ${{ needs.semgrep.result }}
          NEEDS_TRIVY_RESULT: ${{ needs.trivy.result }}
          NEEDS_MUTATION_RESULT: ${{ needs.mutation-test.result }}
          NEEDS_DOCKER_RESULT: ${{ needs.docker-build.result }}
          NEEDS_CODEQL_RESULT: ${{ needs.codeql.result }}
        run: |
          WORKFLOW_REF="$GITHUB_WORKFLOW_REF_VAL"
          if [ -z "$WORKFLOW_REF" ]; then
            WORKFLOW_REF="${GITHUB_REPO}/.github/workflows/java-ci.yml@${GITHUB_REF_NAME_VAL}"
          fi
          WORKFLOW_VERSION="${WORKFLOW_REF##*@}"

          # Extract vulnerability counts from OWASP report
          CRITICAL_VULNS=0
          HIGH_VULNS=0
          MEDIUM_VULNS=0
          LOW_VULNS=0
          OWASP_CRITICAL=0
          OWASP_HIGH=0
          OWASP_MEDIUM=0
          OWASP_LOW=0
          OWASP_REPORT=""

          OWASP_REPORT=$(find all-reports -name "dependency-check-report.json" 2>/dev/null | head -1)
          if [ -n "$OWASP_REPORT" ] && [ -f "$OWASP_REPORT" ]; then
            OWASP_CRITICAL=$(jq '[.dependencies[]?.vulnerabilities[]? | select(.severity == "CRITICAL")] | length' "$OWASP_REPORT" 2>/dev/null || echo 0)
            OWASP_HIGH=$(jq '[.dependencies[]?.vulnerabilities[]? | select(.severity == "HIGH")] | length' "$OWASP_REPORT" 2>/dev/null || echo 0)
            OWASP_MEDIUM=$(jq '[.dependencies[]?.vulnerabilities[]? | select(.severity == "MEDIUM")] | length' "$OWASP_REPORT" 2>/dev/null || echo 0)
            OWASP_LOW=$(jq '[.dependencies[]?.vulnerabilities[]? | select(.severity == "LOW")] | length' "$OWASP_REPORT" 2>/dev/null || echo 0)
            CRITICAL_VULNS=$OWASP_CRITICAL
            HIGH_VULNS=$OWASP_HIGH
            MEDIUM_VULNS=$OWASP_MEDIUM
            LOW_VULNS=$OWASP_LOW
          fi

          # Extract Trivy vulnerability counts if available
          TRIVY_CRITICAL=0
          TRIVY_HIGH=0
          TRIVY_MEDIUM=0
          TRIVY_LOW=0
          TRIVY_REPORT=$(find all-reports -name "trivy-report.json" 2>/dev/null | head -1)
          if [ -n "$TRIVY_REPORT" ] && [ -f "$TRIVY_REPORT" ]; then
            TRIVY_CRITICAL=$(jq '[.Results[]?.Vulnerabilities[]? | select(.Severity == "CRITICAL")] | length' "$TRIVY_REPORT" 2>/dev/null || echo 0)
            TRIVY_HIGH=$(jq '[.Results[]?.Vulnerabilities[]? | select(.Severity == "HIGH")] | length' "$TRIVY_REPORT" 2>/dev/null || echo 0)
            TRIVY_MEDIUM=$(jq '[.Results[]?.Vulnerabilities[]? | select(.Severity == "MEDIUM")] | length' "$TRIVY_REPORT" 2>/dev/null || echo 0)
            TRIVY_LOW=$(jq '[.Results[]?.Vulnerabilities[]? | select(.Severity == "LOW")] | length' "$TRIVY_REPORT" 2>/dev/null || echo 0)
            CRITICAL_VULNS=$((CRITICAL_VULNS + TRIVY_CRITICAL))
            HIGH_VULNS=$((HIGH_VULNS + TRIVY_HIGH))
            MEDIUM_VULNS=$((MEDIUM_VULNS + TRIVY_MEDIUM))
            LOW_VULNS=$((LOW_VULNS + TRIVY_LOW))
          fi

          # Extract checkstyle issues from artifact
          CHECKSTYLE_ISSUES=0
          CHECKSTYLE_REPORT=$(find all-reports -name "checkstyle-result.xml" 2>/dev/null | head -1)
          if [ -n "$CHECKSTYLE_REPORT" ] && [ -f "$CHECKSTYLE_REPORT" ]; then
            CHECKSTYLE_ISSUES=$(grep -c "<error" "$CHECKSTYLE_REPORT" 2>/dev/null || echo 0)
          fi

          # Extract spotbugs issues from artifact
          SPOTBUGS_ISSUES=0
          SPOTBUGS_REPORT=$(find all-reports -name "spotbugsXml.xml" 2>/dev/null | head -1)
          if [ -n "$SPOTBUGS_REPORT" ] && [ -f "$SPOTBUGS_REPORT" ]; then
            SPOTBUGS_ISSUES=$(grep -c "<BugInstance" "$SPOTBUGS_REPORT" 2>/dev/null || echo 0)
          fi

          # Tool run flags (artifact-driven where possible)
          JACOCO_RAN=false
          if [ "$INPUT_RUN_JACOCO" = "true" ]; then
            JACOCO_REPORT=$(find all-reports -path "*/target/site/jacoco/jacoco.xml" 2>/dev/null | head -1)
            if [ -n "$JACOCO_REPORT" ]; then
              JACOCO_RAN=true
            fi
          fi

          CHECKSTYLE_RAN=false
          if [ "$INPUT_RUN_CHECKSTYLE" = "true" ] && [ -n "$CHECKSTYLE_REPORT" ]; then
            CHECKSTYLE_RAN=true
          fi

          SPOTBUGS_RAN=false
          if [ "$INPUT_RUN_SPOTBUGS" = "true" ] && [ -n "$SPOTBUGS_REPORT" ]; then
            SPOTBUGS_RAN=true
          fi

          OWASP_RAN=false
          if [ "$INPUT_RUN_OWASP" = "true" ] && [ -n "$OWASP_REPORT" ]; then
            OWASP_RAN=true
          fi

          JQWIK_RAN=false
          TOTAL_TESTS=$((BUILD_TESTS_PASSED + BUILD_TESTS_FAILED + BUILD_TESTS_SKIPPED))
          if [ "$INPUT_RUN_JQWIK" = "true" ] && [ "$TOTAL_TESTS" -gt 0 ]; then
            JQWIK_RAN=true
          fi

          PITEST_RAN=false
          PITEST_SUCCESS=false
          if [ "$INPUT_RUN_PITEST" = "true" ] && [ "$NEEDS_MUTATION_RESULT" != "skipped" ]; then
            PITEST_RAN=true
            if [ "$NEEDS_MUTATION_RESULT" = "success" ]; then
              PITEST_SUCCESS=true
            fi
          fi

          PMD_RAN=false
          PMD_SUCCESS=false
          if [ "$INPUT_RUN_PMD" = "true" ] && [ "$NEEDS_PMD_RESULT" != "skipped" ]; then
            PMD_RAN=true
            if [ "$NEEDS_PMD_RESULT" = "success" ]; then
              PMD_SUCCESS=true
            fi
          fi

          SEMGREP_RAN=false
          SEMGREP_SUCCESS=false
          if [ "$INPUT_RUN_SEMGREP" = "true" ] && [ "$NEEDS_SEMGREP_RESULT" != "skipped" ]; then
            SEMGREP_RAN=true
            if [ "$NEEDS_SEMGREP_RESULT" = "success" ]; then
              SEMGREP_SUCCESS=true
            fi
          fi

          TRIVY_RAN=false
          TRIVY_SUCCESS=false
          if [ "$INPUT_RUN_TRIVY" = "true" ] && [ "$NEEDS_TRIVY_RESULT" != "skipped" ]; then
            TRIVY_RAN=true
            if [ "$NEEDS_TRIVY_RESULT" = "success" ]; then
              TRIVY_SUCCESS=true
            fi
          fi

          DOCKER_RAN=false
          DOCKER_SUCCESS=false
          if [ "$INPUT_RUN_DOCKER" = "true" ] && [ "$NEEDS_DOCKER_RESULT" != "skipped" ]; then
            DOCKER_RAN=true
            if [ "$NEEDS_DOCKER_RESULT" = "success" ]; then
              DOCKER_SUCCESS=true
            fi
          fi

          CODEQL_RAN=false
          CODEQL_SUCCESS=false
          if [ "$INPUT_RUN_CODEQL" = "true" ] && [ "$NEEDS_CODEQL_RESULT" != "skipped" ]; then
            CODEQL_RAN=true
            if [ "$NEEDS_CODEQL_RESULT" = "success" ]; then
              CODEQL_SUCCESS=true
            fi
          fi

          # Tool success flags (threshold-driven for build-test tools)
          JACOCO_SUCCESS=false
          if [ "$JACOCO_RAN" = "true" ] && [ "$BUILD_COVERAGE" -ge "$INPUT_COVERAGE_MIN" ]; then
            JACOCO_SUCCESS=true
          fi

          CHECKSTYLE_SUCCESS=false
          if [ "$CHECKSTYLE_RAN" = "true" ] && [ "$CHECKSTYLE_ISSUES" -le "$INPUT_MAX_CHECKSTYLE_ERRORS" ]; then
            CHECKSTYLE_SUCCESS=true
          fi

          SPOTBUGS_SUCCESS=false
          if [ "$SPOTBUGS_RAN" = "true" ] && [ "$SPOTBUGS_ISSUES" -le "$INPUT_MAX_SPOTBUGS_BUGS" ]; then
            SPOTBUGS_SUCCESS=true
          fi

          OWASP_SUCCESS=false
          if [ "$OWASP_RAN" = "true" ] && [ "$OWASP_CRITICAL" -le "$INPUT_MAX_CRITICAL_VULNS" ] && [ "$OWASP_HIGH" -le "$INPUT_MAX_HIGH_VULNS" ]; then
            OWASP_SUCCESS=true
          fi

          JQWIK_SUCCESS=false
          if [ "$JQWIK_RAN" = "true" ] && [ "$BUILD_TESTS_FAILED" -eq 0 ]; then
            JQWIK_SUCCESS=true
          fi

          cat > report.json << EOF
          {
            "schema_version": "2.0",
            "metadata": {
              "workflow_version": "${WORKFLOW_VERSION}",
              "workflow_ref": "${WORKFLOW_REF}",
              "generated_at": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")"
            },
            "repository": "${GITHUB_REPO}",
            "run_id": "${GITHUB_RUN_ID}",
            "run_number": "${GITHUB_RUN_NUMBER}",
            "commit": "${GITHUB_SHA_VAL}",
            "branch": "${GITHUB_REF_NAME_VAL}",
            "hub_correlation_id": "${HUB_CORRELATION_ID}",
            "timestamp": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
            "java_version": "${INPUT_JAVA_VERSION}",
            "results": {
              "build": "${BUILD_STATUS}",
              "coverage": ${BUILD_COVERAGE},
              "coverage_lines_covered": ${BUILD_COVERAGE_LINES_COVERED},
              "coverage_lines_total": ${BUILD_COVERAGE_LINES_TOTAL},
              "mutation_score": ${MUTATION_SCORE},
              "mutation_killed": ${MUTATION_KILLED},
              "mutation_survived": ${MUTATION_SURVIVED},
              "tests_passed": ${BUILD_TESTS_PASSED},
              "tests_failed": ${BUILD_TESTS_FAILED},
              "tests_skipped": ${BUILD_TESTS_SKIPPED},
              "tests_runtime_seconds": ${BUILD_TESTS_RUNTIME},
              "critical_vulns": ${CRITICAL_VULNS},
              "high_vulns": ${HIGH_VULNS},
              "medium_vulns": ${MEDIUM_VULNS},
              "low_vulns": ${LOW_VULNS}
            },
            "tool_metrics": {
              "checkstyle_issues": ${CHECKSTYLE_ISSUES},
              "spotbugs_issues": ${SPOTBUGS_ISSUES},
              "pmd_violations": ${PMD_VIOLATIONS},
              "owasp_critical": ${OWASP_CRITICAL},
              "owasp_high": ${OWASP_HIGH},
              "owasp_medium": ${OWASP_MEDIUM},
              "owasp_low": ${OWASP_LOW},
              "semgrep_findings": ${SEMGREP_FINDINGS},
              "trivy_critical": ${TRIVY_CRITICAL},
              "trivy_high": ${TRIVY_HIGH},
              "trivy_medium": ${TRIVY_MEDIUM},
              "trivy_low": ${TRIVY_LOW}
            },
            "tools_configured": {
              "jacoco": ${INPUT_RUN_JACOCO},
              "checkstyle": ${INPUT_RUN_CHECKSTYLE},
              "spotbugs": ${INPUT_RUN_SPOTBUGS},
              "pmd": ${INPUT_RUN_PMD},
              "owasp": ${INPUT_RUN_OWASP},
              "pitest": ${INPUT_RUN_PITEST},
              "jqwik": ${INPUT_RUN_JQWIK},
              "semgrep": ${INPUT_RUN_SEMGREP},
              "trivy": ${INPUT_RUN_TRIVY},
              "codeql": ${INPUT_RUN_CODEQL},
              "docker": ${INPUT_RUN_DOCKER}
            },
            "tools_ran": {
              "jacoco": ${JACOCO_RAN},
              "checkstyle": ${CHECKSTYLE_RAN},
              "spotbugs": ${SPOTBUGS_RAN},
              "pmd": ${PMD_RAN},
              "owasp": ${OWASP_RAN},
              "pitest": ${PITEST_RAN},
              "jqwik": ${JQWIK_RAN},
              "semgrep": ${SEMGREP_RAN},
              "trivy": ${TRIVY_RAN},
              "codeql": ${CODEQL_RAN},
              "docker": ${DOCKER_RAN}
            },
            "tools_success": {
              "jacoco": ${JACOCO_SUCCESS},
              "checkstyle": ${CHECKSTYLE_SUCCESS},
              "spotbugs": ${SPOTBUGS_SUCCESS},
              "pmd": ${PMD_SUCCESS},
              "owasp": ${OWASP_SUCCESS},
              "pitest": ${PITEST_SUCCESS},
              "jqwik": ${JQWIK_SUCCESS},
              "semgrep": ${SEMGREP_SUCCESS},
              "trivy": ${TRIVY_SUCCESS},
              "codeql": ${CODEQL_SUCCESS},
              "docker": ${DOCKER_SUCCESS}
            },
            "thresholds": {
              "coverage_min": ${INPUT_COVERAGE_MIN},
              "mutation_score_min": ${INPUT_MUTATION_SCORE_MIN},
              "owasp_cvss_fail": ${INPUT_OWASP_CVSS_FAIL},
              "max_pmd_violations": ${INPUT_MAX_PMD_VIOLATIONS},
              "max_critical_vulns": ${INPUT_MAX_CRITICAL_VULNS},
              "max_high_vulns": ${INPUT_MAX_HIGH_VULNS},
              "max_semgrep_findings": ${INPUT_MAX_SEMGREP_FINDINGS},
              "max_checkstyle_errors": ${INPUT_MAX_CHECKSTYLE_ERRORS},
              "max_spotbugs_bugs": ${INPUT_MAX_SPOTBUGS_BUGS}
            },
            "dependency_severity": {
              "critical": ${CRITICAL_VULNS},
              "high": ${HIGH_VULNS},
              "medium": ${MEDIUM_VULNS},
              "low": ${LOW_VULNS}
            },
            "environment": {
              "build_tool": "${INPUT_BUILD_TOOL}",
              "workdir": "${INPUT_WORKDIR}",
              "project_type": "${BUILD_PROJECT_TYPE}",
              "retention_days": ${INPUT_RETENTION_DAYS},
              "docker_compose_file": "${INPUT_DOCKER_COMPOSE_FILE}",
              "docker_health_endpoint": "${INPUT_DOCKER_HEALTH_ENDPOINT}"
            }
          }
          EOF

          cat report.json

      - name: Upload Combined Report
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        if: always()
        with:
          name: ${{ inputs.artifact_prefix }}ci-report
          path: report.json
          retention-days: ${{ inputs.retention_days }}

      - name: Resolve Hub Workflow Ref
        id: hub-ref
        run: |
          WF_REF="${GITHUB_WORKFLOW_REF:-}"
          if [ -n "$WF_REF" ]; then
            REPO="${WF_REF%%/.github/workflows/*}"
            REF="${WF_REF##*@}"
          else
            REPO="jguida941/ci-cd-hub"
            REF="main"
          fi
          echo "repo=$REPO" >> "$GITHUB_OUTPUT"
          echo "ref=$REF" >> "$GITHUB_OUTPUT"

      - name: Checkout Hub Scripts
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          repository: ${{ steps.hub-ref.outputs.repo }}
          ref: ${{ steps.hub-ref.outputs.ref }}
          path: hub
          persist-credentials: false
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Render Summary
        if: always()
        run: |
          python hub/scripts/render_summary.py --report report.json --output summary.md
          cat summary.md >> "$GITHUB_STEP_SUMMARY"

      - name: Validate Summary
        if: always()
        run: |
          python hub/scripts/validate_summary.py \
            --report report.json \
            --summary summary.md \
            --reports-dir all-reports \
            --strict
